{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "939d91c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:32:21.102020Z",
     "iopub.status.busy": "2025-10-06T21:32:21.101722Z",
     "iopub.status.idle": "2025-10-06T21:32:28.055220Z",
     "shell.execute_reply": "2025-10-06T21:32:28.054381Z"
    },
    "papermill": {
     "duration": 6.959056,
     "end_time": "2025-10-06T21:32:28.056515",
     "exception": false,
     "start_time": "2025-10-06T21:32:21.097459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется устройство: cuda\n",
      "Доступно GPU: 1\n",
      "Название GPU: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MITSUI - 5-Model Ensemble with Feature Alignment\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "# import kaggle_evaluation.mitsui_inference_server\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используется устройство: {device}\")\n",
    "print(f\"Доступно GPU: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Название GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "NUM_TARGET_COLUMNS = 424\n",
    "\n",
    "# Глобальные переменные\n",
    "models = []\n",
    "scaler = None\n",
    "feature_cols = None\n",
    "base_cols = None\n",
    "is_initialized = False\n",
    "model_val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6418fa8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:32:28.063205Z",
     "iopub.status.busy": "2025-10-06T21:32:28.062872Z",
     "iopub.status.idle": "2025-10-06T21:32:28.073138Z",
     "shell.execute_reply": "2025-10-06T21:32:28.072594Z"
    },
    "papermill": {
     "duration": 0.014809,
     "end_time": "2025-10-06T21:32:28.074242",
     "exception": false,
     "start_time": "2025-10-06T21:32:28.059433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Model1_Deep(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(input_size, 512),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, output_size)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)\n",
    "\n",
    "# class Model2_Wide(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(input_size, 1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(512, output_size)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)\n",
    "\n",
    "# class Model3_Residual(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super().__init__()\n",
    "#         self.input_proj = nn.Linear(input_size, 256)\n",
    "#         self.block1 = nn.Sequential(\n",
    "#             nn.Linear(256, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2)\n",
    "#         )\n",
    "#         self.block2 = nn.Sequential(\n",
    "#             nn.Linear(256, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2)\n",
    "#         )\n",
    "#         self.output = nn.Linear(256, output_size)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.input_proj(x)\n",
    "#         x = x + self.block1(x)\n",
    "#         x = x + self.block2(x)\n",
    "#         return self.output(x)\n",
    "\n",
    "# class Model4_DeepWide(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(input_size, 768),\n",
    "#             nn.BatchNorm1d(768),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(768, 512),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(256, output_size)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)\n",
    "\n",
    "# class Model5_Bottleneck(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super().__init__()\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Linear(input_size, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(512, 128),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(128, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(256, output_size)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.encoder(x)\n",
    "#         x = self.decoder(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# УЛУЧШЕННЫЕ АРХИТЕКТУРЫ МОДЕЛЕЙ\n",
    "# ==========================================\n",
    "\n",
    "class Model1_Deep(nn.Module):\n",
    "    \"\"\"Глубокая сеть с Layer Normalization и лучшей регуляризацией\"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LayerNorm(512),  # LayerNorm вместо BatchNorm\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 384),\n",
    "            nn.LayerNorm(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(384, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            \n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Model2_Wide(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 768)  # Меньше 1024→768\n",
    "        self.bn1 = nn.LayerNorm(768)  # LayerNorm вместо BatchNorm\n",
    "        self.drop1 = nn.Dropout(0.4)  # Больше dropout\n",
    "        \n",
    "        self.fc2 = nn.Linear(768, 512)\n",
    "        self.bn2 = nn.LayerNorm(512)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 384)\n",
    "        self.bn3 = nn.LayerNorm(384)\n",
    "        self.drop3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.output = nn.Linear(384, output_size)\n",
    "        self.skip = nn.Linear(input_size, 384)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        \n",
    "        x = self.activation(self.bn1(self.fc1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = self.activation(self.bn2(self.fc2(x)))\n",
    "        x = self.drop2(x)\n",
    "        x = self.activation(self.bn3(self.fc3(x)))\n",
    "        x = self.drop3(x)\n",
    "        \n",
    "        x = x + identity\n",
    "        return self.output(x)\n",
    "\n",
    "class Model3_Residual(nn.Module):\n",
    "    \"\"\"Исправленная Residual с BatchNorm и Pre-Activation\"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_size, 384)\n",
    "        self.bn_input = nn.BatchNorm1d(384)\n",
    "        \n",
    "        # Pre-activation residual blocks\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(384, 384),\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(384, 384)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(384, 384),\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(384, 384)\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(384, 384),\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(384, 384)\n",
    "        )\n",
    "        \n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn_input(self.input_proj(x))\n",
    "        x = x + self.block1(x)\n",
    "        x = x + self.block2(x)\n",
    "        x = x + self.block3(x)\n",
    "        return self.output_proj(x)\n",
    "\n",
    "class Model4_DeepWide(nn.Module):\n",
    "    \"\"\"Deep & Wide с параллельными путями\"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Deep path (узкий и глубокий)\n",
    "        self.deep = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 384),\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(384, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Wide path (широкий и мелкий)\n",
    "        self.wide = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Combine\n",
    "        self.combine = nn.Sequential(\n",
    "            nn.Linear(256, 128),  # 128 + 128 = 256\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        deep_out = self.deep(x)\n",
    "        wide_out = self.wide(x)\n",
    "        \n",
    "        # Concatenate\n",
    "        combined = torch.cat([deep_out, wide_out], dim=1)\n",
    "        return self.combine(combined)\n",
    "\n",
    "class Model5_Bottleneck(nn.Module):\n",
    "    \"\"\"Bottleneck с Attention механизмом\"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Self-Attention на bottleneck\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 384),\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            \n",
    "            nn.Linear(384, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encoded = self.encoder(x)\n",
    "        \n",
    "        # Attention\n",
    "        attention_weights = self.attention(encoded)\n",
    "        attended = encoded * attention_weights\n",
    "        \n",
    "        # Decode\n",
    "        return self.decoder(attended)\n",
    "\n",
    "class Model6_Transformer(nn.Module):\n",
    "    \"\"\"Transformer-inspired architecture\"\"\"\n",
    "    def __init__(self, input_size, output_size, num_heads=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_size, 512)\n",
    "        \n",
    "        # Multi-head attention\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=512,\n",
    "            num_heads=num_heads,\n",
    "            dropout=0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(512)\n",
    "        self.norm2 = nn.LayerNorm(512)\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512)\n",
    "        )\n",
    "        \n",
    "        # Output\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(256, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Project input\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Add sequence dimension for attention\n",
    "        x = x.unsqueeze(1)  # [batch, 1, features]\n",
    "        \n",
    "        # Self-attention with residual\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        \n",
    "        # Feed-forward with residual\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm2(x + ffn_out)\n",
    "        \n",
    "        # Remove sequence dimension\n",
    "        x = x.squeeze(1)  # [batch, features]\n",
    "        \n",
    "        return self.output(x)\n",
    "\n",
    "class Model7_EnsembleBlock(nn.Module):\n",
    "    \"\"\"Модель с внутренним ансамблем\"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Три параллельных пути\n",
    "        self.path1 = nn.Sequential(\n",
    "            nn.Linear(input_size, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.path2 = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.path3 = nn.Sequential(\n",
    "            nn.Linear(input_size, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.35),\n",
    "            nn.Linear(640, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Gating mechanism для взвешивания путей\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Final layers\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Три пути\n",
    "        out1 = self.path1(x)\n",
    "        out2 = self.path2(x)\n",
    "        out3 = self.path3(x)\n",
    "        \n",
    "        # Gating weights\n",
    "        gates = self.gate(x)  # [batch, 3]\n",
    "        \n",
    "        # Weighted combination\n",
    "        combined = (gates[:, 0:1] * out1 + \n",
    "                   gates[:, 1:2] * out2 + \n",
    "                   gates[:, 2:3] * out3)\n",
    "        \n",
    "        return self.output(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c33b0a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:32:28.080349Z",
     "iopub.status.busy": "2025-10-06T21:32:28.080151Z",
     "iopub.status.idle": "2025-10-06T21:32:28.089261Z",
     "shell.execute_reply": "2025-10-06T21:32:28.088704Z"
    },
    "papermill": {
     "duration": 0.013423,
     "end_time": "2025-10-06T21:32:28.090294",
     "exception": false,
     "start_time": "2025-10-06T21:32:28.076871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_enhanced_features(df, base_cols_ref=None):\n",
    "    \"\"\"Создает расширенный набор технических индикаторов\"\"\"\n",
    "    features = df.copy()\n",
    "    \n",
    "    if base_cols_ref is not None:\n",
    "        numeric_cols = [c for c in base_cols_ref if c in df.columns]\n",
    "    else:\n",
    "        numeric_cols = [c for c in df.columns \n",
    "                       if c not in ['date_id', 'is_scored'] \n",
    "                       and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        try:\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                # ===== БАЗОВЫЕ RETURNS =====\n",
    "                features[f'{col}_return_1d'] = df[col].pct_change(1)\n",
    "                features[f'{col}_return_5d'] = df[col].pct_change(5)\n",
    "                features[f'{col}_return_20d'] = df[col].pct_change(20)\n",
    "                features[f'{col}_return_60d'] = df[col].pct_change(60)\n",
    "                \n",
    "                # ===== SIMPLE MOVING AVERAGES (SMA) =====\n",
    "                features[f'{col}_ma_5'] = df[col].rolling(5, min_periods=1).mean()\n",
    "                features[f'{col}_ma_10'] = df[col].rolling(10, min_periods=1).mean()\n",
    "                features[f'{col}_ma_20'] = df[col].rolling(20, min_periods=1).mean()\n",
    "                features[f'{col}_ma_60'] = df[col].rolling(60, min_periods=1).mean()\n",
    "                \n",
    "                # ===== EXPONENTIAL MOVING AVERAGES (EMA) =====\n",
    "                features[f'{col}_ema_5'] = df[col].ewm(span=5, adjust=False).mean()\n",
    "                features[f'{col}_ema_10'] = df[col].ewm(span=10, adjust=False).mean()\n",
    "                features[f'{col}_ema_20'] = df[col].ewm(span=20, adjust=False).mean()\n",
    "                \n",
    "                # ===== MA CROSSOVERS =====\n",
    "                features[f'{col}_ma_5_20_diff'] = features[f'{col}_ma_5'] - features[f'{col}_ma_20']\n",
    "                features[f'{col}_ma_10_60_diff'] = features[f'{col}_ma_10'] - features[f'{col}_ma_60']\n",
    "                features[f'{col}_ema_5_20_diff'] = features[f'{col}_ema_5'] - features[f'{col}_ema_20']\n",
    "                \n",
    "                # ===== PRICE TO MA DISTANCE =====\n",
    "                features[f'{col}_to_ma_5'] = (df[col] - features[f'{col}_ma_5']) / features[f'{col}_ma_5']\n",
    "                features[f'{col}_to_ma_20'] = (df[col] - features[f'{col}_ma_20']) / features[f'{col}_ma_20']\n",
    "                features[f'{col}_to_ema_10'] = (df[col] - features[f'{col}_ema_10']) / features[f'{col}_ema_10']\n",
    "                \n",
    "                # ===== VOLATILITY =====\n",
    "                features[f'{col}_std_5'] = df[col].rolling(5, min_periods=1).std()\n",
    "                features[f'{col}_std_20'] = df[col].rolling(20, min_periods=1).std()\n",
    "                features[f'{col}_std_60'] = df[col].rolling(60, min_periods=1).std()\n",
    "                \n",
    "                # ===== BOLLINGER BANDS =====\n",
    "                ma_20 = features[f'{col}_ma_20']\n",
    "                std_20 = features[f'{col}_std_20']\n",
    "                features[f'{col}_bb_upper'] = ma_20 + 2 * std_20\n",
    "                features[f'{col}_bb_lower'] = ma_20 - 2 * std_20\n",
    "                features[f'{col}_bb_width'] = (features[f'{col}_bb_upper'] - features[f'{col}_bb_lower']) / ma_20\n",
    "                features[f'{col}_bb_position'] = (df[col] - features[f'{col}_bb_lower']) / (features[f'{col}_bb_upper'] - features[f'{col}_bb_lower'])\n",
    "                \n",
    "                # ===== RSI (Relative Strength Index) =====\n",
    "                delta = df[col].diff()\n",
    "                gain = delta.where(delta > 0, 0).rolling(window=14, min_periods=1).mean()\n",
    "                loss = -delta.where(delta < 0, 0).rolling(window=14, min_periods=1).mean()\n",
    "                rs = gain / loss\n",
    "                features[f'{col}_rsi_14'] = 100 - (100 / (1 + rs))\n",
    "                \n",
    "                # ===== MACD =====\n",
    "                ema_12 = df[col].ewm(span=12, adjust=False).mean()\n",
    "                ema_26 = df[col].ewm(span=26, adjust=False).mean()\n",
    "                features[f'{col}_macd'] = ema_12 - ema_26\n",
    "                features[f'{col}_macd_signal'] = features[f'{col}_macd'].ewm(span=9, adjust=False).mean()\n",
    "                features[f'{col}_macd_diff'] = features[f'{col}_macd'] - features[f'{col}_macd_signal']\n",
    "                \n",
    "                # ===== MOMENTUM =====\n",
    "                features[f'{col}_momentum_5'] = df[col] - df[col].shift(5)\n",
    "                features[f'{col}_momentum_10'] = df[col] - df[col].shift(10)\n",
    "                features[f'{col}_momentum_20'] = df[col] - df[col].shift(20)\n",
    "                \n",
    "                # ===== RATE OF CHANGE (ROC) =====\n",
    "                features[f'{col}_roc_5'] = ((df[col] - df[col].shift(5)) / df[col].shift(5)) * 100\n",
    "                features[f'{col}_roc_10'] = ((df[col] - df[col].shift(10)) / df[col].shift(10)) * 100\n",
    "                features[f'{col}_roc_20'] = ((df[col] - df[col].shift(20)) / df[col].shift(20)) * 100\n",
    "                \n",
    "                # ===== LAG FEATURES =====\n",
    "                features[f'{col}_lag_1'] = df[col].shift(1)\n",
    "                features[f'{col}_lag_2'] = df[col].shift(2)\n",
    "                features[f'{col}_lag_3'] = df[col].shift(3)\n",
    "                features[f'{col}_lag_5'] = df[col].shift(5)\n",
    "                \n",
    "                # ===== MIN/MAX OVER WINDOWS =====\n",
    "                features[f'{col}_max_5'] = df[col].rolling(5, min_periods=1).max()\n",
    "                features[f'{col}_min_5'] = df[col].rolling(5, min_periods=1).min()\n",
    "                features[f'{col}_max_20'] = df[col].rolling(20, min_periods=1).max()\n",
    "                features[f'{col}_min_20'] = df[col].rolling(20, min_periods=1).min()\n",
    "                \n",
    "                # Distance to recent high/low\n",
    "                features[f'{col}_dist_to_max_20'] = (df[col] - features[f'{col}_max_20']) / features[f'{col}_max_20']\n",
    "                features[f'{col}_dist_to_min_20'] = (df[col] - features[f'{col}_min_20']) / features[f'{col}_min_20']\n",
    "                \n",
    "                # ===== ACCELERATION (second derivative) =====\n",
    "                features[f'{col}_acceleration'] = df[col].diff().diff()\n",
    "                \n",
    "                # ===== Z-SCORE (standardized price) =====\n",
    "                rolling_mean = df[col].rolling(20, min_periods=1).mean()\n",
    "                rolling_std = df[col].rolling(20, min_periods=1).std()\n",
    "                features[f'{col}_zscore'] = (df[col] - rolling_mean) / rolling_std\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0411b061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:32:28.096445Z",
     "iopub.status.busy": "2025-10-06T21:32:28.095989Z",
     "iopub.status.idle": "2025-10-06T21:32:28.101226Z",
     "shell.execute_reply": "2025-10-06T21:32:28.100719Z"
    },
    "papermill": {
     "duration": 0.009277,
     "end_time": "2025-10-06T21:32:28.102231",
     "exception": false,
     "start_time": "2025-10-06T21:32:28.092954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_features(df):\n",
    "    global base_cols, feature_cols\n",
    "    \n",
    "    # Если модели еще не инициализированы, используем только базовые колонки\n",
    "    if base_cols is None:\n",
    "        numeric_cols = [c for c in df.columns \n",
    "                       if c not in ['date_id', 'is_scored'] \n",
    "                       and pd.api.types.is_numeric_dtype(df[c])]\n",
    "        test_features = create_enhanced_features(df, base_cols_ref=numeric_cols)\n",
    "    else:\n",
    "        test_features = create_enhanced_features(df, base_cols_ref=base_cols)\n",
    "    \n",
    "    # Если feature_cols еще не определены, создаем их из доступных колонок\n",
    "    if feature_cols is None:\n",
    "        feature_cols = [c for c in test_features.columns \n",
    "                       if c != 'date_id' and pd.api.types.is_numeric_dtype(test_features[c])]\n",
    "    \n",
    "    # Берем только те фичи которые есть в feature_cols\n",
    "    # Если какой-то фичи нет - заполняем нулями\n",
    "    X_test = np.zeros((len(df), len(feature_cols)))\n",
    "    \n",
    "    for i, col in enumerate(feature_cols):\n",
    "        if col in test_features.columns:\n",
    "            X_test[:, i] = test_features[col].fillna(0).values\n",
    "    \n",
    "    X_test = np.nan_to_num(X_test, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75fe4767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:32:28.108237Z",
     "iopub.status.busy": "2025-10-06T21:32:28.108040Z",
     "iopub.status.idle": "2025-10-06T21:32:28.122651Z",
     "shell.execute_reply": "2025-10-06T21:32:28.122100Z"
    },
    "papermill": {
     "duration": 0.019038,
     "end_time": "2025-10-06T21:32:28.123758",
     "exception": false,
     "start_time": "2025-10-06T21:32:28.104720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_models():\n",
    "    global models, scaler, feature_cols, base_cols, model_val_losses, is_initialized, device\n",
    "    \n",
    "    if is_initialized:\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"ИНИЦИАЛИЗАЦИЯ И ОБУЧЕНИЕ МОДЕЛЕЙ НА {device}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    train = pd.read_csv('/home/nicolaedrabcinski/sd_kaggle/data/raw/train.csv')\n",
    "    train_labels = pd.read_csv('/home/nicolaedrabcinski/sd_kaggle/data/raw/train_labels.csv')\n",
    "    \n",
    "    base_cols = [c for c in train.columns \n",
    "                 if c not in ['date_id'] \n",
    "                 and pd.api.types.is_numeric_dtype(train[c])]\n",
    "    \n",
    "    print(f\"\\nБазовых колонок: {len(base_cols)}\")\n",
    "    print(\"Создание признаков...\")\n",
    "    \n",
    "    train_features = create_enhanced_features(train, base_cols_ref=base_cols)\n",
    "    \n",
    "    feature_cols = [c for c in train_features.columns \n",
    "                   if c != 'date_id' and pd.api.types.is_numeric_dtype(train_features[c])]\n",
    "    \n",
    "    print(f\"Создано {len(feature_cols)} признаков\")\n",
    "    \n",
    "    target_cols = [f'target_{i}' for i in range(424)]\n",
    "    \n",
    "    X_train = train_features[feature_cols].fillna(0).values\n",
    "    y_train = train_labels[target_cols].fillna(0).values\n",
    "    \n",
    "    X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    y_train = np.nan_to_num(y_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "    y_tensor = torch.FloatTensor(y_train).to(device)\n",
    "    \n",
    "    split_idx = int(len(X_train_scaled) * 0.9)\n",
    "    X_train_t, X_val_t = X_tensor[:split_idx], X_tensor[split_idx:]\n",
    "    y_train_t, y_val_t = y_tensor[:split_idx], y_tensor[split_idx:]\n",
    "    \n",
    "    print(f\"Train: {len(X_train_t)}, Validation: {len(X_val_t)}\")\n",
    "    \n",
    "    # model_configs = [\n",
    "    #     (Model1_Deep, \"Deep\", 1000),\n",
    "    #     (Model2_Wide, \"Wide\", 1000),\n",
    "    #     (Model3_Residual, \"Residual\", 1000),\n",
    "    #     (Model4_DeepWide, \"DeepWide\", 1000),\n",
    "    #     (Model5_Bottleneck, \"Bottleneck\", 1000),\n",
    "    # ]\n",
    "\n",
    "    model_configs = [\n",
    "        (Model1_Deep, \"Deep+LayerNorm\", 800),\n",
    "        (Model2_Wide, \"Wide+Skip\", 800),\n",
    "        (Model3_Residual, \"Residual+PreAct\", 800),\n",
    "        (Model4_DeepWide, \"DeepWide+Parallel\", 800),\n",
    "        (Model5_Bottleneck, \"Bottleneck+Attention\", 800),\n",
    "        (Model6_Transformer, \"Transformer\", 800),\n",
    "        (Model7_EnsembleBlock, \"EnsembleBlock+Gating\", 800),\n",
    "    ]\n",
    "    \n",
    "    for i, (ModelClass, name, epochs) in enumerate(model_configs):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"МОДЕЛЬ {i+1}/{len(model_configs)}: {name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        model = ModelClass(X_train_scaled.shape[1], 424).to(device)\n",
    "        \n",
    "        criterion = nn.HuberLoss(delta=1.0)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "        \n",
    "        patience = 15\n",
    "        best_val_loss = float('inf')\n",
    "        best_r2 = -float('inf')\n",
    "        best_model_state = None\n",
    "        epochs_no_improve = 0\n",
    "        early_stop = False\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            if early_stop:\n",
    "                print(f\"Early stopping на эпохе {epoch+1}\")\n",
    "                break\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            train_outputs = model(X_train_t)\n",
    "            train_loss = criterion(train_outputs, y_train_t)\n",
    "            train_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_val_t)\n",
    "                val_loss = criterion(val_outputs, y_val_t)\n",
    "                \n",
    "                val_preds = val_outputs.cpu().numpy()\n",
    "                val_true = y_val_t.cpu().numpy()\n",
    "                \n",
    "                mae = mean_absolute_error(val_true.flatten(), val_preds.flatten())\n",
    "                direction_correct = np.mean(np.sign(val_preds) == np.sign(val_true))\n",
    "                r2 = r2_score(val_true.flatten(), val_preds.flatten())\n",
    "                \n",
    "                train_preds = train_outputs.detach().cpu().numpy()\n",
    "                train_true = y_train_t.cpu().numpy()\n",
    "                train_r2 = r2_score(train_true.flatten(), train_preds.flatten())\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_r2 = r2\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                epochs_no_improve = 0\n",
    "                improvement_msg = \"✓ УЛУЧШЕНИЕ\"\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                improvement_msg = f\"NO IMPROVE ({epochs_no_improve}/{patience})\"\n",
    "                \n",
    "                if epochs_no_improve >= patience:\n",
    "                    early_stop = True\n",
    "            \n",
    "            model.train()\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            if (epoch + 1) % 5 == 0 or epoch == 0 or early_stop:\n",
    "                lr = optimizer.param_groups[0]['lr']\n",
    "                print(f\"Ep {epoch+1:3d}/{epochs} | \"\n",
    "                      f\"TrL: {train_loss.item():.6f} | \"\n",
    "                      f\"VaL: {val_loss.item():.6f} | \"\n",
    "                      f\"MAE: {mae:.6f} | \"\n",
    "                      f\"R²_tr: {train_r2:7.4f} | \"\n",
    "                      f\"R²_val: {r2:7.4f} | \"\n",
    "                      f\"Dir: {direction_correct:.4f} | \"\n",
    "                      f\"LR: {lr:.6f} | {improvement_msg}\")\n",
    "        \n",
    "        if best_model_state is not None:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        \n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "        model_val_losses.append(best_val_loss.item())\n",
    "        \n",
    "        print(f\"Завершена. Best Val Loss: {best_val_loss:.6f}, Best R²: {best_r2:.4f}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # ВЫЧИСЛЯЕМ ОПТИМАЛЬНЫЕ ВЕСА\n",
    "    weights = 1.0 / np.array(model_val_losses)\n",
    "    weights = weights / weights.sum()\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ВЕСА МОДЕЛЕЙ ДЛЯ АНСАМБЛЯ:\")\n",
    "    for i, (config, weight) in enumerate(zip(model_configs, weights)):\n",
    "        print(f\"  Модель {i+1} ({config[1]}): {weight:.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    is_initialized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c01c91a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:32:28.129534Z",
     "iopub.status.busy": "2025-10-06T21:32:28.129320Z",
     "iopub.status.idle": "2025-10-06T21:32:28.135819Z",
     "shell.execute_reply": "2025-10-06T21:32:28.135263Z"
    },
    "papermill": {
     "duration": 0.010623,
     "end_time": "2025-10-06T21:32:28.136985",
     "exception": false,
     "start_time": "2025-10-06T21:32:28.126362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test, label_lags_1_batch, label_lags_2_batch, label_lags_3_batch, label_lags_4_batch):\n",
    "    global models, scaler, feature_cols, is_initialized, device\n",
    "    \n",
    "    if not is_initialized:\n",
    "        print(\"Модели не инициализированы!\")\n",
    "        return pl.DataFrame({f'target_{i}': [0.0] for i in range(NUM_TARGET_COLUMNS)})\n",
    "    \n",
    "    try:\n",
    "        test_pd = test.to_pandas()\n",
    "        \n",
    "        # Подготовка с выравниванием\n",
    "        X_test = prepare_features(test_pd)\n",
    "        X_test_scaled = scaler.transform(X_test[-1:])\n",
    "        \n",
    "        # ПЕРЕНОСИМ НА GPU\n",
    "        X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "        \n",
    "        # Ансамбль\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in models:\n",
    "                pred = model(X_test_tensor)\n",
    "                pred_cpu = pred.cpu().numpy()[0]  # ← ПЕРЕНОСИМ НА CPU\n",
    "                all_preds.append(pred_cpu)\n",
    "        \n",
    "        predictions = np.mean(all_preds, axis=0)\n",
    "        predictions = np.clip(predictions, -0.1, 0.1)\n",
    "        predictions = np.nan_to_num(predictions, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        return pl.DataFrame({f'target_{i}': [float(predictions[i])] for i in range(NUM_TARGET_COLUMNS)})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка predict: {e}\")\n",
    "        return pl.DataFrame({f'target_{i}': [0.0] for i in range(NUM_TARGET_COLUMNS)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1680e2e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:32:28.143103Z",
     "iopub.status.busy": "2025-10-06T21:32:28.142511Z",
     "iopub.status.idle": "2025-10-06T21:32:28.149221Z",
     "shell.execute_reply": "2025-10-06T21:32:28.148615Z"
    },
    "papermill": {
     "duration": 0.010662,
     "end_time": "2025-10-06T21:32:28.150233",
     "exception": false,
     "start_time": "2025-10-06T21:32:28.139571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_submission_file():\n",
    "    global models, scaler, feature_cols, is_initialized, device\n",
    "    \n",
    "    print(\"\\nСоздание submission.parquet...\")\n",
    "    \n",
    "    if not is_initialized:\n",
    "        raise Exception(\"Модели не инициализированы!\")\n",
    "    \n",
    "    test = pd.read_csv('/home/nicolaedrabcinski/sd_kaggle/data/raw/test.csv')\n",
    "    \n",
    "    # Подготовка фичей\n",
    "    X_test = prepare_features(test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # ПЕРЕНОСИМ ДАННЫЕ НА GPU\n",
    "    X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "    \n",
    "    print(\"Генерация предсказаний на GPU...\")\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for i, model in enumerate(models):\n",
    "            print(f\"   Модель {i+1}/{len(models)}...\")\n",
    "            pred = model(X_test_tensor)\n",
    "            pred_cpu = pred.cpu().numpy()  # ← ПЕРЕНОСИМ ОБРАТНО НА CPU\n",
    "            all_preds.append(pred_cpu)\n",
    "    \n",
    "    predictions = np.mean(all_preds, axis=0)\n",
    "    predictions = np.clip(predictions, -0.1, 0.1)\n",
    "    predictions = np.nan_to_num(predictions, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    submission = pd.DataFrame({'date_id': test['date_id'].values})\n",
    "    for i in range(424):\n",
    "        submission[f'target_{i}'] = predictions[:, i]\n",
    "    \n",
    "    if 'is_scored' in test.columns:\n",
    "        submission = submission[test['is_scored'] == True].reset_index(drop=True)\n",
    "    \n",
    "    submission = submission.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    submission.to_parquet('submission.parquet', index=False, engine='pyarrow')\n",
    "    \n",
    "    print(f\"Готово: {submission.shape}\")\n",
    "    \n",
    "    # Очищаем GPU память\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646050f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:32:28.156126Z",
     "iopub.status.busy": "2025-10-06T21:32:28.155921Z",
     "iopub.status.idle": "2025-10-06T21:33:22.623540Z",
     "shell.execute_reply": "2025-10-06T21:33:22.622607Z"
    },
    "papermill": {
     "duration": 54.471936,
     "end_time": "2025-10-06T21:33:22.624976",
     "exception": false,
     "start_time": "2025-10-06T21:32:28.153040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЗАПУСК ПАЙПЛАЙНА\n",
      "==================================================\n",
      "======================================================================\n",
      "ИНИЦИАЛИЗАЦИЯ И ОБУЧЕНИЕ МОДЕЛЕЙ НА cuda\n",
      "======================================================================\n",
      "\n",
      "Базовых колонок: 557\n",
      "Создание признаков...\n",
      "Создано 26179 признаков\n",
      "Train: 1764, Validation: 197\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 1/7: Deep+LayerNorm\n",
      "======================================================================\n",
      "Ep   1/800 | TrL: 0.022790 | VaL: 0.005886 | MAE: 0.087069 | R²_tr: -48.6976 | R²_val: -15.4246 | Dir: 0.4418 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep   5/800 | TrL: 0.001885 | VaL: 0.001689 | MAE: 0.049009 | R²_tr: -3.1109 | R²_val: -3.7131 | Dir: 0.4432 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  10/800 | TrL: 0.001660 | VaL: 0.001528 | MAE: 0.046240 | R²_tr: -2.6208 | R²_val: -3.2641 | Dir: 0.4431 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  15/800 | TrL: 0.001499 | VaL: 0.001367 | MAE: 0.043282 | R²_tr: -2.2677 | R²_val: -2.8154 | Dir: 0.4433 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  20/800 | TrL: 0.001346 | VaL: 0.001217 | MAE: 0.040348 | R²_tr: -1.9351 | R²_val: -2.3967 | Dir: 0.4430 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  25/800 | TrL: 0.001207 | VaL: 0.001082 | MAE: 0.037546 | R²_tr: -1.6329 | R²_val: -2.0190 | Dir: 0.4435 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  30/800 | TrL: 0.001085 | VaL: 0.000962 | MAE: 0.034937 | R²_tr: -1.3659 | R²_val: -1.6859 | Dir: 0.4447 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  35/800 | TrL: 0.000978 | VaL: 0.000859 | MAE: 0.032550 | R²_tr: -1.1329 | R²_val: -1.3970 | Dir: 0.4450 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  40/800 | TrL: 0.000887 | VaL: 0.000770 | MAE: 0.030392 | R²_tr: -0.9332 | R²_val: -1.1496 | Dir: 0.4449 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  45/800 | TrL: 0.000809 | VaL: 0.000695 | MAE: 0.028464 | R²_tr: -0.7643 | R²_val: -0.9400 | Dir: 0.4450 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  50/800 | TrL: 0.000744 | VaL: 0.000632 | MAE: 0.026757 | R²_tr: -0.6215 | R²_val: -0.7641 | Dir: 0.4450 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  55/800 | TrL: 0.000689 | VaL: 0.000580 | MAE: 0.025260 | R²_tr: -0.5026 | R²_val: -0.6175 | Dir: 0.4450 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  60/800 | TrL: 0.000644 | VaL: 0.000536 | MAE: 0.023953 | R²_tr: -0.4047 | R²_val: -0.4962 | Dir: 0.4454 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  65/800 | TrL: 0.000607 | VaL: 0.000500 | MAE: 0.022825 | R²_tr: -0.3237 | R²_val: -0.3965 | Dir: 0.4455 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  70/800 | TrL: 0.000576 | VaL: 0.000471 | MAE: 0.021859 | R²_tr: -0.2570 | R²_val: -0.3151 | Dir: 0.4470 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  75/800 | TrL: 0.000552 | VaL: 0.000448 | MAE: 0.021037 | R²_tr: -0.2033 | R²_val: -0.2489 | Dir: 0.4482 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  80/800 | TrL: 0.000532 | VaL: 0.000428 | MAE: 0.020343 | R²_tr: -0.1598 | R²_val: -0.1956 | Dir: 0.4485 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  85/800 | TrL: 0.000516 | VaL: 0.000413 | MAE: 0.019761 | R²_tr: -0.1248 | R²_val: -0.1528 | Dir: 0.4494 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  90/800 | TrL: 0.000503 | VaL: 0.000401 | MAE: 0.019276 | R²_tr: -0.0972 | R²_val: -0.1187 | Dir: 0.4501 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  95/800 | TrL: 0.000493 | VaL: 0.000391 | MAE: 0.018876 | R²_tr: -0.0751 | R²_val: -0.0917 | Dir: 0.4497 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 100/800 | TrL: 0.000485 | VaL: 0.000384 | MAE: 0.018544 | R²_tr: -0.0577 | R²_val: -0.0704 | Dir: 0.4491 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 105/800 | TrL: 0.000479 | VaL: 0.000378 | MAE: 0.018274 | R²_tr: -0.0441 | R²_val: -0.0537 | Dir: 0.4500 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 110/800 | TrL: 0.000474 | VaL: 0.000373 | MAE: 0.018055 | R²_tr: -0.0335 | R²_val: -0.0407 | Dir: 0.4496 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 115/800 | TrL: 0.000470 | VaL: 0.000369 | MAE: 0.017879 | R²_tr: -0.0254 | R²_val: -0.0307 | Dir: 0.4501 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 120/800 | TrL: 0.000467 | VaL: 0.000367 | MAE: 0.017739 | R²_tr: -0.0189 | R²_val: -0.0229 | Dir: 0.4505 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 125/800 | TrL: 0.000465 | VaL: 0.000364 | MAE: 0.017628 | R²_tr: -0.0141 | R²_val: -0.0170 | Dir: 0.4507 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 130/800 | TrL: 0.000463 | VaL: 0.000363 | MAE: 0.017539 | R²_tr: -0.0103 | R²_val: -0.0125 | Dir: 0.4512 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 135/800 | TrL: 0.000462 | VaL: 0.000362 | MAE: 0.017469 | R²_tr: -0.0075 | R²_val: -0.0090 | Dir: 0.4515 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 140/800 | TrL: 0.000461 | VaL: 0.000361 | MAE: 0.017414 | R²_tr: -0.0054 | R²_val: -0.0065 | Dir: 0.4521 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 145/800 | TrL: 0.000460 | VaL: 0.000360 | MAE: 0.017370 | R²_tr: -0.0038 | R²_val: -0.0045 | Dir: 0.4521 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 150/800 | TrL: 0.000460 | VaL: 0.000359 | MAE: 0.017336 | R²_tr: -0.0026 | R²_val: -0.0031 | Dir: 0.4535 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 155/800 | TrL: 0.000459 | VaL: 0.000359 | MAE: 0.017309 | R²_tr: -0.0020 | R²_val: -0.0020 | Dir: 0.4539 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 160/800 | TrL: 0.000459 | VaL: 0.000359 | MAE: 0.017288 | R²_tr: -0.0010 | R²_val: -0.0012 | Dir: 0.4553 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 165/800 | TrL: 0.000459 | VaL: 0.000359 | MAE: 0.017272 | R²_tr: -0.0007 | R²_val: -0.0006 | Dir: 0.4550 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 170/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017260 | R²_tr: -0.0002 | R²_val: -0.0002 | Dir: 0.4549 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 175/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017251 | R²_tr:  0.0001 | R²_val:  0.0002 | Dir: 0.4546 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 180/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017244 | R²_tr:  0.0003 | R²_val:  0.0004 | Dir: 0.4553 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 185/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017238 | R²_tr:  0.0004 | R²_val:  0.0006 | Dir: 0.4554 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 190/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017234 | R²_tr:  0.0005 | R²_val:  0.0007 | Dir: 0.4557 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 195/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017231 | R²_tr:  0.0006 | R²_val:  0.0008 | Dir: 0.4557 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 200/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0008 | Dir: 0.4555 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 205/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017229 | R²_tr:  0.0007 | R²_val:  0.0008 | Dir: 0.4558 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 210/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4558 | LR: 0.000250 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 215/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4558 | LR: 0.000125 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 220/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4558 | LR: 0.000063 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 225/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4558 | LR: 0.000031 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 230/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4558 | LR: 0.000016 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 235/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4559 | LR: 0.000016 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 240/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4559 | LR: 0.000008 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 245/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4559 | LR: 0.000004 | NO IMPROVE (1/15)\n",
      "Ep 250/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4559 | LR: 0.000002 | NO IMPROVE (3/15)\n",
      "Ep 255/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4559 | LR: 0.000001 | NO IMPROVE (2/15)\n",
      "Ep 260/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4559 | LR: 0.000000 | NO IMPROVE (7/15)\n",
      "Ep 265/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4559 | LR: 0.000000 | NO IMPROVE (12/15)\n",
      "Ep 268/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4559 | LR: 0.000000 | NO IMPROVE (15/15)\n",
      "Early stopping на эпохе 269\n",
      "Завершена. Best Val Loss: 0.000358, Best R²: 0.0009\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 2/7: Wide+Skip\n",
      "======================================================================\n",
      "Ep   1/800 | TrL: 0.149266 | VaL: 5.427085 | MAE: 5.908045 | R²_tr: -343.8604 | R²_val: -81068.1641 | Dir: 0.4385 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep   5/800 | TrL: 1.118279 | VaL: 1.658961 | MAE: 2.106934 | R²_tr: -4871.5972 | R²_val: -9986.0527 | Dir: 0.4409 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  10/800 | TrL: 0.424841 | VaL: 0.936084 | MAE: 1.354485 | R²_tr: -1228.5902 | R²_val: -4286.1743 | Dir: 0.4438 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  15/800 | TrL: 0.245085 | VaL: 0.497007 | MAE: 0.873233 | R²_tr: -633.6782 | R²_val: -1821.7101 | Dir: 0.4409 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  20/800 | TrL: 0.161039 | VaL: 0.352836 | MAE: 0.704510 | R²_tr: -402.5441 | R²_val: -1176.2197 | Dir: 0.4422 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  25/800 | TrL: 0.092315 | VaL: 0.235829 | MAE: 0.556184 | R²_tr: -226.5482 | R²_val: -724.4940 | Dir: 0.4465 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  30/800 | TrL: 0.060813 | VaL: 0.203086 | MAE: 0.512552 | R²_tr: -147.3860 | R²_val: -607.5927 | Dir: 0.4445 | LR: 0.001000 | NO IMPROVE (1/15)\n",
      "Ep  35/800 | TrL: 0.057611 | VaL: 0.176986 | MAE: 0.476302 | R²_tr: -140.0954 | R²_val: -518.3328 | Dir: 0.4437 | LR: 0.001000 | NO IMPROVE (4/15)\n",
      "Ep  40/800 | TrL: 0.040187 | VaL: 0.150308 | MAE: 0.436070 | R²_tr: -99.8288 | R²_val: -433.5455 | Dir: 0.4461 | LR: 0.001000 | NO IMPROVE (2/15)\n",
      "Ep  45/800 | TrL: 0.032112 | VaL: 0.118938 | MAE: 0.387535 | R²_tr: -81.1012 | R²_val: -337.8222 | Dir: 0.4417 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  50/800 | TrL: 0.034056 | VaL: 0.123025 | MAE: 0.392708 | R²_tr: -86.6239 | R²_val: -349.9700 | Dir: 0.4436 | LR: 0.001000 | NO IMPROVE (4/15)\n",
      "Ep  55/800 | TrL: 0.027875 | VaL: 0.103799 | MAE: 0.359822 | R²_tr: -71.4520 | R²_val: -292.1675 | Dir: 0.4433 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  60/800 | TrL: 0.031248 | VaL: 0.112768 | MAE: 0.370462 | R²_tr: -78.9977 | R²_val: -319.4554 | Dir: 0.4434 | LR: 0.001000 | NO IMPROVE (5/15)\n",
      "Ep  65/800 | TrL: 0.015172 | VaL: 0.097706 | MAE: 0.349155 | R²_tr: -41.0961 | R²_val: -274.1480 | Dir: 0.4432 | LR: 0.000500 | NO IMPROVE (1/15)\n",
      "Ep  70/800 | TrL: 0.016250 | VaL: 0.084615 | MAE: 0.324920 | R²_tr: -42.7218 | R²_val: -236.3994 | Dir: 0.4436 | LR: 0.000250 | NO IMPROVE (6/15)\n",
      "Ep  75/800 | TrL: 0.012843 | VaL: 0.073137 | MAE: 0.300569 | R²_tr: -34.8964 | R²_val: -203.7640 | Dir: 0.4426 | LR: 0.000250 | NO IMPROVE (1/15)\n",
      "Ep  80/800 | TrL: 0.011878 | VaL: 0.070086 | MAE: 0.291927 | R²_tr: -32.6156 | R²_val: -195.2823 | Dir: 0.4421 | LR: 0.000250 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  85/800 | TrL: 0.010622 | VaL: 0.069347 | MAE: 0.290054 | R²_tr: -29.5050 | R²_val: -193.2117 | Dir: 0.4438 | LR: 0.000250 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  90/800 | TrL: 0.010909 | VaL: 0.070648 | MAE: 0.293382 | R²_tr: -31.2964 | R²_val: -196.8474 | Dir: 0.4429 | LR: 0.000250 | NO IMPROVE (4/15)\n",
      "Ep  95/800 | TrL: 0.010580 | VaL: 0.069637 | MAE: 0.292159 | R²_tr: -30.1279 | R²_val: -193.9083 | Dir: 0.4432 | LR: 0.000250 | NO IMPROVE (3/15)\n",
      "Ep 100/800 | TrL: 0.010514 | VaL: 0.068230 | MAE: 0.289129 | R²_tr: -30.6310 | R²_val: -190.0012 | Dir: 0.4429 | LR: 0.000250 | NO IMPROVE (1/15)\n",
      "Ep 105/800 | TrL: 0.010287 | VaL: 0.066184 | MAE: 0.284924 | R²_tr: -29.4290 | R²_val: -184.1433 | Dir: 0.4428 | LR: 0.000250 | NO IMPROVE (1/15)\n",
      "Ep 110/800 | TrL: 0.009863 | VaL: 0.066135 | MAE: 0.284537 | R²_tr: -27.5659 | R²_val: -183.9700 | Dir: 0.4428 | LR: 0.000250 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 115/800 | TrL: 0.009795 | VaL: 0.065854 | MAE: 0.283820 | R²_tr: -28.2222 | R²_val: -183.2700 | Dir: 0.4429 | LR: 0.000250 | NO IMPROVE (4/15)\n",
      "Ep 120/800 | TrL: 0.009834 | VaL: 0.064135 | MAE: 0.280578 | R²_tr: -28.0254 | R²_val: -178.2956 | Dir: 0.4431 | LR: 0.000250 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 125/800 | TrL: 0.009999 | VaL: 0.064996 | MAE: 0.282026 | R²_tr: -29.2018 | R²_val: -180.8295 | Dir: 0.4438 | LR: 0.000250 | NO IMPROVE (5/15)\n",
      "Ep 130/800 | TrL: 0.009168 | VaL: 0.063796 | MAE: 0.279542 | R²_tr: -26.3798 | R²_val: -177.4778 | Dir: 0.4436 | LR: 0.000125 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 135/800 | TrL: 0.009470 | VaL: 0.063260 | MAE: 0.277987 | R²_tr: -27.0067 | R²_val: -175.8702 | Dir: 0.4432 | LR: 0.000125 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 140/800 | TrL: 0.009461 | VaL: 0.062958 | MAE: 0.277394 | R²_tr: -28.1945 | R²_val: -175.0709 | Dir: 0.4429 | LR: 0.000125 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 145/800 | TrL: 0.009279 | VaL: 0.063417 | MAE: 0.278898 | R²_tr: -26.1779 | R²_val: -176.3301 | Dir: 0.4427 | LR: 0.000125 | NO IMPROVE (3/15)\n",
      "Ep 150/800 | TrL: 0.009087 | VaL: 0.062136 | MAE: 0.275301 | R²_tr: -25.7391 | R²_val: -172.7531 | Dir: 0.4436 | LR: 0.000063 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 155/800 | TrL: 0.008793 | VaL: 0.062500 | MAE: 0.276536 | R²_tr: -24.8934 | R²_val: -173.7439 | Dir: 0.4435 | LR: 0.000063 | NO IMPROVE (4/15)\n",
      "Ep 160/800 | TrL: 0.008924 | VaL: 0.062318 | MAE: 0.275981 | R²_tr: -25.6791 | R²_val: -173.2424 | Dir: 0.4434 | LR: 0.000031 | NO IMPROVE (9/15)\n",
      "Ep 165/800 | TrL: 0.009272 | VaL: 0.062078 | MAE: 0.275675 | R²_tr: -27.3244 | R²_val: -172.5767 | Dir: 0.4429 | LR: 0.000016 | NO IMPROVE (14/15)\n",
      "Ep 166/800 | TrL: 0.008788 | VaL: 0.062061 | MAE: 0.275666 | R²_tr: -25.2046 | R²_val: -172.5292 | Dir: 0.4428 | LR: 0.000016 | NO IMPROVE (15/15)\n",
      "Early stopping на эпохе 167\n",
      "Завершена. Best Val Loss: 0.062035, Best R²: -172.4597\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 3/7: Residual+PreAct\n",
      "======================================================================\n",
      "Ep   1/800 | TrL: 0.014326 | VaL: 0.675374 | MAE: 1.074735 | R²_tr: -30.3000 | R²_val: -2635.4351 | Dir: 0.4395 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep   5/800 | TrL: 0.001212 | VaL: 0.001316 | MAE: 0.040365 | R²_tr: -1.6434 | R²_val: -2.6731 | Dir: 0.4456 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  10/800 | TrL: 0.000926 | VaL: 0.000813 | MAE: 0.031735 | R²_tr: -1.0190 | R²_val: -1.2691 | Dir: 0.4434 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  15/800 | TrL: 0.000807 | VaL: 0.000775 | MAE: 0.030364 | R²_tr: -0.7603 | R²_val: -1.1615 | Dir: 0.4430 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  20/800 | TrL: 0.000699 | VaL: 0.000598 | MAE: 0.025802 | R²_tr: -0.5235 | R²_val: -0.6687 | Dir: 0.4434 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  25/800 | TrL: 0.000611 | VaL: 0.000549 | MAE: 0.024348 | R²_tr: -0.3321 | R²_val: -0.5329 | Dir: 0.4428 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  30/800 | TrL: 0.000552 | VaL: 0.000450 | MAE: 0.021108 | R²_tr: -0.2040 | R²_val: -0.2565 | Dir: 0.4439 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  35/800 | TrL: 0.000514 | VaL: 0.000411 | MAE: 0.019663 | R²_tr: -0.1216 | R²_val: -0.1465 | Dir: 0.4452 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  40/800 | TrL: 0.000494 | VaL: 0.000392 | MAE: 0.018960 | R²_tr: -0.0767 | R²_val: -0.0940 | Dir: 0.4436 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  45/800 | TrL: 0.000481 | VaL: 0.000379 | MAE: 0.018434 | R²_tr: -0.0484 | R²_val: -0.0590 | Dir: 0.4408 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  50/800 | TrL: 0.000474 | VaL: 0.000371 | MAE: 0.018045 | R²_tr: -0.0335 | R²_val: -0.0356 | Dir: 0.4452 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  55/800 | TrL: 0.000470 | VaL: 0.000371 | MAE: 0.018082 | R²_tr: -0.0245 | R²_val: -0.0350 | Dir: 0.4452 | LR: 0.001000 | NO IMPROVE (3/15)\n",
      "Ep  60/800 | TrL: 0.000467 | VaL: 0.000366 | MAE: 0.017779 | R²_tr: -0.0184 | R²_val: -0.0202 | Dir: 0.4448 | LR: 0.001000 | NO IMPROVE (1/15)\n",
      "Ep  65/800 | TrL: 0.000465 | VaL: 0.000363 | MAE: 0.017589 | R²_tr: -0.0144 | R²_val: -0.0116 | Dir: 0.4452 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  70/800 | TrL: 0.000464 | VaL: 0.000361 | MAE: 0.017480 | R²_tr: -0.0117 | R²_val: -0.0078 | Dir: 0.4470 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  75/800 | TrL: 0.000463 | VaL: 0.000362 | MAE: 0.017595 | R²_tr: -0.0095 | R²_val: -0.0109 | Dir: 0.4452 | LR: 0.001000 | NO IMPROVE (4/15)\n",
      "Ep  80/800 | TrL: 0.000462 | VaL: 0.000361 | MAE: 0.017472 | R²_tr: -0.0072 | R²_val: -0.0062 | Dir: 0.4477 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  85/800 | TrL: 0.000462 | VaL: 0.000363 | MAE: 0.017613 | R²_tr: -0.0064 | R²_val: -0.0119 | Dir: 0.4472 | LR: 0.000500 | NO IMPROVE (4/15)\n",
      "Ep  90/800 | TrL: 0.000461 | VaL: 0.000361 | MAE: 0.017496 | R²_tr: -0.0056 | R²_val: -0.0069 | Dir: 0.4473 | LR: 0.000250 | NO IMPROVE (9/15)\n",
      "Ep  95/800 | TrL: 0.000461 | VaL: 0.000360 | MAE: 0.017437 | R²_tr: -0.0062 | R²_val: -0.0044 | Dir: 0.4484 | LR: 0.000250 | NO IMPROVE (1/15)\n",
      "Ep 100/800 | TrL: 0.000461 | VaL: 0.000362 | MAE: 0.017538 | R²_tr: -0.0059 | R²_val: -0.0089 | Dir: 0.4480 | LR: 0.000125 | NO IMPROVE (6/15)\n",
      "Ep 105/800 | TrL: 0.000461 | VaL: 0.000361 | MAE: 0.017523 | R²_tr: -0.0051 | R²_val: -0.0083 | Dir: 0.4480 | LR: 0.000125 | NO IMPROVE (11/15)\n",
      "Ep 109/800 | TrL: 0.000461 | VaL: 0.000361 | MAE: 0.017488 | R²_tr: -0.0052 | R²_val: -0.0068 | Dir: 0.4477 | LR: 0.000063 | NO IMPROVE (15/15)\n",
      "Early stopping на эпохе 110\n",
      "Завершена. Best Val Loss: 0.000360, Best R²: -0.0042\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 4/7: DeepWide+Parallel\n",
      "======================================================================\n",
      "Ep   1/800 | TrL: 0.003890 | VaL: 0.180929 | MAE: 0.481319 | R²_tr: -7.4835 | R²_val: -531.3306 | Dir: 0.4426 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep   5/800 | TrL: 0.005980 | VaL: 0.002754 | MAE: 0.058183 | R²_tr: -12.0417 | R²_val: -6.6849 | Dir: 0.4404 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  10/800 | TrL: 0.001753 | VaL: 0.001449 | MAE: 0.044652 | R²_tr: -2.8232 | R²_val: -3.0446 | Dir: 0.4424 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  15/800 | TrL: 0.001450 | VaL: 0.001308 | MAE: 0.042105 | R²_tr: -2.1621 | R²_val: -2.6514 | Dir: 0.4427 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  20/800 | TrL: 0.001304 | VaL: 0.001175 | MAE: 0.039489 | R²_tr: -1.8436 | R²_val: -2.2780 | Dir: 0.4427 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  25/800 | TrL: 0.001177 | VaL: 0.001050 | MAE: 0.036907 | R²_tr: -1.5676 | R²_val: -1.9310 | Dir: 0.4431 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  30/800 | TrL: 0.001063 | VaL: 0.000939 | MAE: 0.034452 | R²_tr: -1.3181 | R²_val: -1.6196 | Dir: 0.4431 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  35/800 | TrL: 0.000962 | VaL: 0.000841 | MAE: 0.032179 | R²_tr: -1.0987 | R²_val: -1.3467 | Dir: 0.4436 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  40/800 | TrL: 0.000875 | VaL: 0.000757 | MAE: 0.030116 | R²_tr: -0.9091 | R²_val: -1.1118 | Dir: 0.4439 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  45/800 | TrL: 0.000801 | VaL: 0.000685 | MAE: 0.028268 | R²_tr: -0.7476 | R²_val: -0.9122 | Dir: 0.4439 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  50/800 | TrL: 0.000739 | VaL: 0.000625 | MAE: 0.026634 | R²_tr: -0.6114 | R²_val: -0.7443 | Dir: 0.4444 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  55/800 | TrL: 0.000687 | VaL: 0.000575 | MAE: 0.025199 | R²_tr: -0.4976 | R²_val: -0.6043 | Dir: 0.4449 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  60/800 | TrL: 0.000643 | VaL: 0.000533 | MAE: 0.023946 | R²_tr: -0.4030 | R²_val: -0.4882 | Dir: 0.4443 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  65/800 | TrL: 0.000608 | VaL: 0.000499 | MAE: 0.022862 | R²_tr: -0.3249 | R²_val: -0.3926 | Dir: 0.4447 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  70/800 | TrL: 0.000578 | VaL: 0.000471 | MAE: 0.021929 | R²_tr: -0.2608 | R²_val: -0.3142 | Dir: 0.4456 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  75/800 | TrL: 0.000554 | VaL: 0.000448 | MAE: 0.021130 | R²_tr: -0.2084 | R²_val: -0.2502 | Dir: 0.4480 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  80/800 | TrL: 0.000535 | VaL: 0.000429 | MAE: 0.020452 | R²_tr: -0.1657 | R²_val: -0.1984 | Dir: 0.4487 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  85/800 | TrL: 0.000519 | VaL: 0.000414 | MAE: 0.019881 | R²_tr: -0.1312 | R²_val: -0.1565 | Dir: 0.4481 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  90/800 | TrL: 0.000506 | VaL: 0.000402 | MAE: 0.019402 | R²_tr: -0.1034 | R²_val: -0.1229 | Dir: 0.4484 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  95/800 | TrL: 0.000496 | VaL: 0.000393 | MAE: 0.019003 | R²_tr: -0.0812 | R²_val: -0.0961 | Dir: 0.4503 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 100/800 | TrL: 0.000488 | VaL: 0.000385 | MAE: 0.018671 | R²_tr: -0.0634 | R²_val: -0.0747 | Dir: 0.4507 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 105/800 | TrL: 0.000481 | VaL: 0.000379 | MAE: 0.018396 | R²_tr: -0.0493 | R²_val: -0.0578 | Dir: 0.4508 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 110/800 | TrL: 0.000476 | VaL: 0.000374 | MAE: 0.018170 | R²_tr: -0.0385 | R²_val: -0.0445 | Dir: 0.4518 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 115/800 | TrL: 0.000472 | VaL: 0.000371 | MAE: 0.017986 | R²_tr: -0.0293 | R²_val: -0.0341 | Dir: 0.4515 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 120/800 | TrL: 0.000469 | VaL: 0.000368 | MAE: 0.017835 | R²_tr: -0.0225 | R²_val: -0.0259 | Dir: 0.4509 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 125/800 | TrL: 0.000466 | VaL: 0.000365 | MAE: 0.017712 | R²_tr: -0.0171 | R²_val: -0.0196 | Dir: 0.4511 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 130/800 | TrL: 0.000464 | VaL: 0.000364 | MAE: 0.017612 | R²_tr: -0.0129 | R²_val: -0.0147 | Dir: 0.4506 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 135/800 | TrL: 0.000463 | VaL: 0.000362 | MAE: 0.017532 | R²_tr: -0.0097 | R²_val: -0.0109 | Dir: 0.4507 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 140/800 | TrL: 0.000462 | VaL: 0.000361 | MAE: 0.017468 | R²_tr: -0.0072 | R²_val: -0.0080 | Dir: 0.4511 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 145/800 | TrL: 0.000461 | VaL: 0.000360 | MAE: 0.017416 | R²_tr: -0.0052 | R²_val: -0.0057 | Dir: 0.4515 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 150/800 | TrL: 0.000460 | VaL: 0.000360 | MAE: 0.017375 | R²_tr: -0.0038 | R²_val: -0.0040 | Dir: 0.4518 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 155/800 | TrL: 0.000460 | VaL: 0.000359 | MAE: 0.017342 | R²_tr: -0.0027 | R²_val: -0.0027 | Dir: 0.4517 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 160/800 | TrL: 0.000459 | VaL: 0.000359 | MAE: 0.017315 | R²_tr: -0.0018 | R²_val: -0.0018 | Dir: 0.4519 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 165/800 | TrL: 0.000459 | VaL: 0.000359 | MAE: 0.017294 | R²_tr: -0.0012 | R²_val: -0.0011 | Dir: 0.4532 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 170/800 | TrL: 0.000459 | VaL: 0.000359 | MAE: 0.017277 | R²_tr: -0.0007 | R²_val: -0.0005 | Dir: 0.4535 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 175/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017265 | R²_tr: -0.0003 | R²_val: -0.0001 | Dir: 0.4537 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 180/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017255 | R²_tr: -0.0000 | R²_val:  0.0002 | Dir: 0.4535 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 185/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017247 | R²_tr:  0.0002 | R²_val:  0.0004 | Dir: 0.4533 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 190/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017242 | R²_tr:  0.0004 | R²_val:  0.0006 | Dir: 0.4542 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 195/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017238 | R²_tr:  0.0005 | R²_val:  0.0007 | Dir: 0.4543 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 200/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017234 | R²_tr:  0.0005 | R²_val:  0.0008 | Dir: 0.4545 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 205/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017232 | R²_tr:  0.0006 | R²_val:  0.0008 | Dir: 0.4541 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 210/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017231 | R²_tr:  0.0006 | R²_val:  0.0009 | Dir: 0.4540 | LR: 0.000250 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 215/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017231 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000125 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 220/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017231 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000125 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 225/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000063 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 230/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000031 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 235/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000016 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 240/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000008 | NO IMPROVE (1/15)\n",
      "Ep 245/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000004 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 250/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000004 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 255/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000002 | NO IMPROVE (5/15)\n",
      "Ep 260/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000001 | NO IMPROVE (3/15)\n",
      "Ep 265/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000000 | NO IMPROVE (8/15)\n",
      "Ep 270/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000000 | NO IMPROVE (13/15)\n",
      "Ep 275/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000000 | NO IMPROVE (4/15)\n",
      "Ep 280/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000000 | NO IMPROVE (9/15)\n",
      "Ep 285/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000000 | NO IMPROVE (14/15)\n",
      "Ep 286/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0007 | R²_val:  0.0009 | Dir: 0.4545 | LR: 0.000000 | NO IMPROVE (15/15)\n",
      "Early stopping на эпохе 287\n",
      "Завершена. Best Val Loss: 0.000358, Best R²: 0.0009\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 5/7: Bottleneck+Attention\n",
      "======================================================================\n",
      "Ep   1/800 | TrL: 0.090700 | VaL: 0.000896 | MAE: 0.033450 | R²_tr: -216.4552 | R²_val: -1.4991 | Dir: 0.4417 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep   5/800 | TrL: 0.021312 | VaL: 0.000855 | MAE: 0.032169 | R²_tr: -73.5412 | R²_val: -1.3859 | Dir: 0.4443 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  10/800 | TrL: 0.010835 | VaL: 0.000873 | MAE: 0.032392 | R²_tr: -33.3210 | R²_val: -1.4355 | Dir: 0.4425 | LR: 0.001000 | NO IMPROVE (4/15)\n",
      "Ep  15/800 | TrL: 0.007658 | VaL: 0.000869 | MAE: 0.032206 | R²_tr: -22.8080 | R²_val: -1.4261 | Dir: 0.4435 | LR: 0.000500 | NO IMPROVE (9/15)\n",
      "Ep  20/800 | TrL: 0.006244 | VaL: 0.000792 | MAE: 0.030061 | R²_tr: -17.2065 | R²_val: -1.2112 | Dir: 0.4431 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  25/800 | TrL: 0.005610 | VaL: 0.000663 | MAE: 0.027030 | R²_tr: -16.3126 | R²_val: -0.8502 | Dir: 0.4408 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  30/800 | TrL: 0.005358 | VaL: 0.000557 | MAE: 0.024427 | R²_tr: -15.2242 | R²_val: -0.5542 | Dir: 0.4437 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  35/800 | TrL: 0.004921 | VaL: 0.000491 | MAE: 0.022609 | R²_tr: -14.7479 | R²_val: -0.3707 | Dir: 0.4436 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  40/800 | TrL: 0.005161 | VaL: 0.000457 | MAE: 0.021523 | R²_tr: -15.0084 | R²_val: -0.2756 | Dir: 0.4423 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  45/800 | TrL: 0.003799 | VaL: 0.000438 | MAE: 0.020815 | R²_tr: -10.8005 | R²_val: -0.2215 | Dir: 0.4453 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  50/800 | TrL: 0.003904 | VaL: 0.000429 | MAE: 0.020483 | R²_tr: -11.3473 | R²_val: -0.1973 | Dir: 0.4449 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  55/800 | TrL: 0.004100 | VaL: 0.000426 | MAE: 0.020382 | R²_tr: -13.7359 | R²_val: -0.1901 | Dir: 0.4448 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  60/800 | TrL: 0.003679 | VaL: 0.000419 | MAE: 0.020041 | R²_tr: -11.0888 | R²_val: -0.1683 | Dir: 0.4449 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  65/800 | TrL: 0.002654 | VaL: 0.000415 | MAE: 0.019898 | R²_tr: -11.5064 | R²_val: -0.1588 | Dir: 0.4438 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  70/800 | TrL: 0.003644 | VaL: 0.000417 | MAE: 0.019973 | R²_tr: -11.8774 | R²_val: -0.1639 | Dir: 0.4446 | LR: 0.000500 | NO IMPROVE (2/15)\n",
      "Ep  75/800 | TrL: 0.003284 | VaL: 0.000426 | MAE: 0.020333 | R²_tr: -12.5455 | R²_val: -0.1890 | Dir: 0.4450 | LR: 0.000250 | NO IMPROVE (7/15)\n",
      "Ep  80/800 | TrL: 0.002933 | VaL: 0.000435 | MAE: 0.020643 | R²_tr: -11.1828 | R²_val: -0.2143 | Dir: 0.4448 | LR: 0.000125 | NO IMPROVE (12/15)\n",
      "Ep  83/800 | TrL: 0.003391 | VaL: 0.000445 | MAE: 0.021032 | R²_tr: -10.4792 | R²_val: -0.2432 | Dir: 0.4441 | LR: 0.000125 | NO IMPROVE (15/15)\n",
      "Early stopping на эпохе 84\n",
      "Завершена. Best Val Loss: 0.000415, Best R²: -0.1581\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 6/7: Transformer\n",
      "======================================================================\n",
      "Ep   1/800 | TrL: 0.032541 | VaL: 0.071237 | MAE: 0.301981 | R²_tr: -69.9628 | R²_val: -197.9676 | Dir: 0.4454 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep   5/800 | TrL: 0.001133 | VaL: 0.000953 | MAE: 0.035090 | R²_tr: -1.4700 | R²_val: -1.6597 | Dir: 0.4426 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  10/800 | TrL: 0.000983 | VaL: 0.000871 | MAE: 0.033222 | R²_tr: -1.1434 | R²_val: -1.4313 | Dir: 0.4427 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  15/800 | TrL: 0.000899 | VaL: 0.000786 | MAE: 0.031123 | R²_tr: -0.9594 | R²_val: -1.1939 | Dir: 0.4430 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  20/800 | TrL: 0.000818 | VaL: 0.000706 | MAE: 0.029027 | R²_tr: -0.7833 | R²_val: -0.9709 | Dir: 0.4431 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  25/800 | TrL: 0.000746 | VaL: 0.000636 | MAE: 0.027060 | R²_tr: -0.6263 | R²_val: -0.7739 | Dir: 0.4437 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  30/800 | TrL: 0.000684 | VaL: 0.000576 | MAE: 0.025290 | R²_tr: -0.4921 | R²_val: -0.6066 | Dir: 0.4431 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  35/800 | TrL: 0.000633 | VaL: 0.000526 | MAE: 0.023743 | R²_tr: -0.3812 | R²_val: -0.4689 | Dir: 0.4424 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  40/800 | TrL: 0.000592 | VaL: 0.000487 | MAE: 0.022429 | R²_tr: -0.2918 | R²_val: -0.3583 | Dir: 0.4431 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  45/800 | TrL: 0.000560 | VaL: 0.000455 | MAE: 0.021339 | R²_tr: -0.2213 | R²_val: -0.2711 | Dir: 0.4421 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  50/800 | TrL: 0.000535 | VaL: 0.000431 | MAE: 0.020450 | R²_tr: -0.1664 | R²_val: -0.2033 | Dir: 0.4444 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  55/800 | TrL: 0.000516 | VaL: 0.000413 | MAE: 0.019731 | R²_tr: -0.1241 | R²_val: -0.1513 | Dir: 0.4455 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  60/800 | TrL: 0.000501 | VaL: 0.000398 | MAE: 0.019156 | R²_tr: -0.0921 | R²_val: -0.1118 | Dir: 0.4460 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  65/800 | TrL: 0.000490 | VaL: 0.000388 | MAE: 0.018701 | R²_tr: -0.0679 | R²_val: -0.0821 | Dir: 0.4463 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  70/800 | TrL: 0.000481 | VaL: 0.000380 | MAE: 0.018348 | R²_tr: -0.0498 | R²_val: -0.0598 | Dir: 0.4503 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  75/800 | TrL: 0.000475 | VaL: 0.000374 | MAE: 0.018078 | R²_tr: -0.0363 | R²_val: -0.0433 | Dir: 0.4520 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  80/800 | TrL: 0.000471 | VaL: 0.000369 | MAE: 0.017870 | R²_tr: -0.0264 | R²_val: -0.0311 | Dir: 0.4518 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  85/800 | TrL: 0.000467 | VaL: 0.000366 | MAE: 0.017713 | R²_tr: -0.0190 | R²_val: -0.0221 | Dir: 0.4536 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  90/800 | TrL: 0.000465 | VaL: 0.000364 | MAE: 0.017593 | R²_tr: -0.0137 | R²_val: -0.0156 | Dir: 0.4525 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  95/800 | TrL: 0.000463 | VaL: 0.000362 | MAE: 0.017501 | R²_tr: -0.0098 | R²_val: -0.0109 | Dir: 0.4517 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 100/800 | TrL: 0.000462 | VaL: 0.000361 | MAE: 0.017432 | R²_tr: -0.0069 | R²_val: -0.0075 | Dir: 0.4525 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 105/800 | TrL: 0.000461 | VaL: 0.000360 | MAE: 0.017380 | R²_tr: -0.0048 | R²_val: -0.0050 | Dir: 0.4536 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 110/800 | TrL: 0.000460 | VaL: 0.000359 | MAE: 0.017342 | R²_tr: -0.0033 | R²_val: -0.0032 | Dir: 0.4538 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 115/800 | TrL: 0.000460 | VaL: 0.000359 | MAE: 0.017313 | R²_tr: -0.0022 | R²_val: -0.0019 | Dir: 0.4542 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 120/800 | TrL: 0.000459 | VaL: 0.000359 | MAE: 0.017291 | R²_tr: -0.0014 | R²_val: -0.0010 | Dir: 0.4551 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 125/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017274 | R²_tr: -0.0008 | R²_val: -0.0003 | Dir: 0.4565 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 130/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017262 | R²_tr: -0.0004 | R²_val:  0.0001 | Dir: 0.4569 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 135/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017252 | R²_tr: -0.0001 | R²_val:  0.0005 | Dir: 0.4571 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 140/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017245 | R²_tr:  0.0001 | R²_val:  0.0007 | Dir: 0.4574 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 145/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017239 | R²_tr:  0.0003 | R²_val:  0.0009 | Dir: 0.4569 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 150/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017235 | R²_tr:  0.0005 | R²_val:  0.0010 | Dir: 0.4572 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 155/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017232 | R²_tr:  0.0005 | R²_val:  0.0011 | Dir: 0.4569 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 160/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0011 | Dir: 0.4566 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 165/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017229 | R²_tr:  0.0006 | R²_val:  0.0011 | Dir: 0.4562 | LR: 0.000250 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 170/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000250 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 175/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000125 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 180/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000063 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 185/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000031 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 190/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000016 | NO IMPROVE (1/15)\n",
      "Ep 195/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000008 | NO IMPROVE (2/15)\n",
      "Ep 200/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000008 | NO IMPROVE (3/15)\n",
      "Ep 205/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000004 | NO IMPROVE (4/15)\n",
      "Ep 210/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000002 | NO IMPROVE (3/15)\n",
      "Ep 215/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000001 | NO IMPROVE (8/15)\n",
      "Ep 220/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000000 | NO IMPROVE (13/15)\n",
      "Ep 222/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017228 | R²_tr:  0.0007 | R²_val:  0.0011 | Dir: 0.4561 | LR: 0.000000 | NO IMPROVE (15/15)\n",
      "Early stopping на эпохе 223\n",
      "Завершена. Best Val Loss: 0.000358, Best R²: 0.0011\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 7/7: EnsembleBlock+Gating\n",
      "======================================================================\n",
      "Ep   1/800 | TrL: 0.002529 | VaL: 0.296232 | MAE: 0.637347 | R²_tr: -4.5138 | R²_val: -920.0535 | Dir: 0.4385 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep   5/800 | TrL: 0.004898 | VaL: 0.003704 | MAE: 0.061427 | R²_tr: -9.8527 | R²_val: -9.3364 | Dir: 0.4397 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  10/800 | TrL: 0.001582 | VaL: 0.001451 | MAE: 0.044824 | R²_tr: -2.4490 | R²_val: -3.0491 | Dir: 0.4410 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  15/800 | TrL: 0.001447 | VaL: 0.001322 | MAE: 0.042452 | R²_tr: -2.1561 | R²_val: -2.6893 | Dir: 0.4412 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  20/800 | TrL: 0.001318 | VaL: 0.001193 | MAE: 0.039943 | R²_tr: -1.8731 | R²_val: -2.3302 | Dir: 0.4414 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  25/800 | TrL: 0.001195 | VaL: 0.001072 | MAE: 0.037436 | R²_tr: -1.6050 | R²_val: -1.9916 | Dir: 0.4412 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  30/800 | TrL: 0.001082 | VaL: 0.000962 | MAE: 0.035021 | R²_tr: -1.3594 | R²_val: -1.6832 | Dir: 0.4409 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  35/800 | TrL: 0.000981 | VaL: 0.000863 | MAE: 0.032754 | R²_tr: -1.1401 | R²_val: -1.4089 | Dir: 0.4413 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  40/800 | TrL: 0.000893 | VaL: 0.000777 | MAE: 0.030664 | R²_tr: -0.9481 | R²_val: -1.1695 | Dir: 0.4412 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  45/800 | TrL: 0.000817 | VaL: 0.000704 | MAE: 0.028771 | R²_tr: -0.7825 | R²_val: -0.9636 | Dir: 0.4412 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  50/800 | TrL: 0.000753 | VaL: 0.000641 | MAE: 0.027074 | R²_tr: -0.6415 | R²_val: -0.7887 | Dir: 0.4422 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  55/800 | TrL: 0.000698 | VaL: 0.000588 | MAE: 0.025570 | R²_tr: -0.5227 | R²_val: -0.6415 | Dir: 0.4421 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  60/800 | TrL: 0.000653 | VaL: 0.000544 | MAE: 0.024252 | R²_tr: -0.4235 | R²_val: -0.5188 | Dir: 0.4433 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  65/800 | TrL: 0.000615 | VaL: 0.000508 | MAE: 0.023108 | R²_tr: -0.3413 | R²_val: -0.4173 | Dir: 0.4436 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  70/800 | TrL: 0.000584 | VaL: 0.000478 | MAE: 0.022124 | R²_tr: -0.2736 | R²_val: -0.3338 | Dir: 0.4439 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  75/800 | TrL: 0.000559 | VaL: 0.000454 | MAE: 0.021283 | R²_tr: -0.2183 | R²_val: -0.2656 | Dir: 0.4443 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  80/800 | TrL: 0.000538 | VaL: 0.000434 | MAE: 0.020568 | R²_tr: -0.1733 | R²_val: -0.2103 | Dir: 0.4449 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  85/800 | TrL: 0.000521 | VaL: 0.000418 | MAE: 0.019965 | R²_tr: -0.1370 | R²_val: -0.1656 | Dir: 0.4446 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  90/800 | TrL: 0.000508 | VaL: 0.000405 | MAE: 0.019459 | R²_tr: -0.1077 | R²_val: -0.1297 | Dir: 0.4453 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep  95/800 | TrL: 0.000497 | VaL: 0.000395 | MAE: 0.019037 | R²_tr: -0.0843 | R²_val: -0.1011 | Dir: 0.4456 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 100/800 | TrL: 0.000489 | VaL: 0.000386 | MAE: 0.018688 | R²_tr: -0.0657 | R²_val: -0.0783 | Dir: 0.4466 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 105/800 | TrL: 0.000482 | VaL: 0.000380 | MAE: 0.018401 | R²_tr: -0.0510 | R²_val: -0.0604 | Dir: 0.4469 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 110/800 | TrL: 0.000477 | VaL: 0.000375 | MAE: 0.018167 | R²_tr: -0.0394 | R²_val: -0.0462 | Dir: 0.4480 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 115/800 | TrL: 0.000472 | VaL: 0.000371 | MAE: 0.017976 | R²_tr: -0.0303 | R²_val: -0.0352 | Dir: 0.4485 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 120/800 | TrL: 0.000469 | VaL: 0.000368 | MAE: 0.017822 | R²_tr: -0.0231 | R²_val: -0.0266 | Dir: 0.4484 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 125/800 | TrL: 0.000467 | VaL: 0.000365 | MAE: 0.017698 | R²_tr: -0.0176 | R²_val: -0.0199 | Dir: 0.4506 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 130/800 | TrL: 0.000465 | VaL: 0.000364 | MAE: 0.017599 | R²_tr: -0.0133 | R²_val: -0.0148 | Dir: 0.4506 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 135/800 | TrL: 0.000463 | VaL: 0.000362 | MAE: 0.017519 | R²_tr: -0.0100 | R²_val: -0.0109 | Dir: 0.4505 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 140/800 | TrL: 0.000462 | VaL: 0.000361 | MAE: 0.017456 | R²_tr: -0.0074 | R²_val: -0.0079 | Dir: 0.4507 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 145/800 | TrL: 0.000461 | VaL: 0.000360 | MAE: 0.017405 | R²_tr: -0.0054 | R²_val: -0.0056 | Dir: 0.4513 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 150/800 | TrL: 0.000460 | VaL: 0.000360 | MAE: 0.017365 | R²_tr: -0.0039 | R²_val: -0.0039 | Dir: 0.4519 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 155/800 | TrL: 0.000460 | VaL: 0.000359 | MAE: 0.017333 | R²_tr: -0.0028 | R²_val: -0.0026 | Dir: 0.4524 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 160/800 | TrL: 0.000459 | VaL: 0.000359 | MAE: 0.017309 | R²_tr: -0.0019 | R²_val: -0.0016 | Dir: 0.4531 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 165/800 | TrL: 0.000459 | VaL: 0.000359 | MAE: 0.017289 | R²_tr: -0.0012 | R²_val: -0.0009 | Dir: 0.4532 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 170/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017274 | R²_tr: -0.0007 | R²_val: -0.0003 | Dir: 0.4533 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 175/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017263 | R²_tr: -0.0003 | R²_val:  0.0001 | Dir: 0.4539 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 180/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017253 | R²_tr: -0.0001 | R²_val:  0.0004 | Dir: 0.4538 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 185/800 | TrL: 0.000459 | VaL: 0.000358 | MAE: 0.017246 | R²_tr:  0.0002 | R²_val:  0.0006 | Dir: 0.4539 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 190/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017241 | R²_tr:  0.0003 | R²_val:  0.0007 | Dir: 0.4541 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 195/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017236 | R²_tr:  0.0004 | R²_val:  0.0008 | Dir: 0.4543 | LR: 0.001000 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 200/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017233 | R²_tr:  0.0005 | R²_val:  0.0009 | Dir: 0.4547 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 205/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017231 | R²_tr:  0.0006 | R²_val:  0.0009 | Dir: 0.4547 | LR: 0.000500 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 210/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0009 | Dir: 0.4550 | LR: 0.000250 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 215/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000125 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 220/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000063 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 225/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000063 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 230/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000031 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 235/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000016 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 240/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000008 | NO IMPROVE (1/15)\n",
      "Ep 245/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000004 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 250/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000002 | ✓ УЛУЧШЕНИЕ\n",
      "Ep 255/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000002 | NO IMPROVE (5/15)\n",
      "Ep 260/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000001 | NO IMPROVE (4/15)\n",
      "Ep 265/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000000 | NO IMPROVE (9/15)\n",
      "Ep 270/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000000 | NO IMPROVE (14/15)\n",
      "Ep 271/800 | TrL: 0.000458 | VaL: 0.000358 | MAE: 0.017230 | R²_tr:  0.0006 | R²_val:  0.0010 | Dir: 0.4550 | LR: 0.000000 | NO IMPROVE (15/15)\n",
      "Early stopping на эпохе 272\n",
      "Завершена. Best Val Loss: 0.000358, Best R²: 0.0010\n",
      "\n",
      "======================================================================\n",
      "ВЕСА МОДЕЛЕЙ ДЛЯ АНСАМБЛЯ:\n",
      "  Модель 1 (Deep+LayerNorm): 0.1705\n",
      "  Модель 2 (Wide+Skip): 0.0010\n",
      "  Модель 3 (Residual+PreAct): 0.1697\n",
      "  Модель 4 (DeepWide+Parallel): 0.1705\n",
      "  Модель 5 (Bottleneck+Attention): 0.1471\n",
      "  Модель 6 (Transformer): 0.1706\n",
      "  Модель 7 (EnsembleBlock+Gating): 0.1706\n",
      "======================================================================\n",
      "\n",
      "Создание submission файла...\n",
      "\n",
      "Создание submission.parquet...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global is_initialized\n",
    "    \n",
    "    print(\"ЗАПУСК ПАЙПЛАЙНА\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # # Шаг 1: Инициализация и обучение моделей ОДИН РАЗ\n",
    "    # if not is_initialized:\n",
    "    #     print(\"Начало обучения моделей...\")\n",
    "\n",
    "    initialize_models()\n",
    "    # else:\n",
    "    #     print(\"Модели уже инициализированы, пропускаем обучение\")\n",
    "    \n",
    "    # Шаг 2: Создание submission файла\n",
    "    print(\"Создание submission файла...\")\n",
    "    create_submission_file()\n",
    "    \n",
    "# Запускаем основной пайплайн\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13613251,
     "sourceId": 94771,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "sd_kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 68.220891,
   "end_time": "2025-10-06T21:33:25.209067",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-06T21:32:16.988176",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
