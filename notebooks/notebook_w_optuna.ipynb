{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9a2040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется устройство: cuda\n",
      "Доступно GPU: 1\n",
      "Название GPU: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 1: Импорты и настройка\n",
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import warnings\n",
    "import gc\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.stats import spearmanr\n",
    "import joblib\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import plotly.express as px\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используется устройство: {device}\")\n",
    "print(f\"Доступно GPU: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Название GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "NUM_TARGET_COLUMNS = 424\n",
    "\n",
    "# Глобальные переменные\n",
    "models = []\n",
    "scaler = None\n",
    "feature_selector = None\n",
    "feature_cols = None\n",
    "base_cols = None\n",
    "is_initialized = False\n",
    "model_val_scores = []\n",
    "ensemble_weights_global = None\n",
    "best_hyperparams = {}\n",
    "optuna_studies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1726eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 2: Аугментация данных\n",
    "class TimeSeriesAugmentation:\n",
    "    \"\"\"Продвинутая аугментация для финансовых временных рядов\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_gaussian_noise(features, noise_level=0.01):\n",
    "        \"\"\"Добавление гауссовского шума\"\"\"\n",
    "        noise = torch.randn_like(features) * noise_level\n",
    "        return features + noise\n",
    "    \n",
    "    @staticmethod\n",
    "    def time_warp(features, warp_factor=0.1):\n",
    "        \"\"\"Временное искажение - сдвиг признаков во времени\"\"\"\n",
    "        batch_size, seq_len = features.shape\n",
    "        warp_strength = torch.randn(batch_size, 1, device=features.device) * warp_factor\n",
    "        warped_indices = torch.arange(seq_len, device=features.device).float() + warp_strength\n",
    "        warped_indices = torch.clamp(warped_indices, 0, seq_len-1)\n",
    "        \n",
    "        # Интерполяция\n",
    "        warped_features = torch.zeros_like(features)\n",
    "        for i in range(batch_size):\n",
    "            warped_features[i] = torch.interp(\n",
    "                torch.arange(seq_len, device=features.device).float(),\n",
    "                warped_indices[i],\n",
    "                features[i]\n",
    "            )\n",
    "        return warped_features\n",
    "    \n",
    "    @staticmethod\n",
    "    def feature_dropout(features, drop_prob=0.1):\n",
    "        \"\"\"Случайное обнуление признаков (как dropout но для фичей)\"\"\"\n",
    "        mask = torch.rand_like(features) > drop_prob\n",
    "        return features * mask.float()\n",
    "    \n",
    "    @staticmethod\n",
    "    def scaling_augmentation(features, scale_range=(0.9, 1.1)):\n",
    "        \"\"\"Случайное масштабирование признаков\"\"\"\n",
    "        scale_factors = torch.rand(features.shape[0], 1, device=features.device) * (scale_range[1] - scale_range[0]) + scale_range[0]\n",
    "        return features * scale_factors\n",
    "    \n",
    "    @staticmethod\n",
    "    def jittering(features, jitter_strength=0.02):\n",
    "        \"\"\"Дрожание - случайные небольшие изменения\"\"\"\n",
    "        jitter = (torch.rand_like(features) - 0.5) * 2 * jitter_strength\n",
    "        return features + jitter\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_permutation(features, permute_fraction=0.1):\n",
    "        \"\"\"Случайная перестановка небольшой части признаков\"\"\"\n",
    "        batch_size, num_features = features.shape\n",
    "        num_to_permute = int(num_features * permute_fraction)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            perm_indices = torch.randperm(num_features)[:num_to_permute]\n",
    "            features[i, perm_indices] = features[i, perm_indices[torch.randperm(num_to_permute)]]\n",
    "        \n",
    "        return features\n",
    "\n",
    "def advanced_augmentation(features, augmentation_methods=None, augmentation_prob=0.7):\n",
    "    \"\"\"Продвинутая аугментация с комбинацией методов\"\"\"\n",
    "    if augmentation_methods is None:\n",
    "        augmentation_methods = [\n",
    "            ('noise', 0.3),\n",
    "            ('scaling', 0.2), \n",
    "            ('jitter', 0.2),\n",
    "            ('dropout', 0.2),\n",
    "            ('permutation', 0.1)\n",
    "        ]\n",
    "    \n",
    "    augmented_features = features.clone()\n",
    "    \n",
    "    # Применяем аугментации с вероятностью\n",
    "    if torch.rand(1).item() < augmentation_prob:\n",
    "        for method, prob in augmentation_methods:\n",
    "            if torch.rand(1).item() < prob:\n",
    "                if method == 'noise':\n",
    "                    augmented_features = TimeSeriesAugmentation.add_gaussian_noise(augmented_features, 0.01)\n",
    "                elif method == 'scaling':\n",
    "                    augmented_features = TimeSeriesAugmentation.scaling_augmentation(augmented_features)\n",
    "                elif method == 'jitter':\n",
    "                    augmented_features = TimeSeriesAugmentation.jittering(augmented_features)\n",
    "                elif method == 'dropout':\n",
    "                    augmented_features = TimeSeriesAugmentation.feature_dropout(augmented_features, 0.05)\n",
    "                elif method == 'permutation':\n",
    "                    augmented_features = TimeSeriesAugmentation.random_permutation(augmented_features, 0.05)\n",
    "    \n",
    "    return augmented_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f916bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 3: Функции потерь\n",
    "class PearsonCorrelationLoss(nn.Module):\n",
    "    \"\"\"Loss функция для оптимизации Pearson Correlation\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Для каждого target отдельно\n",
    "        batch_size = pred.shape[0]\n",
    "        num_targets = pred.shape[1]\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for i in range(num_targets):\n",
    "            pred_col = pred[:, i]\n",
    "            target_col = target[:, i]\n",
    "            \n",
    "            # Центрируем\n",
    "            pred_centered = pred_col - pred_col.mean()\n",
    "            target_centered = target_col - target_col.mean()\n",
    "            \n",
    "            # Ковариация\n",
    "            covariance = (pred_centered * target_centered).mean()\n",
    "            \n",
    "            # Стандартные отклонения\n",
    "            pred_std = pred_centered.std()\n",
    "            target_std = target_centered.std()\n",
    "            \n",
    "            # Pearson correlation\n",
    "            if pred_std > 1e-8 and target_std > 1e-8:\n",
    "                correlation = covariance / (pred_std * target_std)\n",
    "                # Минимизируем отрицательную корреляцию\n",
    "                total_loss += -correlation\n",
    "            else:\n",
    "                # Штраф за константные предсказания\n",
    "                total_loss += 1.0\n",
    "        \n",
    "        return total_loss / num_targets\n",
    "\n",
    "\n",
    "class SpearmanLoss(nn.Module):\n",
    "    \"\"\"Approximation of Spearman correlation loss\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Используем ранжирование через сортировку\n",
    "        pred_rank = torch.argsort(torch.argsort(pred, dim=0), dim=0).float()\n",
    "        target_rank = torch.argsort(torch.argsort(target, dim=0), dim=0).float()\n",
    "        \n",
    "        # Нормализуем ранги\n",
    "        pred_rank = (pred_rank - pred_rank.mean(dim=0)) / (pred_rank.std(dim=0) + 1e-8)\n",
    "        target_rank = (target_rank - target_rank.mean(dim=0)) / (target_rank.std(dim=0) + 1e-8)\n",
    "        \n",
    "        # Correlation (минимизируем отрицательную)\n",
    "        correlation = (pred_rank * target_rank).mean(dim=0).mean()\n",
    "        return -correlation\n",
    "\n",
    "\n",
    "class CombinedCorrelationLoss(nn.Module):\n",
    "    \"\"\"Комбинация Pearson + Spearman + MSE\"\"\"\n",
    "    def __init__(self, pearson_weight=0.4, spearman_weight=0.4, mse_weight=0.2):\n",
    "        super().__init__()\n",
    "        self.pearson_weight = pearson_weight\n",
    "        self.spearman_weight = spearman_weight\n",
    "        self.mse_weight = mse_weight\n",
    "        \n",
    "        self.pearson_loss = PearsonCorrelationLoss()\n",
    "        self.spearman_loss = SpearmanLoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pearson_l = self.pearson_loss(pred, target)\n",
    "        spearman_l = self.spearman_loss(pred, target)\n",
    "        mse_l = self.mse_loss(pred, target)\n",
    "        \n",
    "        total_loss = (self.pearson_weight * pearson_l + \n",
    "                     self.spearman_weight * spearman_l + \n",
    "                     self.mse_weight * mse_l)\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "class SpearmanRankCorrelationLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    ПРАВИЛЬНАЯ Spearman Correlation Loss для Mitsui Competition\n",
    "    \n",
    "    Вычисляет корреляцию рангов ПО TARGETS внутри каждого sample\n",
    "    (т.е. ранжирует 424 targets для каждого дня отдельно)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        pred, target: (batch_size, 424)\n",
    "        \n",
    "        Для каждого sample в батче:\n",
    "          - Ранжируем 424 predictions\n",
    "          - Ранжируем 424 true targets\n",
    "          - Вычисляем Spearman correlation между этими рангами\n",
    "        \"\"\"\n",
    "        batch_size = pred.shape[0]\n",
    "        num_targets = pred.shape[1]\n",
    "        \n",
    "        correlations = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Для i-го дня ранжируем все 424 targets\n",
    "            pred_sample = pred[i]  # (424,)\n",
    "            target_sample = target[i]  # (424,)\n",
    "            \n",
    "            # Получаем ранги (argsort дважды даёт ранги)\n",
    "            pred_rank = pred_sample.argsort().argsort().float()\n",
    "            target_rank = target_sample.argsort().argsort().float()\n",
    "            \n",
    "            # Нормализуем ранги\n",
    "            pred_rank = (pred_rank - pred_rank.mean()) / (pred_rank.std() + 1e-8)\n",
    "            target_rank = (target_rank - target_rank.mean()) / (target_rank.std() + 1e-8)\n",
    "            \n",
    "            # Pearson correlation на рангах = Spearman correlation\n",
    "            correlation = (pred_rank * target_rank).mean()\n",
    "            correlations.append(correlation)\n",
    "        \n",
    "        # Минимизируем отрицательную среднюю корреляцию\n",
    "        mean_correlation = torch.stack(correlations).mean()\n",
    "        \n",
    "        return -mean_correlation\n",
    "\n",
    "\n",
    "class DirectionalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Штрафует за неправильное направление (знак)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Совпадает ли знак?\n",
    "        pred_sign = torch.sign(pred)\n",
    "        target_sign = torch.sign(target)\n",
    "        direction_correct = (pred_sign == target_sign).float()\n",
    "        \n",
    "        # Штрафуем за несовпадение\n",
    "        direction_loss = 1 - direction_correct.mean()\n",
    "        \n",
    "        return direction_loss\n",
    "\n",
    "\n",
    "class MitsuiOptimizedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    ОПТИМИЗИРОВАННАЯ Loss функция для Mitsui Competition\n",
    "    \n",
    "    Комбинирует:\n",
    "    - Spearman Rank Correlation (главное!)\n",
    "    - MSE (для magnitude)\n",
    "    - Directional Loss (для знака)\n",
    "    \"\"\"\n",
    "    def __init__(self, spearman_weight=0.6, mse_weight=0.2, direction_weight=0.2):\n",
    "        super().__init__()\n",
    "        self.spearman_weight = spearman_weight\n",
    "        self.mse_weight = mse_weight\n",
    "        self.direction_weight = direction_weight\n",
    "        \n",
    "        self.spearman_loss = SpearmanRankCorrelationLoss()\n",
    "        self.directional_loss = DirectionalLoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Три компоненты\n",
    "        spearman_l = self.spearman_loss(pred, target)\n",
    "        mse_l = self.mse_loss(pred, target)\n",
    "        direction_l = self.directional_loss(pred, target)\n",
    "        \n",
    "        # Взвешенная сумма\n",
    "        total_loss = (\n",
    "            self.spearman_weight * spearman_l +\n",
    "            self.mse_weight * mse_l +\n",
    "            self.direction_weight * direction_l\n",
    "        )\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f102b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 4: Архитектуры моделей с поддержкой гиперпараметров\n",
    "class SimpleEffectiveModel_Improved(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=512, dropout_rate=0.4, num_layers=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            next_size = hidden_size // (2 ** i) if i < num_layers - 1 else output_size\n",
    "            layers.extend([\n",
    "                nn.Linear(current_size, next_size),\n",
    "                nn.BatchNorm1d(next_size) if i < num_layers - 1 else nn.Identity(),\n",
    "                nn.ReLU() if i < num_layers - 1 else nn.Identity(),\n",
    "                nn.Dropout(dropout_rate * (0.8 ** i)) if i < num_layers - 1 else nn.Identity()\n",
    "            ])\n",
    "            current_size = next_size\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class ResidualModel(nn.Module):\n",
    "    \"\"\"Модель с residual connections\"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_size=256, num_blocks=2, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        for _ in range(num_blocks):\n",
    "            self.blocks.append(nn.Sequential(\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size)\n",
    "            ))\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "            nn.Linear(hidden_size // 2, output_size)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Residual blocks\n",
    "        for block in self.blocks:\n",
    "            residual = x\n",
    "            x = block(x)\n",
    "            x = x + residual\n",
    "            x = nn.ReLU()(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        return self.output(x)\n",
    "\n",
    "class WideModel(nn.Module):\n",
    "    \"\"\"Широкая модель с большим количеством нейронов\"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_sizes=[1024, 512, 256], dropout_rates=[0.4, 0.3, 0.2]):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        \n",
    "        for i, (hidden_size, dropout_rate) in enumerate(zip(hidden_sizes, dropout_rates)):\n",
    "            layers.extend([\n",
    "                nn.Linear(current_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            current_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(current_size, output_size))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DeepSkipModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=512, num_blocks=4, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(num_blocks):\n",
    "            self.blocks.append(nn.Sequential(\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size)\n",
    "            ))\n",
    "        \n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate * 0.7)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            residual = x\n",
    "            x = block(x)\n",
    "            x = x + residual\n",
    "            x = nn.ReLU()(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        return self.output(x)\n",
    "\n",
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=512, num_heads=8, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Self-attention\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout_rate,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size * 2, hidden_size)\n",
    "        )\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Add sequence dimension for attention\n",
    "        x_seq = x.unsqueeze(1)\n",
    "        \n",
    "        # Self-attention with residual\n",
    "        attn_out, _ = self.attention(x_seq, x_seq, x_seq)\n",
    "        x = x + attn_out.squeeze(1)\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Feed-forward with residual\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = x + ffn_out\n",
    "        x = self.norm2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return self.output(x)\n",
    "\n",
    "class EnsembleInsideModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_experts=3, expert_hidden=384, gate_hidden=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_size, expert_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(expert_hidden, expert_hidden // 2)\n",
    "            ) for _ in range(num_experts)\n",
    "        ])\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(input_size, gate_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_hidden, num_experts),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(expert_hidden // 2, gate_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(gate_hidden, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gates = self.gate(x)\n",
    "        expert_outputs = [expert(x) for expert in self.experts]\n",
    "        \n",
    "        # Weighted combination\n",
    "        combined = torch.zeros_like(expert_outputs[0])\n",
    "        for i, expert_out in enumerate(expert_outputs):\n",
    "            combined += gates[:, i:i+1] * expert_out\n",
    "        \n",
    "        return self.output(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ddb6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 5: Создание признаков\n",
    "def create_optimized_features(df, base_cols_ref=None, max_features=800):\n",
    "    \"\"\"Создает оптимизированный набор признаков\"\"\"\n",
    "    features = df.copy()\n",
    "    \n",
    "    if base_cols_ref is not None:\n",
    "        numeric_cols = [c for c in base_cols_ref if c in df.columns]\n",
    "    else:\n",
    "        numeric_cols = [c for c in df.columns \n",
    "                       if c not in ['date_id', 'is_scored'] \n",
    "                       and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    \n",
    "    # Ограничиваем количество базовых колонок\n",
    "    numeric_cols = numeric_cols[:min(100, len(numeric_cols))]\n",
    "    \n",
    "    print(f\"Обрабатывается {len(numeric_cols)} базовых колонок...\")\n",
    "    \n",
    "    feature_count = 0\n",
    "    for col in numeric_cols:\n",
    "        try:\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                # Базовые returns\n",
    "                features[f'{col}_return_1d'] = df[col].pct_change(1)\n",
    "                features[f'{col}_return_5d'] = df[col].pct_change(5)\n",
    "                \n",
    "                # Скользящие статистики\n",
    "                for window in [5, 10, 20]:\n",
    "                    features[f'{col}_ma_{window}'] = df[col].rolling(window, min_periods=1).mean()\n",
    "                    features[f'{col}_std_{window}'] = df[col].rolling(window, min_periods=1).std()\n",
    "                \n",
    "                # Z-score\n",
    "                rolling_mean = df[col].rolling(20, min_periods=1).mean()\n",
    "                rolling_std = df[col].rolling(20, min_periods=1).std()\n",
    "                features[f'{col}_zscore'] = (df[col] - rolling_mean) / (rolling_std + 1e-8)\n",
    "                \n",
    "                # Lag features\n",
    "                for lag in [1, 2, 3]:\n",
    "                    features[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "                \n",
    "                # Volatility\n",
    "                features[f'{col}_volatility_20'] = df[col].rolling(20).std() / (df[col].rolling(20).mean() + 1e-8)\n",
    "                \n",
    "                feature_count += 11  # 11 features per column\n",
    "                \n",
    "                # Останавливаемся если достигли лимита\n",
    "                if feature_count >= max_features:\n",
    "                    print(f\"Достигнут лимит в {max_features} признаков\")\n",
    "                    break\n",
    "                    \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Заполняем NaN\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    # Удаляем колонки с нулевой дисперсией\n",
    "    selector = VarianceThreshold()\n",
    "    non_constant_features = selector.fit(features.select_dtypes(include=[np.number])).get_support()\n",
    "    feature_columns = features.select_dtypes(include=[np.number]).columns[non_constant_features]\n",
    "    features = features[feature_columns]\n",
    "    \n",
    "    print(f\"Создано {len(features.columns)} признаков после фильтрации\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "def select_best_features_vectorized_fixed(features, targets, n_features=500):\n",
    "    \"\"\"Исправленная векторизованная версия с обработкой NaN\"\"\"\n",
    "    import torch\n",
    "    \n",
    "    print(\"Векторизованный отбор признаков с GPU...\")\n",
    "    \n",
    "    # Фильтруем колонки\n",
    "    feature_cols = [c for c in features.columns if c not in ['date_id', 'is_scored']]\n",
    "    features_filtered = features[feature_cols]\n",
    "    \n",
    "    # Перенос на GPU\n",
    "    X = torch.tensor(features_filtered.values, dtype=torch.float32, device=device)\n",
    "    y = torch.tensor(targets.values, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Заменяем NaN и Inf на 0\n",
    "    X = torch.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    y = torch.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Центрируем данные\n",
    "    X_centered = X - X.mean(dim=0)\n",
    "    y_centered = y - y.mean(dim=0)\n",
    "    \n",
    "    # Вычисляем ковариационную матрицу\n",
    "    covariance = torch.mm(X_centered.T, y_centered) / (X.shape[0] - 1)\n",
    "    \n",
    "    # Вычисляем стандартные отклонения с защитой от деления на 0\n",
    "    x_std = X_centered.std(dim=0, unbiased=True)\n",
    "    y_std = y_centered.std(dim=0, unbiased=True)\n",
    "    \n",
    "    # Защита от нулевых стандартных отклонений\n",
    "    x_std = torch.where(x_std < 1e-8, torch.ones_like(x_std), x_std)\n",
    "    y_std = torch.where(y_std < 1e-8, torch.ones_like(y_std), y_std)\n",
    "    \n",
    "    # Вычисляем матрицу корреляций Пирсона\n",
    "    correlation_matrix = covariance / (x_std.unsqueeze(1) * y_std.unsqueeze(0))\n",
    "    \n",
    "    # Заменяем NaN в корреляциях на 0\n",
    "    correlation_matrix = torch.nan_to_num(correlation_matrix, nan=0.0)\n",
    "    \n",
    "    # Усредняем абсолютные корреляции по targets\n",
    "    feature_importances = correlation_matrix.abs().mean(dim=1)\n",
    "    \n",
    "    # Сортируем признаки по важности\n",
    "    sorted_indices = torch.argsort(feature_importances, descending=True)\n",
    "    selected_features = [feature_cols[i] for i in sorted_indices[:n_features].cpu().numpy()]\n",
    "    \n",
    "    print(f\"Отобрано {len(selected_features)} лучших признаков\")\n",
    "    if len(feature_importances) > 0:\n",
    "        best_score = feature_importances[sorted_indices[0]].item()\n",
    "        print(f\"Лучший признак: {selected_features[0]} (корреляция: {best_score:.4f})\")\n",
    "    \n",
    "    # Очистка памяти\n",
    "    del X, y, X_centered, y_centered, covariance, correlation_matrix\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76c104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 6: Функции обучения с поддержкой Optuna\n",
    "def calculate_spearman_score(predictions, targets):\n",
    "    \"\"\"Вычисляет средний Spearman correlation\"\"\"\n",
    "    correlations = []\n",
    "    \n",
    "    for i in range(targets.shape[1]):\n",
    "        pred_col = predictions[:, i]\n",
    "        target_col = targets[:, i]\n",
    "        \n",
    "        if len(np.unique(pred_col)) > 1 and len(np.unique(target_col)) > 1:\n",
    "            try:\n",
    "                corr, _ = spearmanr(pred_col, target_col)\n",
    "                if not np.isnan(corr):\n",
    "                    correlations.append(corr)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return np.mean(correlations) if correlations else 0.0\n",
    "\n",
    "def train_model_with_augmentation(model, X_train_t, y_train_t, X_val_t, y_val_t, \n",
    "                                epochs=500, patience=50, lr=0.001, model_name=\"\", \n",
    "                                use_augmentation=True, augmentation_strength=0.7,\n",
    "                                trial=None):\n",
    "    \"\"\"Функция обучения с продвинутой аугментацией и поддержкой Optuna\"\"\"\n",
    "    \n",
    "    # criterion = CombinedCorrelationLoss()\n",
    "    criterion = MitsuiOptimizedLoss(\n",
    "        spearman_weight=0.6,\n",
    "        mse_weight=0.2,\n",
    "        direction_weight=0.2\n",
    "    )\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.05)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=8, factor=0.5)\n",
    "    \n",
    "    best_val_score = -float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    if trial is None:\n",
    "        print(f\"Начало обучения {model_name} с аугментацией: {use_augmentation}\")\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if epochs_no_improve >= patience and trial is None:\n",
    "            if trial is None:\n",
    "                print(f\"Early stopping на эпохе {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        # Обучение с аугментацией\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_augmentation:\n",
    "            # Применяем аугментацию только к тренировочным данным\n",
    "            augmented_features = advanced_augmentation(X_train_t, augmentation_prob=augmentation_strength)\n",
    "            train_outputs = model(augmented_features)\n",
    "        else:\n",
    "            train_outputs = model(X_train_t)\n",
    "            \n",
    "        train_loss = criterion(train_outputs, y_train_t)\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Gradient clipping для стабильности\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Валидация (БЕЗ аугментации)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_t)\n",
    "            val_score = calculate_spearman_score(val_outputs.cpu().numpy(), y_val_t.cpu().numpy())\n",
    "            \n",
    "            train_preds = train_outputs.detach().cpu().numpy()\n",
    "            train_true = y_train_t.cpu().numpy()\n",
    "            train_score = calculate_spearman_score(train_preds, train_true)\n",
    "        \n",
    "        # Для Optuna: сообщаем промежуточное значение\n",
    "        if trial is not None:\n",
    "            trial.report(val_score, epoch)\n",
    "            \n",
    "            # Проверяем, нужно ли прервать trial\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # Обновление лучших результатов\n",
    "        if val_score > best_val_score:\n",
    "            best_val_score = val_score\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            epochs_no_improve = 0\n",
    "            improvement_msg = \"✓ УЛУЧШЕНИЕ\"\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            improvement_msg = f\"NO IMPROVE ({epochs_no_improve}/{patience})\"\n",
    "        \n",
    "        model.train()\n",
    "        scheduler.step(train_loss)\n",
    "        \n",
    "        # Логирование (только для обычного обучения, не для Optuna)\n",
    "        if trial is None and ((epoch + 1) % 10 == 0 or epoch == 0 or epochs_no_improve >= patience):\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            aug_status = \"AUG\" if use_augmentation else \"NO_AUG\"\n",
    "            print(f\"{model_name} | {aug_status} | Ep {epoch+1:3d}/{epochs} | \"\n",
    "                  f\"TrL: {train_loss.item():.6f} | \"\n",
    "                  f\"TrScore: {train_score:.4f} | \"\n",
    "                  f\"ValScore: {val_score:.4f} | \"\n",
    "                  f\"LR: {current_lr:.6f} | {improvement_msg}\")\n",
    "    \n",
    "    # Загрузка лучших весов\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    return model, best_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29a00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 7: Функции Optuna для оптимизации гиперпараметров\n",
    "def objective_simple_effective(trial, X_train_t, y_train_t, X_val_t, y_val_t):\n",
    "    \"\"\"Objective функция для SimpleEffectiveModel\"\"\"\n",
    "    \n",
    "    # Предлагаем гиперпараметры\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [256, 512, 1024])\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    num_layers = trial.suggest_int('num_layers', 3, 6)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    augmentation_strength = trial.suggest_float('augmentation_strength', 0.3, 0.9)\n",
    "    \n",
    "    # Создаем модель\n",
    "    model = SimpleEffectiveModel_Improved(\n",
    "        input_size=X_train_t.shape[1],\n",
    "        output_size=424,\n",
    "        hidden_size=hidden_size,\n",
    "        dropout_rate=dropout_rate,\n",
    "        num_layers=num_layers\n",
    "    ).to(device)\n",
    "    \n",
    "    # Обучаем модель\n",
    "    try:\n",
    "        model, val_score = train_model_with_augmentation(\n",
    "            model, X_train_t, y_train_t, X_val_t, y_val_t,\n",
    "            epochs=100,  # Меньше эпох для быстрой оптимизации\n",
    "            patience=15,\n",
    "            lr=lr,\n",
    "            model_name=f\"Optuna_SimpleEffective_{trial.number}\",\n",
    "            use_augmentation=True,\n",
    "            augmentation_strength=augmentation_strength,\n",
    "            trial=trial\n",
    "        )\n",
    "        \n",
    "        return val_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в trial {trial.number}: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def objective_residual(trial, X_train_t, y_train_t, X_val_t, y_val_t):\n",
    "    \"\"\"Objective функция для ResidualModel\"\"\"\n",
    "    \n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [128, 256, 512])\n",
    "    num_blocks = trial.suggest_int('num_blocks', 2, 5)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.4)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    model = ResidualModel(\n",
    "        input_size=X_train_t.shape[1],\n",
    "        output_size=424,\n",
    "        hidden_size=hidden_size,\n",
    "        num_blocks=num_blocks,\n",
    "        dropout_rate=dropout_rate\n",
    "    ).to(device)\n",
    "    \n",
    "    try:\n",
    "        model, val_score = train_model_with_augmentation(\n",
    "            model, X_train_t, y_train_t, X_val_t, y_val_t,\n",
    "            epochs=100,\n",
    "            patience=15,\n",
    "            lr=lr,\n",
    "            model_name=f\"Optuna_Residual_{trial.number}\",\n",
    "            use_augmentation=True,\n",
    "            augmentation_strength=0.7,\n",
    "            trial=trial\n",
    "        )\n",
    "        \n",
    "        return val_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в trial {trial.number}: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def objective_wide(trial, X_train_t, y_train_t, X_val_t, y_val_t):\n",
    "    \"\"\"Objective функция для WideModel\"\"\"\n",
    "    \n",
    "    hidden_size1 = trial.suggest_categorical('hidden_size1', [512, 1024, 2048])\n",
    "    hidden_size2 = trial.suggest_categorical('hidden_size2', [256, 512, 1024])\n",
    "    hidden_size3 = trial.suggest_categorical('hidden_size3', [128, 256, 512])\n",
    "    dropout1 = trial.suggest_float('dropout1', 0.2, 0.6)\n",
    "    dropout2 = trial.suggest_float('dropout2', 0.1, 0.5)\n",
    "    dropout3 = trial.suggest_float('dropout3', 0.1, 0.4)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    model = WideModel(\n",
    "        input_size=X_train_t.shape[1],\n",
    "        output_size=424,\n",
    "        hidden_sizes=[hidden_size1, hidden_size2, hidden_size3],\n",
    "        dropout_rates=[dropout1, dropout2, dropout3]\n",
    "    ).to(device)\n",
    "    \n",
    "    try:\n",
    "        model, val_score = train_model_with_augmentation(\n",
    "            model, X_train_t, y_train_t, X_val_t, y_val_t,\n",
    "            epochs=100,\n",
    "            patience=15,\n",
    "            lr=lr,\n",
    "            model_name=f\"Optuna_Wide_{trial.number}\",\n",
    "            use_augmentation=True,\n",
    "            augmentation_strength=0.6,\n",
    "            trial=trial\n",
    "        )\n",
    "        \n",
    "        return val_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в trial {trial.number}: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def optimize_model_with_optuna(model_type, X_train_t, y_train_t, X_val_t, y_val_t, n_trials=50):\n",
    "    \"\"\"Оптимизация гиперпараметров модели с помощью Optuna\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"OPTUNA ОПТИМИЗАЦИЯ ДЛЯ {model_type}\")\n",
    "    print(f\"Количество trials: {n_trials}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Выбираем соответствующую objective функцию\n",
    "    if model_type == \"SimpleEffective\":\n",
    "        objective_func = lambda trial: objective_simple_effective(trial, X_train_t, y_train_t, X_val_t, y_val_t)\n",
    "    elif model_type == \"Residual\":\n",
    "        objective_func = lambda trial: objective_residual(trial, X_train_t, y_train_t, X_val_t, y_val_t)\n",
    "    elif model_type == \"Wide\":\n",
    "        objective_func = lambda trial: objective_wide(trial, X_train_t, y_train_t, X_val_t, y_val_t)\n",
    "    elif model_type == \"DeepSkip\":\n",
    "        objective_func = lambda trial: objective_deep_skip(trial, X_train_t, y_train_t, X_val_t, y_val_t)\n",
    "    elif model_type == \"Attention\":\n",
    "        objective_func = lambda trial: objective_attention(trial, X_train_t, y_train_t, X_val_t, y_val_t)\n",
    "    elif model_type == \"EnsembleInside\":\n",
    "        objective_func = lambda trial: objective_ensemble_inside(trial, X_train_t, y_train_t, X_val_t, y_val_t)\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный тип модели: {model_type}\")\n",
    "    \n",
    "    # Создаем study\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        pruner=optuna.pruners.HyperbandPruner(\n",
    "            min_resource=10,\n",
    "            max_resource=100,\n",
    "            reduction_factor=3\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Запускаем оптимизацию\n",
    "    study.optimize(objective_func, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    optuna_studies[model_type] = study\n",
    "    best_hyperparams[model_type] = study.best_trial.params\n",
    "    \n",
    "    print(f\"\\nЛУЧШИЕ ГИПЕРПАРАМЕТРЫ ДЛЯ {model_type}:\")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"Лучший val_score: {study.best_value:.4f}\")\n",
    "    \n",
    "    return study.best_trial.params, study.best_value\n",
    "\n",
    "# Добавить в Ячейку 7: Функции Optuna для новых моделей\n",
    "\n",
    "def objective_deep_skip(trial, X_train_t, y_train_t, X_val_t, y_val_t):\n",
    "    \"\"\"Objective функция для DeepSkipModel\"\"\"\n",
    "    \n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [256, 512, 1024])\n",
    "    num_blocks = trial.suggest_int('num_blocks', 2, 6)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    augmentation_strength = trial.suggest_float('augmentation_strength', 0.3, 0.9)\n",
    "    \n",
    "    model = DeepSkipModel(\n",
    "        input_size=X_train_t.shape[1],\n",
    "        output_size=424,\n",
    "        hidden_size=hidden_size,\n",
    "        num_blocks=num_blocks,\n",
    "        dropout_rate=dropout_rate\n",
    "    ).to(device)\n",
    "    \n",
    "    try:\n",
    "        model, val_score = train_model_with_augmentation(\n",
    "            model, X_train_t, y_train_t, X_val_t, y_val_t,\n",
    "            epochs=100,\n",
    "            patience=15,\n",
    "            lr=lr,\n",
    "            model_name=f\"Optuna_DeepSkip_{trial.number}\",\n",
    "            use_augmentation=True,\n",
    "            augmentation_strength=augmentation_strength,\n",
    "            trial=trial\n",
    "        )\n",
    "        \n",
    "        return val_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в trial {trial.number}: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def objective_attention(trial, X_train_t, y_train_t, X_val_t, y_val_t):\n",
    "    \"\"\"Objective функция для AttentionModel\"\"\"\n",
    "    \n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [256, 512, 1024])\n",
    "    num_heads = trial.suggest_categorical('num_heads', [4, 8, 16])\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.05, 0.3)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "    augmentation_strength = trial.suggest_float('augmentation_strength', 0.3, 0.7)\n",
    "    \n",
    "    model = AttentionModel(\n",
    "        input_size=X_train_t.shape[1],\n",
    "        output_size=424,\n",
    "        hidden_size=hidden_size,\n",
    "        num_heads=num_heads,\n",
    "        dropout_rate=dropout_rate\n",
    "    ).to(device)\n",
    "    \n",
    "    try:\n",
    "        model, val_score = train_model_with_augmentation(\n",
    "            model, X_train_t, y_train_t, X_val_t, y_val_t,\n",
    "            epochs=100,\n",
    "            patience=15,\n",
    "            lr=lr,\n",
    "            model_name=f\"Optuna_Attention_{trial.number}\",\n",
    "            use_augmentation=True,\n",
    "            augmentation_strength=augmentation_strength,\n",
    "            trial=trial\n",
    "        )\n",
    "        \n",
    "        return val_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в trial {trial.number}: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def objective_ensemble_inside(trial, X_train_t, y_train_t, X_val_t, y_val_t):\n",
    "    \"\"\"Objective функция для EnsembleInsideModel\"\"\"\n",
    "    \n",
    "    num_experts = trial.suggest_int('num_experts', 2, 5)\n",
    "    expert_hidden = trial.suggest_categorical('expert_hidden', [256, 384, 512])\n",
    "    gate_hidden = trial.suggest_categorical('gate_hidden', [64, 128, 256])\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    augmentation_strength = trial.suggest_float('augmentation_strength', 0.3, 0.9)\n",
    "    \n",
    "    model = EnsembleInsideModel(\n",
    "        input_size=X_train_t.shape[1],\n",
    "        output_size=424,\n",
    "        num_experts=num_experts,\n",
    "        expert_hidden=expert_hidden,\n",
    "        gate_hidden=gate_hidden\n",
    "    ).to(device)\n",
    "    \n",
    "    try:\n",
    "        model, val_score = train_model_with_augmentation(\n",
    "            model, X_train_t, y_train_t, X_val_t, y_val_t,\n",
    "            epochs=100,\n",
    "            patience=15,\n",
    "            lr=lr,\n",
    "            model_name=f\"Optuna_EnsembleInside_{trial.number}\",\n",
    "            use_augmentation=True,\n",
    "            augmentation_strength=augmentation_strength,\n",
    "            trial=trial\n",
    "        )\n",
    "        \n",
    "        return val_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в trial {trial.number}: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6799398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 8: Инициализация моделей с Optuna (ИСПРАВЛЕННАЯ)\n",
    "def initialize_models_with_optuna(use_optuna=True, optuna_trials=30):\n",
    "    global models, scaler, feature_cols, base_cols, model_val_scores, is_initialized, device\n",
    "    global best_hyperparams, optuna_studies\n",
    "    \n",
    "    if is_initialized:\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"ИНИЦИАЛИЗАЦИЯ ВСЕХ 6 МОДЕЛЕЙ С OPTUNA ОПТИМИЗАЦИЕЙ НА {device}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Загрузка данных\n",
    "    train = pd.read_csv('/home/nicolaedrabcinski/sd_kaggle/data/raw/train.csv')\n",
    "    train_labels = pd.read_csv('/home/nicolaedrabcinski/sd_kaggle/data/raw/train_labels.csv')\n",
    "    \n",
    "    # Базовые колонки\n",
    "    base_cols = [c for c in train.columns \n",
    "                 if c not in ['date_id'] \n",
    "                 and pd.api.types.is_numeric_dtype(train[c])]\n",
    "    \n",
    "    print(f\"Базовых колонок: {len(base_cols)}\")\n",
    "    print(\"Создание оптимизированных признаков...\")\n",
    "    \n",
    "    # Создание признаков\n",
    "    train_features = create_optimized_features(train, base_cols_ref=base_cols, max_features=800)\n",
    "    \n",
    "    # Выбор лучших признаков\n",
    "    target_cols = [f'target_{i}' for i in range(424)]\n",
    "    selected_features = select_best_features_vectorized_fixed(train_features, train_labels[target_cols], n_features=500)\n",
    "    \n",
    "    feature_cols = selected_features\n",
    "    \n",
    "    # Подготовка данных\n",
    "    X_train = train_features[feature_cols].fillna(0).values\n",
    "    y_train = train_labels[target_cols].fillna(0).values\n",
    "    \n",
    "    X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    y_train = np.nan_to_num(y_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Масштабирование\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Перенос на GPU\n",
    "    X_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "    y_tensor = torch.FloatTensor(y_train).to(device)\n",
    "    \n",
    "    # Разделение на train/validation\n",
    "    split_idx = int(len(X_train_scaled) * 0.85)\n",
    "    X_train_t, X_val_t = X_tensor[:split_idx], X_tensor[split_idx:]\n",
    "    y_train_t, y_val_t = y_tensor[:split_idx], y_tensor[split_idx:]\n",
    "    \n",
    "    print(f\"Train: {len(X_train_t)}, Validation: {len(X_val_t)}\")\n",
    "    \n",
    "    if use_optuna:\n",
    "        # Оптимизация гиперпараметров для ВСЕХ 6 моделей\n",
    "        models_to_optimize = [\"SimpleEffective\", \"Residual\", \"Wide\", \"DeepSkip\", \"Attention\", \"EnsembleInside\"]\n",
    "        \n",
    "        for model_type in models_to_optimize:\n",
    "            try:\n",
    "                best_params, best_score = optimize_model_with_optuna(\n",
    "                    model_type, X_train_t, y_train_t, X_val_t, y_val_t, n_trials=optuna_trials\n",
    "                )\n",
    "                print(f\"✅ {model_type} оптимизирована. Best score: {best_score:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Ошибка оптимизации {model_type}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Конфигурация ВСЕХ 6 моделей с оптимизированными гиперпараметрами\n",
    "    model_configs = []\n",
    "    \n",
    "    # SimpleEffective с оптимизированными параметрами\n",
    "    if \"SimpleEffective\" in best_hyperparams:\n",
    "        params = best_hyperparams[\"SimpleEffective\"]\n",
    "        model_configs.append(\n",
    "            (SimpleEffectiveModel_Improved, \"SimpleEffective_Optuna\", params.get('lr', 0.001), \n",
    "             True, params.get('augmentation_strength', 0.7), params)\n",
    "        )\n",
    "    else:\n",
    "        model_configs.append(\n",
    "            (SimpleEffectiveModel_Improved, \"SimpleEffective_Default\", 0.001, True, 0.7, {})\n",
    "        )\n",
    "    \n",
    "    # Residual с оптимизированными параметрами\n",
    "    if \"Residual\" in best_hyperparams:\n",
    "        params = best_hyperparams[\"Residual\"]\n",
    "        model_configs.append(\n",
    "            (ResidualModel, \"Residual_Optuna\", params.get('lr', 0.001), \n",
    "             True, 0.7, params)\n",
    "        )\n",
    "    else:\n",
    "        model_configs.append(\n",
    "            (ResidualModel, \"Residual_Default\", 0.001, True, 0.7, {})\n",
    "        )\n",
    "    \n",
    "    # Wide с оптимизированными параметрами\n",
    "    if \"Wide\" in best_hyperparams:\n",
    "        params = best_hyperparams[\"Wide\"]\n",
    "        model_configs.append(\n",
    "            (WideModel, \"Wide_Optuna\", params.get('lr', 0.0005), \n",
    "             True, 0.6, params)\n",
    "        )\n",
    "    else:\n",
    "        model_configs.append(\n",
    "            (WideModel, \"Wide_Default\", 0.0005, True, 0.6, {})\n",
    "        )\n",
    "    \n",
    "    # DeepSkip с оптимизированными параметрами\n",
    "    if \"DeepSkip\" in best_hyperparams:\n",
    "        params = best_hyperparams[\"DeepSkip\"]\n",
    "        model_configs.append(\n",
    "            (DeepSkipModel, \"DeepSkip_Optuna\", params.get('lr', 0.001), \n",
    "             True, 0.7, params)\n",
    "        )\n",
    "    else:\n",
    "        model_configs.append(\n",
    "            (DeepSkipModel, \"DeepSkip_Default\", 0.001, True, 0.7, {})\n",
    "        )\n",
    "    \n",
    "    # Attention с оптимизированными параметрами\n",
    "    if \"Attention\" in best_hyperparams:\n",
    "        params = best_hyperparams[\"Attention\"]\n",
    "        model_configs.append(\n",
    "            (AttentionModel, \"Attention_Optuna\", params.get('lr', 0.0008), \n",
    "             True, 0.5, params)\n",
    "        )\n",
    "    else:\n",
    "        model_configs.append(\n",
    "            (AttentionModel, \"Attention_Default\", 0.0008, True, 0.5, {})\n",
    "        )\n",
    "    \n",
    "    # EnsembleInside с оптимизированными параметрами\n",
    "    if \"EnsembleInside\" in best_hyperparams:\n",
    "        params = best_hyperparams[\"EnsembleInside\"]\n",
    "        model_configs.append(\n",
    "            (EnsembleInsideModel, \"EnsembleInside_Optuna\", params.get('lr', 0.001), \n",
    "             True, 0.7, params)\n",
    "        )\n",
    "    else:\n",
    "        model_configs.append(\n",
    "            (EnsembleInsideModel, \"EnsembleInside_Default\", 0.001, True, 0.7, {})\n",
    "        )\n",
    "    \n",
    "    # Обучение всех 6 моделей\n",
    "    for i, (ModelClass, name, lr, use_aug, aug_strength, hyperparams) in enumerate(model_configs):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"МОДЕЛЬ {i+1}/{len(model_configs)}: {name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        try:\n",
    "            # Создание модели с гиперпараметрами\n",
    "            if \"Optuna\" in name:\n",
    "                print(\"Используются оптимизированные гиперпараметры:\")\n",
    "                for key, value in hyperparams.items():\n",
    "                    print(f\"  {key}: {value}\")\n",
    "            \n",
    "            if name == \"SimpleEffective_Optuna\":\n",
    "                model = ModelClass(\n",
    "                    X_train_scaled.shape[1], 424,\n",
    "                    hidden_size=hyperparams.get('hidden_size', 512),\n",
    "                    dropout_rate=hyperparams.get('dropout_rate', 0.4),\n",
    "                    num_layers=hyperparams.get('num_layers', 4)\n",
    "                ).to(device)\n",
    "            elif name == \"Residual_Optuna\":\n",
    "                model = ModelClass(\n",
    "                    X_train_scaled.shape[1], 424,\n",
    "                    hidden_size=hyperparams.get('hidden_size', 256),\n",
    "                    num_blocks=hyperparams.get('num_blocks', 2),\n",
    "                    dropout_rate=hyperparams.get('dropout_rate', 0.2)\n",
    "                ).to(device)\n",
    "            elif name == \"Wide_Optuna\":\n",
    "                model = ModelClass(\n",
    "                    X_train_scaled.shape[1], 424,\n",
    "                    hidden_sizes=[\n",
    "                        hyperparams.get('hidden_size1', 1024),\n",
    "                        hyperparams.get('hidden_size2', 512),\n",
    "                        hyperparams.get('hidden_size3', 256)\n",
    "                    ],\n",
    "                    dropout_rates=[\n",
    "                        hyperparams.get('dropout1', 0.4),\n",
    "                        hyperparams.get('dropout2', 0.3),\n",
    "                        hyperparams.get('dropout3', 0.2)\n",
    "                    ]\n",
    "                ).to(device)\n",
    "            elif name == \"DeepSkip_Optuna\":\n",
    "                model = ModelClass(\n",
    "                    X_train_scaled.shape[1], 424,\n",
    "                    hidden_size=hyperparams.get('hidden_size', 512),\n",
    "                    num_blocks=hyperparams.get('num_blocks', 4),\n",
    "                    dropout_rate=hyperparams.get('dropout_rate', 0.3)\n",
    "                ).to(device)\n",
    "            elif name == \"Attention_Optuna\":\n",
    "                model = ModelClass(\n",
    "                    X_train_scaled.shape[1], 424,\n",
    "                    hidden_size=hyperparams.get('hidden_size', 512),\n",
    "                    num_heads=hyperparams.get('num_heads', 8),\n",
    "                    dropout_rate=hyperparams.get('dropout_rate', 0.1)\n",
    "                ).to(device)\n",
    "            elif name == \"EnsembleInside_Optuna\":\n",
    "                model = ModelClass(\n",
    "                    X_train_scaled.shape[1], 424,\n",
    "                    num_experts=hyperparams.get('num_experts', 3),\n",
    "                    expert_hidden=hyperparams.get('expert_hidden', 384),\n",
    "                    gate_hidden=hyperparams.get('gate_hidden', 128)\n",
    "                ).to(device)\n",
    "            elif name == \"Wide_Default\":\n",
    "                model = ModelClass(X_train_scaled.shape[1], 424).to(device)\n",
    "            elif name == \"Attention_Default\":\n",
    "                model = ModelClass(X_train_scaled.shape[1], 424, hidden_size=384).to(device)\n",
    "            elif name == \"DeepSkip_Default\":\n",
    "                model = ModelClass(X_train_scaled.shape[1], 424, hidden_size=512, num_blocks=5).to(device)\n",
    "            elif name == \"EnsembleInside_Default\":\n",
    "                model = ModelClass(X_train_scaled.shape[1], 424, num_experts=4).to(device)\n",
    "            else:\n",
    "                model = ModelClass(X_train_scaled.shape[1], 424, hidden_size=512).to(device)\n",
    "            \n",
    "            # Обучение\n",
    "            model, val_score = train_model_with_augmentation(\n",
    "                model, X_train_t, y_train_t, X_val_t, y_val_t, \n",
    "                epochs=200, patience=20, lr=lr, model_name=name,\n",
    "                use_augmentation=use_aug, augmentation_strength=aug_strength\n",
    "            )\n",
    "            \n",
    "            models.append(model)\n",
    "            model_val_scores.append(val_score)\n",
    "            \n",
    "            print(f\"✅ {name} завершена. Best Val Score: {val_score:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ ОШИБКА при обучении модели {name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "        \n",
    "        # Очистка GPU памяти\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Проверка что хоть что-то обучилось\n",
    "    if not models:\n",
    "        raise Exception(\"❌ НИ ОДНА МОДЕЛЬ НЕ БЫЛА УСПЕШНО ОБУЧЕНА!\")\n",
    "    \n",
    "    # Вычисление весов для ансамбля\n",
    "    weights = np.array(model_val_scores)\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ВЕСА ВСЕХ 6 МОДЕЛЕЙ С OPTUNA ОПТИМИЗАЦИЕЙ:\")\n",
    "    for i, (config, weight, val_score) in enumerate(zip(model_configs, weights, model_val_scores)):\n",
    "        if i < len(models):\n",
    "            optuna_status = \"OPTUNA\" if \"Optuna\" in config[1] else \"DEFAULT\"\n",
    "            print(f\"  Модель {i+1} ({config[1]}): вес={weight:.4f}, val_score={val_score:.4f} [{optuna_status}]\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    is_initialized = True\n",
    "    \n",
    "    # Сохранение scaler и feature_cols\n",
    "    joblib.dump(scaler, 'scaler_optuna.joblib')\n",
    "    joblib.dump(feature_cols, 'feature_cols_optuna.joblib')\n",
    "    joblib.dump(best_hyperparams, 'best_hyperparams.joblib')\n",
    "    print(\"Scaler, feature_cols и hyperparams сохранены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d75c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 9: Функции предсказания и оценки (ОБНОВЛЕННАЯ)\n",
    "def prepare_features(df):\n",
    "    global feature_cols, scaler\n",
    "    \n",
    "    # Создаем фичи тем же способом что и при обучении\n",
    "    test_features = create_optimized_features(df, base_cols_ref=base_cols, max_features=800)\n",
    "    \n",
    "    # Используем только те фичи, которые были отобраны при обучении\n",
    "    available_features = [f for f in feature_cols if f in test_features.columns]\n",
    "    \n",
    "    X_test = np.zeros((len(df), len(feature_cols)))\n",
    "    \n",
    "    for i, col in enumerate(feature_cols):\n",
    "        if col in test_features.columns:\n",
    "            X_test[:, i] = test_features[col].fillna(0).values\n",
    "    \n",
    "    X_test = np.nan_to_num(X_test, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    return X_test\n",
    "\n",
    "@torch.no_grad()\n",
    "def efficient_predict_batch(test_data, models, weights=None, batch_size=1024):\n",
    "    \"\"\"Эффективное предсказание с батчингом\"\"\"\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(models)) / len(models)\n",
    "    \n",
    "    # Если test_data уже pandas DataFrame, используем как есть\n",
    "    if hasattr(test_data, 'to_pandas'):\n",
    "        test_pd = test_data.to_pandas()\n",
    "    else:\n",
    "        test_pd = test_data\n",
    "    \n",
    "    X_test = prepare_features(test_pd)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Батчинг для больших данных\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i in range(0, len(X_test_scaled), batch_size):\n",
    "        batch = X_test_scaled[i:i+batch_size]\n",
    "        X_batch_tensor = torch.FloatTensor(batch).to(device)\n",
    "        \n",
    "        batch_preds = []\n",
    "        for model, weight in zip(models, weights):\n",
    "            pred = model(X_batch_tensor).cpu().numpy()\n",
    "            batch_preds.append(pred * weight)\n",
    "        \n",
    "        batch_ensemble = np.sum(batch_preds, axis=0)\n",
    "        \n",
    "        # Мягкое ограничение\n",
    "        batch_ensemble = np.tanh(batch_ensemble * 10) * 0.1\n",
    "        all_predictions.append(batch_ensemble)\n",
    "    \n",
    "    predictions = np.vstack(all_predictions)\n",
    "    predictions = np.nan_to_num(predictions, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def diagnose_predictions(predictions, targets):\n",
    "    \"\"\"Диагностика предсказаний для поиска проблем\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ДИАГНОСТИКА ПРЕДСКАЗАНИЙ\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nФорма данных:\")\n",
    "    print(f\"  Predictions: {predictions.shape}\")\n",
    "    print(f\"  Targets: {targets.shape}\")\n",
    "    \n",
    "    print(f\"\\nСтатистика predictions:\")\n",
    "    print(f\"  Mean:   {predictions.mean():.8f}\")\n",
    "    print(f\"  Std:    {predictions.std():.8f}\")\n",
    "    print(f\"  Min:    {predictions.min():.8f}\")\n",
    "    print(f\"  Max:    {predictions.max():.8f}\")\n",
    "    print(f\"  Median: {np.median(predictions):.8f}\")\n",
    "    \n",
    "    print(f\"\\nСтатистика targets:\")\n",
    "    print(f\"  Mean:   {targets.mean():.8f}\")\n",
    "    print(f\"  Std:    {targets.std():.8f}\")\n",
    "    print(f\"  Min:    {targets.min():.8f}\")\n",
    "    print(f\"  Max:    {targets.max():.8f}\")\n",
    "    print(f\"  Median: {np.median(targets):.8f}\")\n",
    "    \n",
    "    # Проверка на константные колонки\n",
    "    const_pred_cols = []\n",
    "    const_target_cols = []\n",
    "    \n",
    "    for i in range(predictions.shape[1]):\n",
    "        if len(np.unique(predictions[:, i])) < 2:\n",
    "            const_pred_cols.append(i)\n",
    "        if len(np.unique(targets[:, i])) < 2:\n",
    "            const_target_cols.append(i)\n",
    "    \n",
    "    if len(const_pred_cols) > 0:\n",
    "        print(f\"\\n⚠️ Константные predictions колонки: {len(const_pred_cols)}/{predictions.shape[1]}\")\n",
    "        print(f\"   Примеры индексов: {const_pred_cols[:10]}\")\n",
    "    else:\n",
    "        print(f\"\\n✅ Нет константных predictions колонок\")\n",
    "    \n",
    "    if len(const_target_cols) > 0:\n",
    "        print(f\"\\n⚠️ Константные target колонки: {len(const_target_cols)}/{targets.shape[1]}\")\n",
    "        print(f\"   Примеры индексов: {const_target_cols[:10]}\")\n",
    "    else:\n",
    "        print(f\"\\n✅ Нет константных target колонок\")\n",
    "    \n",
    "    # Проверка на NaN и Inf\n",
    "    nan_preds = np.isnan(predictions).sum()\n",
    "    inf_preds = np.isinf(predictions).sum()\n",
    "    nan_targets = np.isnan(targets).sum()\n",
    "    inf_targets = np.isinf(targets).sum()\n",
    "    \n",
    "    if nan_preds > 0 or inf_preds > 0:\n",
    "        print(f\"\\n⚠️ Predictions: NaN={nan_preds}, Inf={inf_preds}\")\n",
    "    else:\n",
    "        print(f\"\\n✅ Predictions: Нет NaN/Inf\")\n",
    "    \n",
    "    if nan_targets > 0 or inf_targets > 0:\n",
    "        print(f\"\\n⚠️ Targets: NaN={nan_targets}, Inf={inf_targets}\")\n",
    "    else:\n",
    "        print(f\"\\n✅ Targets: Нет NaN/Inf\")\n",
    "    \n",
    "    # Распределение знаков\n",
    "    pos_preds = (predictions > 0).sum()\n",
    "    neg_preds = (predictions < 0).sum()\n",
    "    zero_preds = (predictions == 0).sum()\n",
    "    \n",
    "    pos_targets = (targets > 0).sum()\n",
    "    neg_targets = (targets < 0).sum()\n",
    "    zero_targets = (targets == 0).sum()\n",
    "    \n",
    "    total = predictions.size\n",
    "    print(f\"\\nРаспределение знаков predictions:\")\n",
    "    print(f\"  Positive: {pos_preds}/{total} ({100*pos_preds/total:.1f}%)\")\n",
    "    print(f\"  Negative: {neg_preds}/{total} ({100*neg_preds/total:.1f}%)\")\n",
    "    print(f\"  Zero:     {zero_preds}/{total} ({100*zero_preds/total:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nРаспределение знаков targets:\")\n",
    "    print(f\"  Positive: {pos_targets}/{total} ({100*pos_targets/total:.1f}%)\")\n",
    "    print(f\"  Negative: {neg_targets}/{total} ({100*neg_targets/total:.1f}%)\")\n",
    "    print(f\"  Zero:     {zero_targets}/{total} ({100*zero_targets/total:.1f}%)\")\n",
    "    \n",
    "    # Проверка вариации по targets\n",
    "    low_variance_preds = 0\n",
    "    low_variance_targets = 0\n",
    "    \n",
    "    for i in range(predictions.shape[1]):\n",
    "        if predictions[:, i].std() < 1e-6:\n",
    "            low_variance_preds += 1\n",
    "        if targets[:, i].std() < 1e-6:\n",
    "            low_variance_targets += 1\n",
    "    \n",
    "    if low_variance_preds > 0:\n",
    "        print(f\"\\n⚠️ Predictions с низкой дисперсией (std < 1e-6): {low_variance_preds}/{predictions.shape[1]}\")\n",
    "    \n",
    "    if low_variance_targets > 0:\n",
    "        print(f\"\\n⚠️ Targets с низкой дисперсией (std < 1e-6): {low_variance_targets}/{targets.shape[1]}\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "def calculate_kaggle_score(predictions, targets):\n",
    "    \"\"\" ПРАВИЛЬНАЯ метрика соревнования: Modified Sharpe Ratio\n",
    "    Score = (Mean Spearman Correlation / Std Spearman Correlation) * 100,000\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ВЫЧИСЛЕНИЕ KAGGLE SCORE (Modified Sharpe Ratio)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    correlations = []\n",
    "    failed_targets = 0\n",
    "    \n",
    "    # Для каждого target вычисляем Spearman correlation\n",
    "    for i in range(targets.shape[1]):  # 424 targets\n",
    "        pred_col = predictions[:, i]\n",
    "        true_col = targets[:, i]\n",
    "        \n",
    "        # Проверяем что есть вариация в данных\n",
    "        if len(np.unique(pred_col)) < 2 or len(np.unique(true_col)) < 2:\n",
    "            failed_targets += 1\n",
    "            continue\n",
    "        \n",
    "        # Spearman rank correlation\n",
    "        try:\n",
    "            corr, p_value = spearmanr(pred_col, true_col)\n",
    "            if not np.isnan(corr) and not np.isinf(corr):\n",
    "                correlations.append(corr)\n",
    "            else:\n",
    "                failed_targets += 1\n",
    "        except Exception as e:\n",
    "            failed_targets += 1\n",
    "            continue\n",
    "    \n",
    "    if len(correlations) == 0:\n",
    "        print(\"\\n⚠️ КРИТИЧЕСКАЯ ОШИБКА: Не удалось вычислить ни одной корреляции!\")\n",
    "        print(f\"   Провалено targets: {failed_targets}/{targets.shape[1]}\")\n",
    "        print(\"\\n   Причины:\")\n",
    "        print(\"   - Все predictions константные для каждого target\")\n",
    "        print(\"   - Все targets константные\")\n",
    "        print(\"   - Недостаточно вариации в данных\")\n",
    "        \n",
    "        return {\n",
    "            'kaggle_score': 0.0,\n",
    "            'sharpe_ratio': 0.0,\n",
    "            'mean_correlation': 0.0,\n",
    "            'std_correlation': 0.0,\n",
    "            'median_correlation': 0.0,\n",
    "            'correlations': np.array([]),\n",
    "            'successful_targets': 0,\n",
    "            'failed_targets': failed_targets\n",
    "        }\n",
    "    \n",
    "    correlations = np.array(correlations)\n",
    "    \n",
    "    # Статистика\n",
    "    mean_corr = np.mean(correlations)\n",
    "    std_corr = np.std(correlations)\n",
    "    median_corr = np.median(correlations)\n",
    "    min_corr = np.min(correlations)\n",
    "    max_corr = np.max(correlations)\n",
    "    \n",
    "    # Kaggle Score (масштабированный Modified Sharpe Ratio)\n",
    "    if std_corr > 1e-8:  # Защита от деления на 0\n",
    "        sharpe_ratio = mean_corr / std_corr\n",
    "        kaggle_score = sharpe_ratio * 100000  # Масштабирование\n",
    "    else:\n",
    "        sharpe_ratio = 0\n",
    "        kaggle_score = 0\n",
    "    \n",
    "    print(f\"\\nСтатистика Spearman Correlations:\")\n",
    "    print(f\"  Успешно: {len(correlations)}/{targets.shape[1]} targets\")\n",
    "    if failed_targets > 0:\n",
    "        print(f\"  Провалено: {failed_targets} targets (константные значения)\")\n",
    "    print(f\"  Mean:    {mean_corr:.6f}\")\n",
    "    print(f\"  Median:  {median_corr:.6f}\")\n",
    "    print(f\"  Std:     {std_corr:.6f}\")\n",
    "    print(f\"  Min:     {min_corr:.6f}\")\n",
    "    print(f\"  Max:     {max_corr:.6f}\")\n",
    "    \n",
    "    # Распределение\n",
    "    positive = (correlations > 0).sum()\n",
    "    negative = (correlations < 0).sum()\n",
    "    near_zero = (np.abs(correlations) < 0.01).sum()\n",
    "    \n",
    "    print(f\"\\n  Positive correlations: {positive}/{len(correlations)} ({100*positive/len(correlations):.1f}%)\")\n",
    "    print(f\"  Negative correlations: {negative}/{len(correlations)} ({100*negative/len(correlations):.1f}%)\")\n",
    "    print(f\"  Near zero (|r| < 0.01): {near_zero}/{len(correlations)} ({100*near_zero/len(correlations):.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(f\"KAGGLE SCORE (Modified Sharpe Ratio):\")\n",
    "    print(f\"=\"*70)\n",
    "    print(f\"  Sharpe Ratio:        {sharpe_ratio:.6f}\")\n",
    "    print(f\"  KAGGLE SCORE:        {kaggle_score:.2f}\")\n",
    "    \n",
    "    # Интерпретация\n",
    "    if kaggle_score > 100000:\n",
    "        print(f\"\\n  ✅ ОТЛИЧНЫЙ результат! (> 100,000)\")\n",
    "    elif kaggle_score > 50000:\n",
    "        print(f\"\\n  ✓ Хороший результат (> 50,000)\")\n",
    "    elif kaggle_score > 0:\n",
    "        print(f\"\\n  ⚠ Слабый результат (> 0, но < 50,000)\")\n",
    "    else:\n",
    "        print(f\"\\n  ❌ ПЛОХОЙ результат (отрицательный score)\")\n",
    "        print(f\"     Модель предсказывает в противоположном направлении!\")\n",
    "    \n",
    "    print(f\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'kaggle_score': kaggle_score,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'mean_correlation': mean_corr,\n",
    "        'std_correlation': std_corr,\n",
    "        'median_correlation': median_corr,\n",
    "        'min_correlation': min_corr,\n",
    "        'max_correlation': max_corr,\n",
    "        'correlations': correlations,\n",
    "        'successful_targets': len(correlations),\n",
    "        'failed_targets': failed_targets\n",
    "    }\n",
    "\n",
    "def full_evaluation_corrected():\n",
    "    \"\"\"Полная оценка с ПРАВИЛЬНОЙ метрикой\"\"\"\n",
    "    global models, scaler, feature_cols, base_cols, model_val_scores, is_initialized, device\n",
    "    \n",
    "    if not is_initialized:\n",
    "        print(\"Модели не инициализированы!\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"🎯\"*35)\n",
    "    print(\"ПОЛНАЯ ОЦЕНКА МОДЕЛИ (ПРАВИЛЬНАЯ МЕТРИКА)\")\n",
    "    print(\"🎯\"*35)\n",
    "    \n",
    "    # Загружаем данные\n",
    "    train = pd.read_csv('/home/nicolaedrabcinski/sd_kaggle/data/raw/train.csv')\n",
    "    train_labels = pd.read_csv('/home/nicolaedrabcinski/sd_kaggle/data/raw/train_labels.csv')\n",
    "    \n",
    "    # Создаем фичи\n",
    "    train_features = create_optimized_features(train, base_cols_ref=base_cols, max_features=800)\n",
    "    \n",
    "    target_cols = [f'target_{i}' for i in range(424)]\n",
    "    \n",
    "    X_train = train_features[feature_cols].fillna(0).values\n",
    "    y_train = train_labels[target_cols].fillna(0).values\n",
    "    \n",
    "    X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    y_train = np.nan_to_num(y_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Validation set (последние 10%)\n",
    "    split_idx = int(len(X_train) * 0.9)\n",
    "    X_val = X_train[split_idx:]\n",
    "    y_val = y_train[split_idx:]\n",
    "    \n",
    "    print(f\"\\n1️⃣  VALIDATION SCORE:\")\n",
    "    print(f\"Validation set size: {len(X_val)} samples\")\n",
    "    \n",
    "    # Предсказания\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_val_tensor = torch.FloatTensor(X_val_scaled).to(device)\n",
    "    \n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            pred = model(X_val_tensor)\n",
    "            pred_cpu = pred.cpu().numpy()\n",
    "            all_preds.append(pred_cpu)\n",
    "    \n",
    "    # Взвешенный ансамбль\n",
    "    weights = np.array(model_val_scores)\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    val_preds = np.average(all_preds, axis=0, weights=weights)\n",
    "    val_preds = np.tanh(val_preds * 10) * 0.1  # Мягкое ограничение\n",
    "    val_preds = np.nan_to_num(val_preds, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # ДИАГНОСТИКА VALIDATION PREDICTIONS\n",
    "    diagnose_predictions(val_preds, y_val)\n",
    "    \n",
    "    # Вычисляем ПРАВИЛЬНЫЙ Kaggle Score\n",
    "    val_results = calculate_kaggle_score(val_preds, y_val)\n",
    "    \n",
    "    # Test set (последние 90 дней)\n",
    "    print(f\"\\n2️⃣  TEST SCORE:\")\n",
    "    test_train = train.tail(90).reset_index(drop=True)\n",
    "    test_labels = train_labels.tail(90).reset_index(drop=True)\n",
    "    \n",
    "    X_test = prepare_features(test_train)\n",
    "    y_test = test_labels[target_cols].fillna(0).values\n",
    "    y_test = np.nan_to_num(y_test, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "    \n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            pred = model(X_test_tensor)\n",
    "            pred_cpu = pred.cpu().numpy()\n",
    "            all_preds.append(pred_cpu)\n",
    "    \n",
    "    test_preds = np.average(all_preds, axis=0, weights=weights)\n",
    "    test_preds = np.tanh(test_preds * 10) * 0.1  # Мягкое ограничение\n",
    "    test_preds = np.nan_to_num(test_preds, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # ДИАГНОСТИКА TEST PREDICTIONS\n",
    "    diagnose_predictions(test_preds, y_test)\n",
    "    \n",
    "    test_results = calculate_kaggle_score(test_preds, y_test)\n",
    "    \n",
    "    # Сравнение\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"📊 СРАВНЕНИЕ РЕЗУЛЬТАТОВ:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Метрика':<30} {'Validation':<20} {'Test':<20}\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'KAGGLE SCORE':<30} {val_results['kaggle_score']:<20.2f} {test_results['kaggle_score']:<20.2f}\")\n",
    "    print(f\"{'Sharpe Ratio':<30} {val_results['sharpe_ratio']:<20.6f} {test_results['sharpe_ratio']:<20.6f}\")\n",
    "    print(f\"{'Mean Correlation':<30} {val_results['mean_correlation']:<20.6f} {test_results['mean_correlation']:<20.6f}\")\n",
    "    print(f\"{'Std Correlation':<30} {val_results['std_correlation']:<20.6f} {test_results['std_correlation']:<20.6f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if val_results['kaggle_score'] > 100000:\n",
    "        print(\"✅ ОТЛИЧНЫЙ РЕЗУЛЬТАТ! Score > 100,000\")\n",
    "    elif val_results['kaggle_score'] > 50000:\n",
    "        print(\"✓ Хороший результат. Score > 50,000\")\n",
    "    elif val_results['kaggle_score'] > 0:\n",
    "        print(\"⚠ Слабый результат. Score > 0, но < 50,000\")\n",
    "    else:\n",
    "        print(\"❌ ПЛОХОЙ результат. Отрицательный score!\")\n",
    "    \n",
    "    print(\"\\n\" + \"🎯\"*35 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'validation': val_results,\n",
    "        'test': test_results\n",
    "    }\n",
    "\n",
    "def create_submission_file():\n",
    "    global models, scaler, feature_cols, is_initialized, device, model_val_scores\n",
    "    \n",
    "    print(\"\\nСоздание submission.parquet...\")\n",
    "    \n",
    "    if not is_initialized:\n",
    "        raise Exception(\"Модели не инициализированы!\")\n",
    "    \n",
    "    test = pd.read_csv('/home/nicolaedrabcinski/sd_kaggle/data/raw/test.csv')\n",
    "    \n",
    "    print(\"Генерация предсказаний...\")\n",
    "    \n",
    "    # Вычисляем веса\n",
    "    weights = np.array(model_val_scores)\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    # Используем батчинговое предсказание\n",
    "    predictions = efficient_predict_batch(test, models, weights)\n",
    "    \n",
    "    submission = pd.DataFrame({'date_id': test['date_id'].values})\n",
    "    for i in range(424):\n",
    "        submission[f'target_{i}'] = predictions[:, i]\n",
    "    \n",
    "    if 'is_scored' in test.columns:\n",
    "        submission = submission[test['is_scored'] == True].reset_index(drop=True)\n",
    "    \n",
    "    submission = submission.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    submission.to_parquet('submission_optuna.parquet', index=False, engine='pyarrow')\n",
    "    \n",
    "    print(f\"Готово: {submission.shape}\")\n",
    "    \n",
    "    # Очищаем GPU память\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e7e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 10: Визуализация Optuna и основной пайплайн\n",
    "def visualize_optuna_results():\n",
    "    \"\"\"Визуализация результатов Optuna с сохранением в PNG\"\"\"\n",
    "    if not optuna_studies:\n",
    "        print(\"Нет данных Optuna для визуализации\")\n",
    "        return\n",
    "    \n",
    "    # Создаем папку для визуализаций\n",
    "    import os\n",
    "    os.makedirs('optuna_visualizations', exist_ok=True)\n",
    "    \n",
    "    for model_type, study in optuna_studies.items():\n",
    "        print(f\"\\n📊 ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ OPTUNA ДЛЯ {model_type}:\")\n",
    "        \n",
    "        # Лучшие параметры\n",
    "        print(f\"Лучшие параметры: {study.best_trial.params}\")\n",
    "        print(f\"Лучший score: {study.best_value:.4f}\")\n",
    "        \n",
    "        try:\n",
    "            # Важность параметров\n",
    "            fig = optuna.visualization.plot_param_importances(study)\n",
    "            fig.update_layout(title=f\"Важность параметров - {model_type}\")\n",
    "            fig.write_image(f\"optuna_visualizations/{model_type}_param_importance.png\")\n",
    "            # fig.show()\n",
    "            print(f\"✅ Сохранен: optuna_visualizations/{model_type}_param_importance.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"Не удалось создать график важности параметров: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # Параллельные координаты\n",
    "            fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "            fig.update_layout(title=f\"Параллельные координаты - {model_type}\")\n",
    "            fig.write_image(f\"optuna_visualizations/{model_type}_parallel_coord.png\")\n",
    "            # fig.show()\n",
    "            print(f\"✅ Сохранен: optuna_visualizations/{model_type}_parallel_coord.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"Не удалось создать график параллельных координат: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # История оптимизации\n",
    "            fig = optuna.visualization.plot_optimization_history(study)\n",
    "            fig.update_layout(title=f\"История оптимизации - {model_type}\")\n",
    "            fig.write_image(f\"optuna_visualizations/{model_type}_optimization_history.png\")\n",
    "            # fig.show()\n",
    "            print(f\"✅ Сохранен: optuna_visualizations/{model_type}_optimization_history.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"Не удалось создать график истории оптимизации: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # Распределение параметров\n",
    "            fig = optuna.visualization.plot_slice(study)\n",
    "            fig.update_layout(title=f\"Срез параметров - {model_type}\")\n",
    "            fig.write_image(f\"optuna_visualizations/{model_type}_slice_plot.png\")\n",
    "            # fig.show()\n",
    "            print(f\"✅ Сохранен: optuna_visualizations/{model_type}_slice_plot.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"Не удалось создать график среза параметров: {e}\")\n",
    "    \n",
    "    print(f\"\\n🎉 Все визуализации сохранены в папку 'optuna_visualizations/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb7017ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЗАПУСК ПАЙПЛАЙНА С OPTUNA ОПТИМИЗАЦИЕЙ\n",
      "============================================================\n",
      "Начало обучения с оптимизацией гиперпараметров...\n",
      "======================================================================\n",
      "ИНИЦИАЛИЗАЦИЯ ВСЕХ 6 МОДЕЛЕЙ С OPTUNA ОПТИМИЗАЦИЕЙ НА cuda\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Базовых колонок: 557\n",
      "Создание оптимизированных признаков...\n",
      "Обрабатывается 100 базовых колонок...\n",
      "Достигнут лимит в 800 признаков\n",
      "Создано 1507 признаков после фильтрации\n",
      "Векторизованный отбор признаков с GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 21:35:36,469] A new study created in memory with name: no-name-c0673959-413c-4696-880c-8a8fdc509186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отобрано 500 лучших признаков\n",
      "Лучший признак: US_Stock_EMB_adj_open_volatility_20 (корреляция: 0.0607)\n",
      "Train: 1666, Validation: 295\n",
      "\n",
      "======================================================================\n",
      "OPTUNA ОПТИМИЗАЦИЯ ДЛЯ SimpleEffective\n",
      "Количество trials: 10\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70c46d77f2840c0a673377bda44c128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 21:36:58,011] Trial 0 finished with value: 0.006195330756502192 and parameters: {'hidden_size': 256, 'dropout_rate': 0.18283347655873736, 'num_layers': 4, 'lr': 0.0002661348065476525, 'augmentation_strength': 0.6175825223429894}. Best is trial 0 with value: 0.006195330756502192.\n",
      "[I 2025-10-14 21:38:19,905] Trial 1 finished with value: 0.0025544337046246586 and parameters: {'hidden_size': 256, 'dropout_rate': 0.1866993947000553, 'num_layers': 4, 'lr': 0.0006734224139662396, 'augmentation_strength': 0.3181087550689702}. Best is trial 0 with value: 0.006195330756502192.\n",
      "[I 2025-10-14 21:39:42,550] Trial 2 finished with value: 0.005312468657923564 and parameters: {'hidden_size': 1024, 'dropout_rate': 0.4845760806116023, 'num_layers': 3, 'lr': 6.676094501662065e-05, 'augmentation_strength': 0.7740756617822193}. Best is trial 0 with value: 0.006195330756502192.\n",
      "[I 2025-10-14 21:41:04,601] Trial 3 finished with value: 0.004635957939532578 and parameters: {'hidden_size': 1024, 'dropout_rate': 0.3978063519584836, 'num_layers': 5, 'lr': 0.00023733994552376373, 'augmentation_strength': 0.5301893030291442}. Best is trial 0 with value: 0.006195330756502192.\n",
      "Ошибка в trial 4: \n",
      "[I 2025-10-14 21:42:18,855] Trial 4 finished with value: 0.0 and parameters: {'hidden_size': 256, 'dropout_rate': 0.10896427709915334, 'num_layers': 4, 'lr': 0.002239614911833058, 'augmentation_strength': 0.7257741707666001}. Best is trial 0 with value: 0.006195330756502192.\n",
      "Ошибка в trial 5: \n",
      "[I 2025-10-14 21:42:43,937] Trial 5 finished with value: 0.0 and parameters: {'hidden_size': 256, 'dropout_rate': 0.4494733488060141, 'num_layers': 6, 'lr': 2.0929365274806498e-05, 'augmentation_strength': 0.30676036316206484}. Best is trial 0 with value: 0.006195330756502192.\n",
      "Ошибка в trial 6: \n",
      "[I 2025-10-14 21:43:09,151] Trial 6 finished with value: 0.0 and parameters: {'hidden_size': 512, 'dropout_rate': 0.4661937242272586, 'num_layers': 5, 'lr': 1.935246646688751e-05, 'augmentation_strength': 0.46293415151156325}. Best is trial 0 with value: 0.006195330756502192.\n",
      "Ошибка в trial 7: \n",
      "[I 2025-10-14 21:43:34,519] Trial 7 finished with value: 0.0 and parameters: {'hidden_size': 512, 'dropout_rate': 0.39909732994430913, 'num_layers': 6, 'lr': 1.4011041372978752e-05, 'augmentation_strength': 0.4099372576047609}. Best is trial 0 with value: 0.006195330756502192.\n",
      "Ошибка в trial 8: \n",
      "[I 2025-10-14 21:43:59,925] Trial 8 finished with value: 0.0 and parameters: {'hidden_size': 1024, 'dropout_rate': 0.2343829620463466, 'num_layers': 5, 'lr': 0.00035250391943343796, 'augmentation_strength': 0.7384583903742146}. Best is trial 0 with value: 0.006195330756502192.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 21:44:08,803] A new study created in memory with name: no-name-b7b2e686-6550-4234-ab39-dc3a2eda33eb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка в trial 9: \n",
      "[I 2025-10-14 21:44:08,801] Trial 9 finished with value: 0.0 and parameters: {'hidden_size': 1024, 'dropout_rate': 0.28066494833373806, 'num_layers': 6, 'lr': 0.0019314930676701486, 'augmentation_strength': 0.7933749118265564}. Best is trial 0 with value: 0.006195330756502192.\n",
      "\n",
      "ЛУЧШИЕ ГИПЕРПАРАМЕТРЫ ДЛЯ SimpleEffective:\n",
      "  hidden_size: 256\n",
      "  dropout_rate: 0.18283347655873736\n",
      "  num_layers: 4\n",
      "  lr: 0.0002661348065476525\n",
      "  augmentation_strength: 0.6175825223429894\n",
      "Лучший val_score: 0.0062\n",
      "✅ SimpleEffective оптимизирована. Best score: 0.0062\n",
      "\n",
      "======================================================================\n",
      "OPTUNA ОПТИМИЗАЦИЯ ДЛЯ Residual\n",
      "Количество trials: 10\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10de2daf846a4446a3d8fdefaf51d136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 21:45:30,364] Trial 0 finished with value: 0.0002320562126475153 and parameters: {'hidden_size': 128, 'num_blocks': 4, 'dropout_rate': 0.34071999392182284, 'lr': 3.211380718503001e-05}. Best is trial 0 with value: 0.0002320562126475153.\n",
      "[I 2025-10-14 21:46:35,883] Trial 1 finished with value: 0.00018388511871774514 and parameters: {'hidden_size': 512, 'num_blocks': 5, 'dropout_rate': 0.3841198472800519, 'lr': 0.0010643941237084157}. Best is trial 0 with value: 0.0002320562126475153.\n",
      "[I 2025-10-14 21:47:58,418] Trial 2 finished with value: 0.002472165285959948 and parameters: {'hidden_size': 512, 'num_blocks': 2, 'dropout_rate': 0.2013170746155894, 'lr': 1.1770594962404306e-05}. Best is trial 2 with value: 0.002472165285959948.\n",
      "Ошибка в trial 3: \n",
      "[I 2025-10-14 21:48:13,058] Trial 3 finished with value: 0.0 and parameters: {'hidden_size': 512, 'num_blocks': 4, 'dropout_rate': 0.2681773782683764, 'lr': 0.007880009778737046}. Best is trial 2 with value: 0.002472165285959948.\n",
      "Ошибка в trial 4: \n",
      "[I 2025-10-14 21:48:22,170] Trial 4 finished with value: 0.0 and parameters: {'hidden_size': 256, 'num_blocks': 5, 'dropout_rate': 0.331067493730528, 'lr': 5.7114480428133835e-05}. Best is trial 2 with value: 0.002472165285959948.\n",
      "[I 2025-10-14 21:49:06,261] Trial 5 finished with value: 0.0 and parameters: {'hidden_size': 512, 'num_blocks': 5, 'dropout_rate': 0.17252949860532496, 'lr': 0.0028864160904972596}. Best is trial 2 with value: 0.002472165285959948.\n",
      "Ошибка в trial 6: \n",
      "[I 2025-10-14 21:49:31,917] Trial 6 finished with value: 0.0 and parameters: {'hidden_size': 512, 'num_blocks': 3, 'dropout_rate': 0.14443787916567857, 'lr': 0.00030478644621808736}. Best is trial 2 with value: 0.002472165285959948.\n",
      "Ошибка в trial 7: \n",
      "[I 2025-10-14 21:49:57,426] Trial 7 finished with value: 0.0 and parameters: {'hidden_size': 128, 'num_blocks': 3, 'dropout_rate': 0.32673396574077507, 'lr': 0.0003499845432782918}. Best is trial 2 with value: 0.002472165285959948.\n",
      "[I 2025-10-14 21:51:20,542] Trial 8 finished with value: 0.002176482063687629 and parameters: {'hidden_size': 128, 'num_blocks': 2, 'dropout_rate': 0.13812888622048575, 'lr': 0.00011639076871004712}. Best is trial 2 with value: 0.002472165285959948.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 21:52:30,164] A new study created in memory with name: no-name-0356175e-918a-44c5-a8b0-01e0ee8a2013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 21:52:30,162] Trial 9 finished with value: 0.006292403639395551 and parameters: {'hidden_size': 512, 'num_blocks': 3, 'dropout_rate': 0.36587434789878137, 'lr': 0.0006432037874787973}. Best is trial 9 with value: 0.006292403639395551.\n",
      "\n",
      "ЛУЧШИЕ ГИПЕРПАРАМЕТРЫ ДЛЯ Residual:\n",
      "  hidden_size: 512\n",
      "  num_blocks: 3\n",
      "  dropout_rate: 0.36587434789878137\n",
      "  lr: 0.0006432037874787973\n",
      "Лучший val_score: 0.0063\n",
      "✅ Residual оптимизирована. Best score: 0.0063\n",
      "\n",
      "======================================================================\n",
      "OPTUNA ОПТИМИЗАЦИЯ ДЛЯ Wide\n",
      "Количество trials: 10\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be4134330f94c90a581fd80a4046fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 21:53:52,533] Trial 0 finished with value: 0.007118558765279368 and parameters: {'hidden_size1': 512, 'hidden_size2': 256, 'hidden_size3': 256, 'dropout1': 0.5502052504713265, 'dropout2': 0.13319968174207572, 'dropout3': 0.26775372055551644, 'lr': 2.7813437719055103e-05}. Best is trial 0 with value: 0.007118558765279368.\n",
      "[I 2025-10-14 21:55:15,674] Trial 1 finished with value: 0.0055973796373838145 and parameters: {'hidden_size1': 2048, 'hidden_size2': 512, 'hidden_size3': 128, 'dropout1': 0.4886548729122299, 'dropout2': 0.27145769846641454, 'dropout3': 0.22889185222646452, 'lr': 0.00012960128397787962}. Best is trial 0 with value: 0.007118558765279368.\n",
      "Ошибка в trial 2: \n",
      "[I 2025-10-14 21:55:41,585] Trial 2 finished with value: 0.0 and parameters: {'hidden_size1': 1024, 'hidden_size2': 512, 'hidden_size3': 128, 'dropout1': 0.3876862333406134, 'dropout2': 0.4562396477857831, 'dropout3': 0.1653651636665881, 'lr': 2.8884217218454276e-05}. Best is trial 0 with value: 0.007118558765279368.\n",
      "Ошибка в trial 3: \n",
      "[I 2025-10-14 21:56:07,051] Trial 3 finished with value: 0.0 and parameters: {'hidden_size1': 2048, 'hidden_size2': 512, 'hidden_size3': 256, 'dropout1': 0.48125581384140476, 'dropout2': 0.3819571058637091, 'dropout3': 0.2686022842497067, 'lr': 3.074234459414467e-05}. Best is trial 0 with value: 0.007118558765279368.\n",
      "[I 2025-10-14 21:57:28,985] Trial 4 finished with value: 0.0013513312039892538 and parameters: {'hidden_size1': 1024, 'hidden_size2': 512, 'hidden_size3': 128, 'dropout1': 0.2491470153698625, 'dropout2': 0.26941930750115717, 'dropout3': 0.1097064383894621, 'lr': 0.0004502010636999425}. Best is trial 0 with value: 0.007118558765279368.\n",
      "[I 2025-10-14 21:58:51,234] Trial 5 finished with value: 0.008535511759488133 and parameters: {'hidden_size1': 1024, 'hidden_size2': 1024, 'hidden_size3': 512, 'dropout1': 0.3933935184335017, 'dropout2': 0.16721243904973276, 'dropout3': 0.34738895506018463, 'lr': 0.00016172429558128834}. Best is trial 5 with value: 0.008535511759488133.\n",
      "Ошибка в trial 6: \n",
      "[I 2025-10-14 21:59:16,699] Trial 6 finished with value: 0.0 and parameters: {'hidden_size1': 512, 'hidden_size2': 512, 'hidden_size3': 128, 'dropout1': 0.4930856237631472, 'dropout2': 0.19846741964233297, 'dropout3': 0.33920031861847644, 'lr': 1.7256768998078386e-05}. Best is trial 5 with value: 0.008535511759488133.\n",
      "Ошибка в trial 7: \n",
      "[I 2025-10-14 22:00:31,338] Trial 7 finished with value: 0.0 and parameters: {'hidden_size1': 2048, 'hidden_size2': 256, 'hidden_size3': 256, 'dropout1': 0.2074193133093255, 'dropout2': 0.1797702809281932, 'dropout3': 0.3948965631639184, 'lr': 1.3748681526391406e-05}. Best is trial 5 with value: 0.008535511759488133.\n",
      "Ошибка в trial 8: \n",
      "[I 2025-10-14 22:01:46,446] Trial 8 finished with value: 0.0 and parameters: {'hidden_size1': 1024, 'hidden_size2': 1024, 'hidden_size3': 512, 'dropout1': 0.27581475319621707, 'dropout2': 0.23096577779957245, 'dropout3': 0.31529040154732196, 'lr': 1.1646933956052232e-05}. Best is trial 5 with value: 0.008535511759488133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 22:01:55,749] A new study created in memory with name: no-name-b07020e2-42d8-4891-b63c-172ff28d1549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка в trial 9: \n",
      "[I 2025-10-14 22:01:55,747] Trial 9 finished with value: 0.0 and parameters: {'hidden_size1': 2048, 'hidden_size2': 1024, 'hidden_size3': 256, 'dropout1': 0.5357675908560295, 'dropout2': 0.47847001219593677, 'dropout3': 0.18646070884242974, 'lr': 0.0007269941851594987}. Best is trial 5 with value: 0.008535511759488133.\n",
      "\n",
      "ЛУЧШИЕ ГИПЕРПАРАМЕТРЫ ДЛЯ Wide:\n",
      "  hidden_size1: 1024\n",
      "  hidden_size2: 1024\n",
      "  hidden_size3: 512\n",
      "  dropout1: 0.3933935184335017\n",
      "  dropout2: 0.16721243904973276\n",
      "  dropout3: 0.34738895506018463\n",
      "  lr: 0.00016172429558128834\n",
      "Лучший val_score: 0.0085\n",
      "✅ Wide оптимизирована. Best score: 0.0085\n",
      "\n",
      "======================================================================\n",
      "OPTUNA ОПТИМИЗАЦИЯ ДЛЯ DeepSkip\n",
      "Количество trials: 10\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd285abfba743e9b257556f58c77d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 22:03:17,907] Trial 0 finished with value: 0.006627344350697417 and parameters: {'hidden_size': 256, 'num_blocks': 4, 'dropout_rate': 0.14245902279511943, 'lr': 0.005605600246289252, 'augmentation_strength': 0.48563468492549733}. Best is trial 0 with value: 0.006627344350697417.\n",
      "[I 2025-10-14 22:04:39,721] Trial 1 finished with value: 0.009037602856593392 and parameters: {'hidden_size': 512, 'num_blocks': 3, 'dropout_rate': 0.1593471678905147, 'lr': 4.292329872735687e-05, 'augmentation_strength': 0.42251735704433485}. Best is trial 1 with value: 0.009037602856593392.\n",
      "Ошибка в trial 2: \n",
      "[I 2025-10-14 22:04:48,851] Trial 2 finished with value: 0.0 and parameters: {'hidden_size': 512, 'num_blocks': 2, 'dropout_rate': 0.2942485822531524, 'lr': 9.06992125752985e-05, 'augmentation_strength': 0.48096851111555466}. Best is trial 1 with value: 0.009037602856593392.\n",
      "Ошибка в trial 3: \n",
      "[I 2025-10-14 22:05:15,052] Trial 3 finished with value: 0.0 and parameters: {'hidden_size': 1024, 'num_blocks': 6, 'dropout_rate': 0.30271522029333375, 'lr': 0.00026990678069467713, 'augmentation_strength': 0.41964582022158364}. Best is trial 1 with value: 0.009037602856593392.\n",
      "Ошибка в trial 4: \n",
      "[I 2025-10-14 22:05:40,808] Trial 4 finished with value: 0.0 and parameters: {'hidden_size': 256, 'num_blocks': 2, 'dropout_rate': 0.11143961835446792, 'lr': 2.058811750346448e-05, 'augmentation_strength': 0.8578441323921593}. Best is trial 1 with value: 0.009037602856593392.\n",
      "Ошибка в trial 5: \n",
      "[I 2025-10-14 22:05:50,018] Trial 5 finished with value: 0.0 and parameters: {'hidden_size': 512, 'num_blocks': 3, 'dropout_rate': 0.41145313902208214, 'lr': 1.452993717316531e-05, 'augmentation_strength': 0.5596384045222955}. Best is trial 1 with value: 0.009037602856593392.\n",
      "[I 2025-10-14 22:07:13,524] Trial 6 finished with value: 0.004077988834676848 and parameters: {'hidden_size': 512, 'num_blocks': 4, 'dropout_rate': 0.3990028847056083, 'lr': 1.50249372718984e-05, 'augmentation_strength': 0.7595904254039942}. Best is trial 1 with value: 0.009037602856593392.\n",
      "Ошибка в trial 7: \n",
      "[I 2025-10-14 22:07:22,658] Trial 7 finished with value: 0.0 and parameters: {'hidden_size': 512, 'num_blocks': 3, 'dropout_rate': 0.2598057403672128, 'lr': 4.1518311913585886e-05, 'augmentation_strength': 0.526974890867036}. Best is trial 1 with value: 0.009037602856593392.\n",
      "Ошибка в trial 8: \n",
      "[I 2025-10-14 22:07:31,872] Trial 8 finished with value: 0.0 and parameters: {'hidden_size': 256, 'num_blocks': 2, 'dropout_rate': 0.31014837251637795, 'lr': 0.006213640854403748, 'augmentation_strength': 0.7944619920521954}. Best is trial 1 with value: 0.009037602856593392.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 22:07:57,481] A new study created in memory with name: no-name-769d645d-d986-4ec9-b77f-747dc9ad592d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка в trial 9: \n",
      "[I 2025-10-14 22:07:57,479] Trial 9 finished with value: 0.0 and parameters: {'hidden_size': 256, 'num_blocks': 5, 'dropout_rate': 0.2868976858523793, 'lr': 0.008770567504824536, 'augmentation_strength': 0.47443031156926296}. Best is trial 1 with value: 0.009037602856593392.\n",
      "\n",
      "ЛУЧШИЕ ГИПЕРПАРАМЕТРЫ ДЛЯ DeepSkip:\n",
      "  hidden_size: 512\n",
      "  num_blocks: 3\n",
      "  dropout_rate: 0.1593471678905147\n",
      "  lr: 4.292329872735687e-05\n",
      "  augmentation_strength: 0.42251735704433485\n",
      "Лучший val_score: 0.0090\n",
      "✅ DeepSkip оптимизирована. Best score: 0.0090\n",
      "\n",
      "======================================================================\n",
      "OPTUNA ОПТИМИЗАЦИЯ ДЛЯ Attention\n",
      "Количество trials: 10\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6daacb9fe6f4e1d9edf7f18efecb25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 22:09:19,049] Trial 0 finished with value: 0.005361454339121452 and parameters: {'hidden_size': 512, 'num_heads': 4, 'dropout_rate': 0.18276176448069797, 'lr': 0.00011519503227045127, 'augmentation_strength': 0.5452673022815104}. Best is trial 0 with value: 0.005361454339121452.\n",
      "Ошибка в trial 1: \n",
      "[I 2025-10-14 22:10:33,232] Trial 1 finished with value: 0.0 and parameters: {'hidden_size': 256, 'num_heads': 4, 'dropout_rate': 0.27973626790277245, 'lr': 5.583958397756887e-05, 'augmentation_strength': 0.42824279979848073}. Best is trial 0 with value: 0.005361454339121452.\n",
      "Ошибка в trial 2: \n",
      "[I 2025-10-14 22:11:48,021] Trial 2 finished with value: 0.0 and parameters: {'hidden_size': 256, 'num_heads': 4, 'dropout_rate': 0.2987334861149724, 'lr': 3.6354708934343e-05, 'augmentation_strength': 0.5502249506609751}. Best is trial 0 with value: 0.005361454339121452.\n",
      "[I 2025-10-14 22:13:10,550] Trial 3 finished with value: -0.00028358890992626295 and parameters: {'hidden_size': 256, 'num_heads': 8, 'dropout_rate': 0.18073746026048665, 'lr': 0.0002525581620109094, 'augmentation_strength': 0.6370315162522275}. Best is trial 0 with value: 0.005361454339121452.\n",
      "Ошибка в trial 4: \n",
      "[I 2025-10-14 22:13:36,254] Trial 4 finished with value: 0.0 and parameters: {'hidden_size': 1024, 'num_heads': 8, 'dropout_rate': 0.11575704580294412, 'lr': 3.4573891166077906e-05, 'augmentation_strength': 0.6616756471554511}. Best is trial 0 with value: 0.005361454339121452.\n",
      "[I 2025-10-14 22:14:58,997] Trial 5 finished with value: 0.00473041140854265 and parameters: {'hidden_size': 1024, 'num_heads': 8, 'dropout_rate': 0.1776856627929671, 'lr': 0.00031011187208402426, 'augmentation_strength': 0.5084434665214431}. Best is trial 0 with value: 0.005361454339121452.\n",
      "Ошибка в trial 6: \n",
      "[I 2025-10-14 22:16:14,637] Trial 6 finished with value: 0.0 and parameters: {'hidden_size': 1024, 'num_heads': 8, 'dropout_rate': 0.23749362521999268, 'lr': 0.00011787020659969206, 'augmentation_strength': 0.684511654720845}. Best is trial 0 with value: 0.005361454339121452.\n",
      "[I 2025-10-14 22:17:36,743] Trial 7 finished with value: 0.009041757872839045 and parameters: {'hidden_size': 512, 'num_heads': 8, 'dropout_rate': 0.2944549750391537, 'lr': 0.0009553212412273206, 'augmentation_strength': 0.39243139721786197}. Best is trial 7 with value: 0.009041757872839045.\n",
      "[I 2025-10-14 22:18:59,677] Trial 8 finished with value: 0.009824960685171762 and parameters: {'hidden_size': 1024, 'num_heads': 4, 'dropout_rate': 0.18413713429117845, 'lr': 4.710208379346669e-05, 'augmentation_strength': 0.6852492269167936}. Best is trial 8 with value: 0.009824960685171762.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 22:19:25,238] A new study created in memory with name: no-name-19ac556e-8fad-4402-abaa-d88bc6c3c62c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка в trial 9: \n",
      "[I 2025-10-14 22:19:25,236] Trial 9 finished with value: 0.0 and parameters: {'hidden_size': 512, 'num_heads': 4, 'dropout_rate': 0.14732108980066821, 'lr': 1.1021711463123248e-05, 'augmentation_strength': 0.5065639840918428}. Best is trial 8 with value: 0.009824960685171762.\n",
      "\n",
      "ЛУЧШИЕ ГИПЕРПАРАМЕТРЫ ДЛЯ Attention:\n",
      "  hidden_size: 1024\n",
      "  num_heads: 4\n",
      "  dropout_rate: 0.18413713429117845\n",
      "  lr: 4.710208379346669e-05\n",
      "  augmentation_strength: 0.6852492269167936\n",
      "Лучший val_score: 0.0098\n",
      "✅ Attention оптимизирована. Best score: 0.0098\n",
      "\n",
      "======================================================================\n",
      "OPTUNA ОПТИМИЗАЦИЯ ДЛЯ EnsembleInside\n",
      "Количество trials: 10\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a2b5b3047740b8b3a305b1edb2acd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 22:20:48,390] Trial 0 finished with value: 0.0037545842268386694 and parameters: {'num_experts': 3, 'expert_hidden': 512, 'gate_hidden': 128, 'lr': 0.00013319545921315043, 'augmentation_strength': 0.5855723596499758}. Best is trial 0 with value: 0.0037545842268386694.\n",
      "Ошибка в trial 1: \n",
      "[I 2025-10-14 22:20:57,074] Trial 1 finished with value: 0.0 and parameters: {'num_experts': 3, 'expert_hidden': 384, 'gate_hidden': 128, 'lr': 0.004449354822094503, 'augmentation_strength': 0.7065910235735845}. Best is trial 0 with value: 0.0037545842268386694.\n",
      "[I 2025-10-14 22:21:59,507] Trial 2 finished with value: 0.004156865878527825 and parameters: {'num_experts': 5, 'expert_hidden': 384, 'gate_hidden': 128, 'lr': 0.009789164377206169, 'augmentation_strength': 0.586605612296109}. Best is trial 2 with value: 0.004156865878527825.\n",
      "[I 2025-10-14 22:23:21,754] Trial 3 finished with value: 0.006792392885787304 and parameters: {'num_experts': 5, 'expert_hidden': 384, 'gate_hidden': 128, 'lr': 0.005277392611181266, 'augmentation_strength': 0.5065439234017669}. Best is trial 3 with value: 0.006792392885787304.\n",
      "Ошибка в trial 4: \n",
      "[I 2025-10-14 22:23:30,703] Trial 4 finished with value: 0.0 and parameters: {'num_experts': 3, 'expert_hidden': 256, 'gate_hidden': 128, 'lr': 0.00016320747557985142, 'augmentation_strength': 0.7101218998193104}. Best is trial 3 with value: 0.006792392885787304.\n",
      "[I 2025-10-14 22:24:51,823] Trial 5 finished with value: 0.05350206664769106 and parameters: {'num_experts': 5, 'expert_hidden': 256, 'gate_hidden': 256, 'lr': 0.0008736259494474606, 'augmentation_strength': 0.3742853580135097}. Best is trial 5 with value: 0.05350206664769106.\n",
      "[I 2025-10-14 22:26:13,274] Trial 6 finished with value: 0.0063612822963859715 and parameters: {'num_experts': 2, 'expert_hidden': 384, 'gate_hidden': 64, 'lr': 0.00011388542116959287, 'augmentation_strength': 0.4816109458471375}. Best is trial 5 with value: 0.05350206664769106.\n",
      "[I 2025-10-14 22:27:35,032] Trial 7 finished with value: 0.03987706709674886 and parameters: {'num_experts': 3, 'expert_hidden': 512, 'gate_hidden': 128, 'lr': 0.0017133487071748974, 'augmentation_strength': 0.8390310943035955}. Best is trial 5 with value: 0.05350206664769106.\n",
      "Ошибка в trial 8: \n",
      "[I 2025-10-14 22:27:44,039] Trial 8 finished with value: 0.0 and parameters: {'num_experts': 2, 'expert_hidden': 256, 'gate_hidden': 128, 'lr': 3.5441491195486786e-05, 'augmentation_strength': 0.43117036190795915}. Best is trial 5 with value: 0.05350206664769106.\n",
      "Ошибка в trial 9: \n",
      "[I 2025-10-14 22:28:09,420] Trial 9 finished with value: 0.0 and parameters: {'num_experts': 4, 'expert_hidden': 256, 'gate_hidden': 128, 'lr': 4.482032709251472e-05, 'augmentation_strength': 0.6875513079266264}. Best is trial 5 with value: 0.05350206664769106.\n",
      "\n",
      "ЛУЧШИЕ ГИПЕРПАРАМЕТРЫ ДЛЯ EnsembleInside:\n",
      "  num_experts: 5\n",
      "  expert_hidden: 256\n",
      "  gate_hidden: 256\n",
      "  lr: 0.0008736259494474606\n",
      "  augmentation_strength: 0.3742853580135097\n",
      "Лучший val_score: 0.0535\n",
      "✅ EnsembleInside оптимизирована. Best score: 0.0535\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 1/6: SimpleEffective_Optuna\n",
      "======================================================================\n",
      "Используются оптимизированные гиперпараметры:\n",
      "  hidden_size: 256\n",
      "  dropout_rate: 0.18283347655873736\n",
      "  num_layers: 4\n",
      "  lr: 0.0002661348065476525\n",
      "  augmentation_strength: 0.6175825223429894\n",
      "Начало обучения SimpleEffective_Optuna с аугментацией: True\n",
      "SimpleEffective_Optuna | AUG | Ep   1/200 | TrL: 0.150826 | TrScore: 0.0005 | ValScore: -0.0039 | LR: 0.000266 | ✓ УЛУЧШЕНИЕ\n",
      "SimpleEffective_Optuna | AUG | Ep  10/200 | TrL: 0.135102 | TrScore: 0.0002 | ValScore: -0.0024 | LR: 0.000266 | ✓ УЛУЧШЕНИЕ\n",
      "SimpleEffective_Optuna | AUG | Ep  20/200 | TrL: 0.123455 | TrScore: 0.0002 | ValScore: -0.0005 | LR: 0.000266 | ✓ УЛУЧШЕНИЕ\n",
      "SimpleEffective_Optuna | AUG | Ep  30/200 | TrL: 0.118130 | TrScore: -0.0008 | ValScore: 0.0032 | LR: 0.000266 | ✓ УЛУЧШЕНИЕ\n",
      "SimpleEffective_Optuna | AUG | Ep  40/200 | TrL: 0.114787 | TrScore: -0.0002 | ValScore: 0.0030 | LR: 0.000266 | NO IMPROVE (6/20)\n",
      "SimpleEffective_Optuna | AUG | Ep  50/200 | TrL: 0.113384 | TrScore: 0.0002 | ValScore: 0.0001 | LR: 0.000266 | NO IMPROVE (16/20)\n",
      "SimpleEffective_Optuna | AUG | Ep  54/200 | TrL: 0.112839 | TrScore: 0.0002 | ValScore: -0.0002 | LR: 0.000266 | NO IMPROVE (20/20)\n",
      "Early stopping на эпохе 55\n",
      "✅ SimpleEffective_Optuna завершена. Best Val Score: 0.0040\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 2/6: Residual_Optuna\n",
      "======================================================================\n",
      "Используются оптимизированные гиперпараметры:\n",
      "  hidden_size: 512\n",
      "  num_blocks: 3\n",
      "  dropout_rate: 0.36587434789878137\n",
      "  lr: 0.0006432037874787973\n",
      "Начало обучения Residual_Optuna с аугментацией: True\n",
      "Residual_Optuna | AUG | Ep   1/200 | TrL: 0.179807 | TrScore: -0.0005 | ValScore: -0.0050 | LR: 0.000643 | ✓ УЛУЧШЕНИЕ\n",
      "Residual_Optuna | AUG | Ep  10/200 | TrL: 0.111352 | TrScore: -0.0006 | ValScore: 0.0050 | LR: 0.000643 | ✓ УЛУЧШЕНИЕ\n",
      "Residual_Optuna | AUG | Ep  20/200 | TrL: 0.110418 | TrScore: 0.0021 | ValScore: 0.0000 | LR: 0.000322 | NO IMPROVE (10/20)\n",
      "Residual_Optuna | AUG | Ep  30/200 | TrL: 0.110622 | TrScore: -0.0003 | ValScore: 0.0000 | LR: 0.000161 | NO IMPROVE (20/20)\n",
      "Early stopping на эпохе 31\n",
      "✅ Residual_Optuna завершена. Best Val Score: 0.0050\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 3/6: Wide_Optuna\n",
      "======================================================================\n",
      "Используются оптимизированные гиперпараметры:\n",
      "  hidden_size1: 1024\n",
      "  hidden_size2: 1024\n",
      "  hidden_size3: 512\n",
      "  dropout1: 0.3933935184335017\n",
      "  dropout2: 0.16721243904973276\n",
      "  dropout3: 0.34738895506018463\n",
      "  lr: 0.00016172429558128834\n",
      "Начало обучения Wide_Optuna с аугментацией: True\n",
      "Wide_Optuna | AUG | Ep   1/200 | TrL: 0.160066 | TrScore: 0.0001 | ValScore: 0.0050 | LR: 0.000162 | ✓ УЛУЧШЕНИЕ\n",
      "Wide_Optuna | AUG | Ep  10/200 | TrL: 0.129427 | TrScore: 0.0009 | ValScore: 0.0031 | LR: 0.000162 | NO IMPROVE (8/20)\n",
      "Wide_Optuna | AUG | Ep  20/200 | TrL: 0.116065 | TrScore: -0.0004 | ValScore: 0.0014 | LR: 0.000162 | NO IMPROVE (18/20)\n",
      "Wide_Optuna | AUG | Ep  22/200 | TrL: 0.113238 | TrScore: 0.0025 | ValScore: -0.0007 | LR: 0.000162 | NO IMPROVE (20/20)\n",
      "Early stopping на эпохе 23\n",
      "✅ Wide_Optuna завершена. Best Val Score: 0.0054\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 4/6: DeepSkip_Optuna\n",
      "======================================================================\n",
      "Используются оптимизированные гиперпараметры:\n",
      "  hidden_size: 512\n",
      "  num_blocks: 3\n",
      "  dropout_rate: 0.1593471678905147\n",
      "  lr: 4.292329872735687e-05\n",
      "  augmentation_strength: 0.42251735704433485\n",
      "Начало обучения DeepSkip_Optuna с аугментацией: True\n",
      "DeepSkip_Optuna | AUG | Ep   1/200 | TrL: 0.287520 | TrScore: -0.0005 | ValScore: 0.0022 | LR: 0.000043 | ✓ УЛУЧШЕНИЕ\n",
      "DeepSkip_Optuna | AUG | Ep  10/200 | TrL: 0.236452 | TrScore: -0.0014 | ValScore: 0.0015 | LR: 0.000043 | NO IMPROVE (7/20)\n",
      "DeepSkip_Optuna | AUG | Ep  20/200 | TrL: 0.203625 | TrScore: 0.0006 | ValScore: -0.0025 | LR: 0.000043 | NO IMPROVE (17/20)\n",
      "DeepSkip_Optuna | AUG | Ep  23/200 | TrL: 0.198301 | TrScore: -0.0025 | ValScore: -0.0036 | LR: 0.000043 | NO IMPROVE (20/20)\n",
      "Early stopping на эпохе 24\n",
      "✅ DeepSkip_Optuna завершена. Best Val Score: 0.0026\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 5/6: Attention_Optuna\n",
      "======================================================================\n",
      "Используются оптимизированные гиперпараметры:\n",
      "  hidden_size: 1024\n",
      "  num_heads: 4\n",
      "  dropout_rate: 0.18413713429117845\n",
      "  lr: 4.710208379346669e-05\n",
      "  augmentation_strength: 0.6852492269167936\n",
      "Начало обучения Attention_Optuna с аугментацией: True\n",
      "Attention_Optuna | AUG | Ep   1/200 | TrL: 0.193090 | TrScore: -0.0004 | ValScore: 0.0006 | LR: 0.000047 | ✓ УЛУЧШЕНИЕ\n",
      "Attention_Optuna | AUG | Ep  10/200 | TrL: 0.163123 | TrScore: 0.0001 | ValScore: 0.0011 | LR: 0.000047 | ✓ УЛУЧШЕНИЕ\n",
      "Attention_Optuna | AUG | Ep  20/200 | TrL: 0.148930 | TrScore: 0.0017 | ValScore: 0.0014 | LR: 0.000047 | NO IMPROVE (1/20)\n",
      "Attention_Optuna | AUG | Ep  30/200 | TrL: 0.137370 | TrScore: 0.0031 | ValScore: 0.0011 | LR: 0.000047 | NO IMPROVE (6/20)\n",
      "Attention_Optuna | AUG | Ep  40/200 | TrL: 0.132295 | TrScore: 0.0016 | ValScore: 0.0006 | LR: 0.000047 | NO IMPROVE (16/20)\n",
      "Attention_Optuna | AUG | Ep  44/200 | TrL: 0.129793 | TrScore: 0.0032 | ValScore: 0.0007 | LR: 0.000047 | NO IMPROVE (20/20)\n",
      "Early stopping на эпохе 45\n",
      "✅ Attention_Optuna завершена. Best Val Score: 0.0014\n",
      "\n",
      "======================================================================\n",
      "МОДЕЛЬ 6/6: EnsembleInside_Optuna\n",
      "======================================================================\n",
      "Используются оптимизированные гиперпараметры:\n",
      "  num_experts: 5\n",
      "  expert_hidden: 256\n",
      "  gate_hidden: 256\n",
      "  lr: 0.0008736259494474606\n",
      "  augmentation_strength: 0.3742853580135097\n",
      "Начало обучения EnsembleInside_Optuna с аугментацией: True\n",
      "EnsembleInside_Optuna | AUG | Ep   1/200 | TrL: 0.109357 | TrScore: -0.0012 | ValScore: 0.0098 | LR: 0.000874 | ✓ УЛУЧШЕНИЕ\n",
      "EnsembleInside_Optuna | AUG | Ep  10/200 | TrL: 0.103877 | TrScore: 0.0094 | ValScore: 0.0102 | LR: 0.000874 | NO IMPROVE (7/20)\n",
      "EnsembleInside_Optuna | AUG | Ep  20/200 | TrL: 0.091929 | TrScore: 0.0252 | ValScore: 0.0162 | LR: 0.000874 | ✓ УЛУЧШЕНИЕ\n",
      "EnsembleInside_Optuna | AUG | Ep  30/200 | TrL: 0.080327 | TrScore: 0.0437 | ValScore: 0.0172 | LR: 0.000874 | ✓ УЛУЧШЕНИЕ\n",
      "EnsembleInside_Optuna | AUG | Ep  40/200 | TrL: 0.061476 | TrScore: 0.0711 | ValScore: 0.0242 | LR: 0.000874 | ✓ УЛУЧШЕНИЕ\n",
      "EnsembleInside_Optuna | AUG | Ep  50/200 | TrL: 0.034704 | TrScore: 0.1120 | ValScore: 0.0341 | LR: 0.000874 | ✓ УЛУЧШЕНИЕ\n",
      "EnsembleInside_Optuna | AUG | Ep  60/200 | TrL: -0.000621 | TrScore: 0.1640 | ValScore: 0.0439 | LR: 0.000874 | ✓ УЛУЧШЕНИЕ\n",
      "EnsembleInside_Optuna | AUG | Ep  70/200 | TrL: -0.037264 | TrScore: 0.2185 | ValScore: 0.0497 | LR: 0.000874 | ✓ УЛУЧШЕНИЕ\n",
      "EnsembleInside_Optuna | AUG | Ep  80/200 | TrL: -0.055100 | TrScore: 0.2497 | ValScore: 0.0561 | LR: 0.000874 | ✓ УЛУЧШЕНИЕ\n",
      "EnsembleInside_Optuna | AUG | Ep  90/200 | TrL: -0.100622 | TrScore: 0.3187 | ValScore: 0.0577 | LR: 0.000874 | NO IMPROVE (5/20)\n",
      "EnsembleInside_Optuna | AUG | Ep 100/200 | TrL: -0.112478 | TrScore: 0.3433 | ValScore: 0.0600 | LR: 0.000874 | NO IMPROVE (2/20)\n",
      "EnsembleInside_Optuna | AUG | Ep 110/200 | TrL: -0.148814 | TrScore: 0.3979 | ValScore: 0.0568 | LR: 0.000874 | NO IMPROVE (12/20)\n",
      "EnsembleInside_Optuna | AUG | Ep 118/200 | TrL: -0.162126 | TrScore: 0.4189 | ValScore: 0.0586 | LR: 0.000874 | NO IMPROVE (20/20)\n",
      "Early stopping на эпохе 119\n",
      "✅ EnsembleInside_Optuna завершена. Best Val Score: 0.0628\n",
      "\n",
      "======================================================================\n",
      "ВЕСА ВСЕХ 6 МОДЕЛЕЙ С OPTUNA ОПТИМИЗАЦИЕЙ:\n",
      "  Модель 1 (SimpleEffective_Optuna): вес=0.0491, val_score=0.0040 [OPTUNA]\n",
      "  Модель 2 (Residual_Optuna): вес=0.0620, val_score=0.0050 [OPTUNA]\n",
      "  Модель 3 (Wide_Optuna): вес=0.0662, val_score=0.0054 [OPTUNA]\n",
      "  Модель 4 (DeepSkip_Optuna): вес=0.0323, val_score=0.0026 [OPTUNA]\n",
      "  Модель 5 (Attention_Optuna): вес=0.0178, val_score=0.0014 [OPTUNA]\n",
      "  Модель 6 (EnsembleInside_Optuna): вес=0.7726, val_score=0.0628 [OPTUNA]\n",
      "======================================================================\n",
      "\n",
      "Scaler, feature_cols и hyperparams сохранены\n",
      "\n",
      "📊 ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ OPTUNA ДЛЯ SimpleEffective:\n",
      "Лучшие параметры: {'hidden_size': 256, 'dropout_rate': 0.18283347655873736, 'num_layers': 4, 'lr': 0.0002661348065476525, 'augmentation_strength': 0.6175825223429894}\n",
      "Лучший score: 0.0062\n",
      "✅ Сохранен: optuna_visualizations/SimpleEffective_param_importance.png\n",
      "✅ Сохранен: optuna_visualizations/SimpleEffective_parallel_coord.png\n",
      "✅ Сохранен: optuna_visualizations/SimpleEffective_optimization_history.png\n",
      "✅ Сохранен: optuna_visualizations/SimpleEffective_slice_plot.png\n",
      "\n",
      "📊 ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ OPTUNA ДЛЯ Residual:\n",
      "Лучшие параметры: {'hidden_size': 512, 'num_blocks': 3, 'dropout_rate': 0.36587434789878137, 'lr': 0.0006432037874787973}\n",
      "Лучший score: 0.0063\n",
      "✅ Сохранен: optuna_visualizations/Residual_param_importance.png\n",
      "✅ Сохранен: optuna_visualizations/Residual_parallel_coord.png\n",
      "✅ Сохранен: optuna_visualizations/Residual_optimization_history.png\n",
      "✅ Сохранен: optuna_visualizations/Residual_slice_plot.png\n",
      "\n",
      "📊 ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ OPTUNA ДЛЯ Wide:\n",
      "Лучшие параметры: {'hidden_size1': 1024, 'hidden_size2': 1024, 'hidden_size3': 512, 'dropout1': 0.3933935184335017, 'dropout2': 0.16721243904973276, 'dropout3': 0.34738895506018463, 'lr': 0.00016172429558128834}\n",
      "Лучший score: 0.0085\n",
      "✅ Сохранен: optuna_visualizations/Wide_param_importance.png\n",
      "✅ Сохранен: optuna_visualizations/Wide_parallel_coord.png\n",
      "✅ Сохранен: optuna_visualizations/Wide_optimization_history.png\n",
      "✅ Сохранен: optuna_visualizations/Wide_slice_plot.png\n",
      "\n",
      "📊 ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ OPTUNA ДЛЯ DeepSkip:\n",
      "Лучшие параметры: {'hidden_size': 512, 'num_blocks': 3, 'dropout_rate': 0.1593471678905147, 'lr': 4.292329872735687e-05, 'augmentation_strength': 0.42251735704433485}\n",
      "Лучший score: 0.0090\n",
      "✅ Сохранен: optuna_visualizations/DeepSkip_param_importance.png\n",
      "✅ Сохранен: optuna_visualizations/DeepSkip_parallel_coord.png\n",
      "✅ Сохранен: optuna_visualizations/DeepSkip_optimization_history.png\n",
      "✅ Сохранен: optuna_visualizations/DeepSkip_slice_plot.png\n",
      "\n",
      "📊 ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ OPTUNA ДЛЯ Attention:\n",
      "Лучшие параметры: {'hidden_size': 1024, 'num_heads': 4, 'dropout_rate': 0.18413713429117845, 'lr': 4.710208379346669e-05, 'augmentation_strength': 0.6852492269167936}\n",
      "Лучший score: 0.0098\n",
      "✅ Сохранен: optuna_visualizations/Attention_param_importance.png\n",
      "✅ Сохранен: optuna_visualizations/Attention_parallel_coord.png\n",
      "✅ Сохранен: optuna_visualizations/Attention_optimization_history.png\n",
      "✅ Сохранен: optuna_visualizations/Attention_slice_plot.png\n",
      "\n",
      "📊 ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ OPTUNA ДЛЯ EnsembleInside:\n",
      "Лучшие параметры: {'num_experts': 5, 'expert_hidden': 256, 'gate_hidden': 256, 'lr': 0.0008736259494474606, 'augmentation_strength': 0.3742853580135097}\n",
      "Лучший score: 0.0535\n",
      "✅ Сохранен: optuna_visualizations/EnsembleInside_param_importance.png\n",
      "✅ Сохранен: optuna_visualizations/EnsembleInside_parallel_coord.png\n",
      "✅ Сохранен: optuna_visualizations/EnsembleInside_optimization_history.png\n",
      "✅ Сохранен: optuna_visualizations/EnsembleInside_slice_plot.png\n",
      "\n",
      "🎉 Все визуализации сохранены в папку 'optuna_visualizations/'\n",
      "\n",
      "Запуск полной оценки модели...\n",
      "\n",
      "🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯\n",
      "ПОЛНАЯ ОЦЕНКА МОДЕЛИ (ПРАВИЛЬНАЯ МЕТРИКА)\n",
      "🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯\n",
      "Обрабатывается 100 базовых колонок...\n",
      "Достигнут лимит в 800 признаков\n",
      "Создано 1507 признаков после фильтрации\n",
      "\n",
      "1️⃣  VALIDATION SCORE:\n",
      "Validation set size: 197 samples\n",
      "\n",
      "======================================================================\n",
      "ДИАГНОСТИКА ПРЕДСКАЗАНИЙ\n",
      "======================================================================\n",
      "\n",
      "Форма данных:\n",
      "  Predictions: (197, 424)\n",
      "  Targets: (197, 424)\n",
      "\n",
      "Статистика predictions:\n",
      "  Mean:   -0.00033972\n",
      "  Std:    0.01681757\n",
      "  Min:    -0.07203742\n",
      "  Max:    0.07142386\n",
      "  Median: -0.00045117\n",
      "\n",
      "Статистика targets:\n",
      "  Mean:   -0.00012092\n",
      "  Std:    0.02677094\n",
      "  Min:    -0.26562447\n",
      "  Max:    0.30091500\n",
      "  Median: 0.00000000\n",
      "\n",
      "✅ Нет константных predictions колонок\n",
      "\n",
      "✅ Нет константных target колонок\n",
      "\n",
      "✅ Predictions: Нет NaN/Inf\n",
      "\n",
      "✅ Targets: Нет NaN/Inf\n",
      "\n",
      "Распределение знаков predictions:\n",
      "  Positive: 40827/83528 (48.9%)\n",
      "  Negative: 42701/83528 (51.1%)\n",
      "  Zero:     0/83528 (0.0%)\n",
      "\n",
      "Распределение знаков targets:\n",
      "  Positive: 36783/83528 (44.0%)\n",
      "  Negative: 37149/83528 (44.5%)\n",
      "  Zero:     9596/83528 (11.5%)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ВЫЧИСЛЕНИЕ KAGGLE SCORE (Modified Sharpe Ratio)\n",
      "======================================================================\n",
      "\n",
      "Статистика Spearman Correlations:\n",
      "  Успешно: 424/424 targets\n",
      "  Mean:    0.028804\n",
      "  Median:  0.028221\n",
      "  Std:     0.085699\n",
      "  Min:     -0.250455\n",
      "  Max:     0.273723\n",
      "\n",
      "  Positive correlations: 263/424 (62.0%)\n",
      "  Negative correlations: 161/424 (38.0%)\n",
      "  Near zero (|r| < 0.01): 34/424 (8.0%)\n",
      "\n",
      "======================================================================\n",
      "KAGGLE SCORE (Modified Sharpe Ratio):\n",
      "======================================================================\n",
      "  Sharpe Ratio:        0.336111\n",
      "  KAGGLE SCORE:        33611.05\n",
      "\n",
      "  ⚠ Слабый результат (> 0, но < 50,000)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "2️⃣  TEST SCORE:\n",
      "Обрабатывается 100 базовых колонок...\n",
      "Достигнут лимит в 800 признаков\n",
      "Создано 1502 признаков после фильтрации\n",
      "\n",
      "======================================================================\n",
      "ДИАГНОСТИКА ПРЕДСКАЗАНИЙ\n",
      "======================================================================\n",
      "\n",
      "Форма данных:\n",
      "  Predictions: (90, 424)\n",
      "  Targets: (90, 424)\n",
      "\n",
      "Статистика predictions:\n",
      "  Mean:   -0.00020441\n",
      "  Std:    0.01786772\n",
      "  Min:    -0.08103655\n",
      "  Max:    0.07919317\n",
      "  Median: -0.00056324\n",
      "\n",
      "Статистика targets:\n",
      "  Mean:   -0.00035172\n",
      "  Std:    0.02992744\n",
      "  Min:    -0.26562447\n",
      "  Max:    0.30091500\n",
      "  Median: 0.00000000\n",
      "\n",
      "✅ Нет константных predictions колонок\n",
      "\n",
      "✅ Нет константных target колонок\n",
      "\n",
      "✅ Predictions: Нет NaN/Inf\n",
      "\n",
      "✅ Targets: Нет NaN/Inf\n",
      "\n",
      "Распределение знаков predictions:\n",
      "  Positive: 18537/38160 (48.6%)\n",
      "  Negative: 19623/38160 (51.4%)\n",
      "  Zero:     0/38160 (0.0%)\n",
      "\n",
      "Распределение знаков targets:\n",
      "  Positive: 16955/38160 (44.4%)\n",
      "  Negative: 17145/38160 (44.9%)\n",
      "  Zero:     4060/38160 (10.6%)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ВЫЧИСЛЕНИЕ KAGGLE SCORE (Modified Sharpe Ratio)\n",
      "======================================================================\n",
      "\n",
      "Статистика Spearman Correlations:\n",
      "  Успешно: 424/424 targets\n",
      "  Mean:    0.006594\n",
      "  Median:  0.008608\n",
      "  Std:     0.116016\n",
      "  Min:     -0.355198\n",
      "  Max:     0.330702\n",
      "\n",
      "  Positive correlations: 223/424 (52.6%)\n",
      "  Negative correlations: 201/424 (47.4%)\n",
      "  Near zero (|r| < 0.01): 23/424 (5.4%)\n",
      "\n",
      "======================================================================\n",
      "KAGGLE SCORE (Modified Sharpe Ratio):\n",
      "======================================================================\n",
      "  Sharpe Ratio:        0.056834\n",
      "  KAGGLE SCORE:        5683.42\n",
      "\n",
      "  ⚠ Слабый результат (> 0, но < 50,000)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "📊 СРАВНЕНИЕ РЕЗУЛЬТАТОВ:\n",
      "======================================================================\n",
      "Метрика                        Validation           Test                \n",
      "----------------------------------------------------------------------\n",
      "KAGGLE SCORE                   33611.05             5683.42             \n",
      "Sharpe Ratio                   0.336111             0.056834            \n",
      "Mean Correlation               0.028804             0.006594            \n",
      "Std Correlation                0.085699             0.116016            \n",
      "======================================================================\n",
      "⚠ Слабый результат. Score > 0, но < 50,000\n",
      "\n",
      "🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯\n",
      "\n",
      "\n",
      "Создание submission файла...\n",
      "\n",
      "Создание submission.parquet...\n",
      "Генерация предсказаний...\n",
      "Обрабатывается 100 базовых колонок...\n",
      "Достигнут лимит в 800 признаков\n",
      "Создано 1502 признаков после фильтрации\n",
      "Готово: (90, 425)\n",
      "\n",
      "✅ OPTUNA АНСАМБЛЬ ГОТОВ!\n",
      "🔢 Количество моделей: 6\n",
      "🎯 Использована оптимизация гиперпараметров: True\n",
      "🔬 Количество trials на модель: 10\n",
      "🏆 Ожидаемый Kaggle Score: 33611.05\n",
      "📁 Submission файл: submission_optuna.parquet\n",
      "\n",
      "🚀 ОТПРАВЛЯЙТЕ НА KAGGLE!\n"
     ]
    }
   ],
   "source": [
    "def main_with_optuna(use_optuna=True, optuna_trials=30, run_evaluation=True):\n",
    "    global is_initialized\n",
    "    \n",
    "    print(\"ЗАПУСК ПАЙПЛАЙНА С OPTUNA ОПТИМИЗАЦИЕЙ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not is_initialized:\n",
    "        print(\"Начало обучения с оптимизацией гиперпараметров...\")\n",
    "        initialize_models_with_optuna(use_optuna=use_optuna, optuna_trials=optuna_trials)\n",
    "    \n",
    "    # Визуализация результатов Optuna\n",
    "    if use_optuna:\n",
    "        visualize_optuna_results()\n",
    "    \n",
    "    # Полная оценка модели\n",
    "    if run_evaluation:\n",
    "        print(\"\\nЗапуск полной оценки модели...\")\n",
    "        results = full_evaluation_corrected()\n",
    "    \n",
    "    # Создание submission\n",
    "    print(\"\\nСоздание submission файла...\")\n",
    "    create_submission_file()\n",
    "    \n",
    "    print(\"\\n✅ OPTUNA АНСАМБЛЬ ГОТОВ!\")\n",
    "    print(f\"🔢 Количество моделей: {len(models)}\")\n",
    "    print(f\"🎯 Использована оптимизация гиперпараметров: {use_optuna}\")\n",
    "    if use_optuna:\n",
    "        print(f\"🔬 Количество trials на модель: {optuna_trials}\")\n",
    "    if run_evaluation:\n",
    "        print(f\"🏆 Ожидаемый Kaggle Score: {results['validation']['kaggle_score']:.2f}\")\n",
    "    print(f\"📁 Submission файл: submission_optuna.parquet\")\n",
    "    print(f\"\\n🚀 ОТПРАВЛЯЙТЕ НА KAGGLE!\")\n",
    "\n",
    "# Запуск пайплайна\n",
    "if __name__ == \"__main__\":\n",
    "    main_with_optuna(use_optuna=True, optuna_trials=10, run_evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367bacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fd85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd_kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
