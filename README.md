# MITSUI Commodity Prediction Challenge

Time series forecasting –¥–ª—è 424 —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–º–µ—Ç–∞–ª–ª—ã, –∞–∫—Ü–∏–∏, forex) –∏—Å–ø–æ–ª—å–∑—É—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ Deep Learning –º–æ–¥–µ–ª–∏.

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞

- üéØ **–ú–µ—Ç—Ä–∏–∫–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è**: Spearman correlation (Modified Sharpe Ratio)
- üî• **16+ –º–æ–¥–µ–ª–µ–π**: –û—Ç –ø—Ä–æ—Å—Ç—ã—Ö (DLinear) –¥–æ SOTA (PatchTST, N-HiTS)
- üìä **–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏**: –ë–µ–∑ data leakage
- ‚ö° **Hyperparameter tuning**: Optuna –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- üìà **Tracking**: WandB –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

## –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
git clone git@github.com:nicolaedrabcinski/sd_kaggle.git
cd sd_kaggle

# –°–æ–∑–¥–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# –∏–ª–∏
.venv\Scripts\activate  # Windows

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt

# –ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–µ–∫—Ç –∫–∞–∫ –ø–∞–∫–µ—Ç
pip install -e .
```

### 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ

```bash
# –ß–µ—Ä–µ–∑ Kaggle API
kaggle competitions download -c mitsui-commodity-prediction-challenge -p data/raw/
cd data/raw && unzip mitsui-commodity-prediction-challenge.zip && cd ../..
```

### 3. –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏

```bash
# –ö–†–ò–¢–ò–ß–ù–û: –ó–∞–ø—É—Å—Ç–∏—Ç—å feature engineering –ë–ï–ó data leakage
python scripts/create_proper_features.py

# –≠—Ç–æ —Å–æ–∑–¥–∞—Å—Ç: data/processed/train_features_v2.csv
# –° lagged targets –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
```

### 4. –¢—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å

```bash
# –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
python scripts/train.py --list

# –¢—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å (–±—ã—Å—Ç—Ä–æ)
python scripts/train.py --model dlinear --epochs 100

# –¢—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å SOTA –º–æ–¥–µ–ª—å
python scripts/train.py --model patchtst --epochs 100

# –¢—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏ (–¥–æ–ª–≥–æ!)
python scripts/train.py --all --epochs 50
```

### 5. –°—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

```bash
python scripts/train.py --compare
```

### 6. –°–æ–∑–¥–∞—Ç—å submission

```bash
python scripts/create_submission.py --model dlinear
```

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ Kaggle (–Ω–µ –≤ Git)
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–µ –≤ Git)
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/            # –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –º–æ–¥–µ–ª–µ–π (–Ω–µ –≤ Git)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                  # Jupyter notebooks –¥–ª—è EDA
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ eda_commodity_prediction.ipynb
‚îÇ
‚îú‚îÄ‚îÄ scripts/                    # –°–∫—Ä–∏–ø—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ train.py               # –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ create_proper_features.py  # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ create_submission.py   # –°–æ–∑–¥–∞–Ω–∏–µ submission
‚îÇ   ‚îú‚îÄ‚îÄ optimize.py            # Hyperparameter optimization
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py          # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îî‚îÄ‚îÄ debug/                 # –û—Ç–ª–∞–¥–æ—á–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã
‚îÇ
‚îú‚îÄ‚îÄ src/                       # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset.py         # Dataset –∏ DataLoader
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                # –†–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ registry.py        # –†–µ–≥–∏—Å—Ç—Ä –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dlinear.py         # DLinear, NLinear, RLinear, FITS
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patchtst.py        # PatchTST, CrossFormer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nhits.py           # N-HiTS, N-BEATS
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ timesnet.py        # TimesNet, Autoformer, FEDformer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cnn_attention.py   # CNN + Attention
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tabnet.py          # TabNet, MLP
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ft_transformer.py  # Feature Tokenizer Transformer
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py         # Trainer –∫–ª–∞—Å—Å
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ losses.py          # MitsuiLoss, SpearmanLoss
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ technical_indicators.py  # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ
‚îú‚îÄ‚îÄ outputs/                   # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îú‚îÄ‚îÄ submissions/               # –§–∞–π–ª—ã –¥–ª—è submission
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt           # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ pyproject.toml            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

## –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏

### Baseline (–±—ã—Å—Ç—Ä—ã–µ)
- **dlinear** - Decomposition + Linear (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è —Å—Ç–∞—Ä—Ç–∞)
- **nlinear** - Normalized Linear
- **rlinear** - RevIN + Linear
- **fits** - Frequency Interpolation

### Transformer-based
- **patchtst** - PatchTST (SOTA –¥–ª—è time series) ‚≠ê
- **patchtst_ci** - PatchTST —Å Channel Independence
- **ft_transformer** - Feature Tokenizer Transformer
- **performer** - –õ–∏–Ω–µ–π–Ω—ã–π attention
- **crossformer** - Cross-dimension dependencies

### Advanced Time Series
- **nhits** - N-HiTS (SOTA forecasting) ‚≠ê
- **nbeats** - N-BEATS (–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π)
- **autoformer** - Auto-correlation
- **fedformer** - Frequency enhanced
- **timesnet** - Multi-periodicity

### Tabular-focused
- **tabnet** - TabNet (attentive)
- **residual_mlp** - Deep MLP —Å residuals
- **xgboost_nn** - Neural network –≤ —Å—Ç–∏–ª–µ XGBoost

### CNN-based
- **cnn_attention** - Multi-scale CNN + Attention
- **wavenet** - Dilated causal convolutions

## –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è

**–ì–ª–∞–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞**: Modified Sharpe Ratio –Ω–∞ –æ—Å–Ω–æ–≤–µ Spearman correlation

```python
# –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è Spearman correlation
correlations = [spearman(predictions[i], targets[i]) for i in range(424)]

# –§–∏–Ω–∞–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
mean_correlation = mean(correlations)
std_correlation = std(correlations)
modified_sharpe = mean_correlation / std_correlation
```

**–í–∞–∂–Ω–æ**:
- MSE/RMSE –ù–ï —è–≤–ª—è—é—Ç—Å—è —Ü–µ–ª–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
- R¬≤ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –¥–ª—è efficient markets (—ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ!)
- Directional accuracy (>50%) –≤–∞–∂–Ω–µ–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏–π

## Hyperparameter Optimization

```bash
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
python scripts/optimize.py --model patchtst --trials 100

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
python scripts/visualize_optuna.py
```

## –í–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏

### –ë–µ–∑ Data Leakage!

1. **–í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ**: Train/Val/Test —Å—Ç—Ä–æ–≥–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–µ random!)
2. **Lagged targets**: –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (lag 1-4)
3. **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è**: Fit —Ç–æ–ª—å–∫–æ –Ω–∞ train, transform –Ω–∞ val/test
4. **Lookback**: Val/Test –∏–º–µ—é—Ç overlap –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

### Loss Function

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **MitsuiLoss** - –∫–æ–º–±–∏–Ω–∞—Ü–∏—è:
- Spearman correlation loss (70%)
- Directional loss (30%)

```python
# –í scripts/train.py
python train.py --model dlinear --loss mitsui --spearman-weight 0.7
```

### Feature Engineering

–°–æ–∑–¥–∞–µ—Ç—Å—è `train_features_v2.csv` —Å:
- Lagged targets (lag 1-4 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞)
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (MA, EMA, RSI, Bollinger)
- Momentum features
- Volatility measures

## Troubleshooting

### –û—à–∏–±–∫–∞: "Data file not found"

```bash
# –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –∑–∞–ø—É—Å—Ç–∏–ª–∏ feature engineering:
python scripts/create_proper_features.py
```

### –û—à–∏–±–∫–∞: "CUDA out of memory"

```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ batch size:
python scripts/train.py --model patchtst --epochs 100
# –ó–∞—Ç–µ–º –≤ –∫–æ–¥–µ MODEL_REGISTRY —É–º–µ–Ω—å—à–∏—Ç–µ batch_size
```

### –ú–æ–¥–µ–ª—å –≤—ã–¥–∞–µ—Ç NaN

- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ NaN –≤ –¥–∞–Ω–Ω—ã—Ö
- –£–º–µ–Ω—å—à–∏—Ç–µ learning rate
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ gradient clipping (—É–∂–µ –≤–∫–ª—é—á–µ–Ω–æ)

## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

–õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤:
- `models/checkpoints/{model_name}/best_model.pth`
- `outputs/{model_name}_v2_results.json`

–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:
```bash
python scripts/train.py --compare
```

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

1. **–ù–∞—á–Ω–∏—Ç–µ —Å dlinear** - –±—ã—Å—Ç—Ä—ã–π baseline
2. **–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ hyperparameters** –¥–ª—è –≤–∞—à–µ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
3. **–ê–Ω—Å–∞–º–±–ª—å** - –∫–æ–º–±–∏–Ω–∏—Ä—É–π—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
4. **Feature engineering** - –¥–æ–±–∞–≤—å—Ç–µ domain-specific –ø—Ä–∏–∑–Ω–∞–∫–∏

## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

- **PyTorch 2.0+** - Deep Learning framework
- **PyTorch Lightning** - Training utilities
- **Optuna** - Hyperparameter optimization
- **WandB** - Experiment tracking
- **Pandas/NumPy** - Data processing
- **SciPy** - Spearman correlation

## –ê–≤—Ç–æ—Ä

**Nicolae Drabcinski**
UTM FCIM, SD-241M
Email: drabcinski@gmail.com

## License

MIT License
